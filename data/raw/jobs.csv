"id","site","job_url","job_url_direct","title","company","location","job_type","date_posted","salary_source","interval","min_amount","max_amount","currency","is_remote","job_level","job_function","company_industry","listing_type","emails","description","company_url","company_url_direct","company_addresses","company_num_employees","company_revenue","company_description","logo_photo_url","banner_photo_url","ceo_name","ceo_photo_url"
"1009480753410","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009480753410","","Data Engineer II","Lennar","Irving, TX","","2024-10-10","direct_data","yearly",87937.0,110058.0,"USD",False,"","","","organic","","We are Lennar
Lennar is one of the nation's leading homebuilders, dedicated to making an impact and creating an extraordinary experience for their Homeowners, Communities, and Associates by building quality homes and providing exceptional customer service, giving back to the communities in which we work and live in, and fostering a culture of opportunity and growth for our Associates throughout their career. Lennar has been recognized as a Fortune 500® company and consistently ranked among the top homebuilders in the United States.
Join a Company that Empowers you to Build your Future
The primary mission of the Data Engineer II role is to help our business evolve into a data and insights-driven organization. This position sits in our Enterprise Data and Analytics team, which aims to drive improved business outcomes using insights gleaned from data and analytics, infusing them into Lennar’s corporate fabric.
The Data Engineer II will be involved in technical planning & solutions implementation as part of our data platform engineering team. This is done by helping implement our next generation data and analytics platforms and products using Data engineering best practices. This position will also help mentor more junior associates, such as recent college graduates and early career teammates. The Data Engineer II is a key role in operationalizing Lennar’s enterprise data fabric.* A career with purpose.
* A career built on making dreams come true.
* A career built on building zero defect homes, cost management, and adherence to schedules.


Your Responsibilities on the Team* Build and operationalize data engineering solutions for Lennar’s data and analytics platforms and products.
* Be part of the operational support excellence rotation team, available to provide insight and troubleshoot during support calls.
* Implement ETL, ELT and streaming data ingestion data delivery processes across multiple sources.
* Experience in data modeling, cloud data lake, cloud data warehouse
* Instrument data analytics platforms with robust metrics and monitoring.
* Improve data ingestion architecture, emphasizing data quality, maintainability, and extensibility.
* Support process improvement on the team to enable rapid development of data products.
* Implement standards and best practices for data analytics team, including code modularization, versioning, testing, automation of CI/CD workflows, code reviews etc.
* Gain an understanding of core business processes and align data development with business strategy.
* Wrangle and integrate data from disparate systems to allow data analysts and data scientists to leverage end-to-end data and information.


Requirements
Technical Requirements* At least 4+, prefers 5+ years in:
	+ Data Architecture design
	+ Data modeling & Data warehousing concepts
	+ Data transformations and standardizations
	+ ETL processes & strategies
	+ Monitoring and error handling
	+ SDLC & workflow best practices
		- Code Reviews
		- QA/Testing methodologies
* At least 2+, prefers 3+ years with the following technologies and platforms:
	+ AWS platform: S3, EC2, EMR, EKS, Glue, Lambda, AppFlow, Cloudwatch etc.
	+ AWS certification is big plus
	+ Snowflake Data Cloud
		- Account Administration
		- Virtual warehouse strategies
		- Snowflake feature implementation: Data Sharing, Time Travel, and Zero-copy cloning
		- Role-based Access Control strategies
	+ Dbt
		- Managing dbt cloud environment
		- Managing multi-repository dbt projects
		- Creating and managing dbt models
		- Creating and leveraging dbt macros
	+ Version control & branching strategies (Github a plus)
	+ Proficient in languages: SQL, Python
	+ Data governance, security, and compliance concepts
	+ Data Ingestion
		- Incremental and CDC ingestion methods
		- REST APIs
* Familiarity (At least 1+ years of experience) with:
	+ Orchestration & scheduling tools (Prefect, Airflow is a plus)
	+ Qlik Replicate


Other Requirements* Willingness and availability to be:
	+ On-site at a Lennar designated office location up to 5 days a week.
	+ Part of on-call support calls, which could happen during off hours and weekends.
* Ability to work collaboratively and productively with other team members to achieve Lennar’s objectives.
* Thirst to help transform Lennar into an insights-driven organization.
* Demonstrated some experience in all aspects of development including, but not limited to, gathering requirements, development of technical components related to process scope and supporting testing and post implementation support.
* Ability to work and partner with users and stakeholders to gather solution requirements.
* Experience working with business users to understand how to optimally deliver insights within their operational workflows & decision-making processes.
* Ability and willingness to quickly learn new technologies.
* Ability and willingness to learn about the business, its strategy, objectives, and core business processes.


Additional Requirements:* Travel up to 10% of the time to Divisions within the Lennar family.
* Interact well with co-workers.
* Cross train for position(s) within the team organizational structure from time to time, as required by the Leadership Team.
* Comply with and implement company policies and procedures.
* Accept constructive criticism.
* Strong work ethic.
* Team player.

  

This description outlines the basic responsibilities and requirements for the position noted. This is not a comprehensive listing of all job duties of the Associates. Duties, responsibilities and activities may change at any time with or without notice.
#LI-GC1
Physical & Office/Site Presence Requirements:
This is primarily a sedentary office position which requires he position to have the ability to operate computer equipment. Finger dexterity is necessary.
Life at Lennar
At Lennar, we are committed to fostering a supportive and enriching environment for our Associates, offering a comprehensive array of benefits designed to enhance their well-being and professional growth. Our Associates have access to robust health insurance plans, including Medical, Dental, and Vision coverage, ensuring their health needs are well taken care of. Our 401(k) Retirement Plan, complete with a $1 for $1 Company Match up to 5%, helps secure their financial future, while Paid Parental Leave and an Associate Assistance Plan provide essential support during life's critical moments. To further support our Associates, we provide an Education Assistance Program and up to $30,000 in Adoption Assistance, underscoring our commitment to their diverse needs and aspirations. From the moment of hire, they can enjoy up to three weeks of vacation annually, alongside generous Holiday, Sick Leave, and Personal Day policies. Additionally, we offer a New Hire Referral Bonus Program, significant Home Purchase Discounts, and unique opportunities such as the Everyone’s Included Day. At Lennar, we believe in investing in our Associates, empowering them to thrive both personally and professionally. Lennar Associates will have access to these benefits as outlined by Lennar’s policies and applicable plan terms. Visit Lennartotalrewards.com to view our suite of benefits.
Join the fun and follow us on social media to see what's happening at our company, and don't forget to connect with us on Lennar: Overview | LinkedIn<https://www.linkedin.com/company/lennar/> for the latest job opportunities.
Lennar is an equal opportunity employer and complies with all applicable federal, state, and local fair employment practices laws.","https://www.glassdoor.com/Overview/W-EI_IE400.htm","","","","","","https://media.glassdoor.com/sql/400/lennar-squareLogo-1703097424096.png","","",""
"1009481605127","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009481605127","","Engineer, Data - Clinical Analytics","Concentra","Addison, TX","","2024-10-10","direct_data","yearly",78524.0,119490.0,"USD",False,"","","","organic","","Overview:

The Data Engineer - Clinical Analytics is primarily focused on analytical processes with ability to implement database solutions and best practices in the realm of data science and machine learning projects. Essential software engineering skills with foundational knowledge on data movement and orchestration both on-premises and cloud environment. The Data Engineer supports and aligns with business decisions within Concentra by analyzing raw data, constructing, and maintaining data systems, and improving data quality and efficiency. Implements programming languages to develop and test architectures that enables data operations for predictive (i.e., machine learning/AI) or prescriptive modeling.
Responsibilities:
- 

Analyze, develop, combine raw information, and maintain various data sources
  

- 

Identify opportunities for data acquisition and collaborate with Application owners and Subject Matter Experts (SME) to document data domain knowledge
  

- 

Implement ETL methods to prepare both structured and unstructured data for predictive and prescriptive modeling
  

- 

Leverage data serialization techniques to meet project needs for use in various reporting platforms
  

- 

Understand enterprise project life cycle and prepare for integration and user acceptance testing methods.
  

- 

Produce technical documentation by following enterprise standards and guidelines
  

- 

Participate in relevant information-sharing activities
  

- 

Proactive identification of issues and opportunities that will have an impact on the business use of reports and ensure managerial awareness
  

- 

Understand troubleshooting and resolutions processes  

This job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.  


Qualifications:
**Education Level:**
Bachelor’s Degree in Computer Science or Computer Engineering preferred  

Degree must be from an accredited college or university.  

**Job-Related Experience**- 

Customarily has at least 6 months to 1 year in software development and data pipelines
  

- 

Relational Database exposure/experience
  

- 

Documentation and publication  

**Job-Related Skills/Competencies*** Concentra Core Competencies of Service Mentality, Attention to Detail, Sense of Urgency, Initiative and Flexibility
* Ability to make decisions or solve problems by using logic to identify key facts, explore alternatives, and propose quality solutions
* Outstanding customer service skills as well as the ability to deal with people in a manner which shows tact and professionalism
* The ability to properly handle sensitive and confidential information (including HIPAA and PHI) in accordance with federal and state laws and company policies
  

- 

Ability to write SQL queries, develop and tune query performance
  

- 

Develop skills for appropriate use of technology to align with project needs
  

- 

Familiarize and scale tools such as: SQL Server, SSIS, Python, Azure, Docker, Git, and Visual Studio
  

- 

Ability to understand and interact with cloud technology such as: Azure, AWS and/or GCP preferred
  

- 

Understand data management process
  

- 

Support current and future initiatives of application development
  

- 

Participate in peer-review of codes and maintain repositories
  

- 

Concentra Core Competencies of Service Mentality, Attention to Detail, Sense of Urgency, Initiative and Flexibility
  

- 

Ability to make decisions or solve problems by using logic to identify key facts
  

- 

Highly organized
  

- 

Good communication skills to effectively speak and write in a clear and professional manner
  

- 

Skilled at listening, understanding and providing feedback  


Additional Data:
**Employee Benefits*** 401(k) Retirement Plan with Employer Match
* Medical, Vision, Prescription, Telehealth, & Dental Plans
* Life & Disability Insurance
* Paid Time Off
* Colleague Referral Bonus Program
* Tuition Reimbursement
* Commuter Benefits
* Dependent Care Spending Account
* Employee Discounts

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation, if required.  

\\*This job requires access to confidential and sensitive information, requiring ongoing discretion and secure information management\\* **Concentra is an Equal Opportunity Employer, including disability/veterans**","https://www.glassdoor.com/Overview/W-EI_IE4169.htm","","","","","","https://media.glassdoor.com/sql/4169/concentra-squareLogo-1702595672375.png","","",""
"1009480228249","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009480228249","","Data Engineer","EMFOI","Plano, TX","","2024-10-10","direct_data","hourly",40.0,50.0,"USD",False,"","","","organic","","Hi

Today we have a new role with us

Position: Data Engineer with AWS

Location: Hybrid - Plano, TX

Client: Data Engineer with AWS - Hybrid - Plano, TX - Ex-Capital One needed with PWC/CAP ONE

Responsibilities :

BS/BA degree or equivalent experience

General: Strong organizational, problem-solving, and critical thinking skills; Strong documentation skills

Coding: Proficiency in Java (Preferable) & Python

Cluster Computing frameworks: Proficiency in Spark

AWS Data Services: Proficiency in Lake formation, Glue ETL (or) EMR, S3, Glue Catalog, Athena, Kinesis (or) MSK, Airflow (or) Lambda + Step Functions + Event Bridge

Data De/Serialization: Expertise in atleast 2 of the formats: Parquet, Iceberg, AVRO, JSON-LD

DevOps: Linux Scripting, Jenkins, Git, CI/CD, JIRA, TDD

AWS Data Security: Good Understanding of security concepts such as: Lake formation, IAM, Service roles, Encryption, KMS, Secrets Manager

Job Type: Contract

Pay: $40.00 - $50.00 per hour

Expected hours: 40 per week

Benefits:

* 401(k)
* Dental insurance
* Health insurance

Schedule:

* 8 hour shift

Work Location: In person","","","","","","","","","",""
"1009480269806","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009480269806","","Cloud Data Engineer, Air Force, Google Public Sector","Google","Addison, TX","","2024-10-10","description","yearly",142000.0,211000.0,"USD",False,"","","","organic","","The application window will be open until at least October 11, 2024. This opportunity will remain online based on business needs which may be before or after the specified date.Note: By applying to this position you will have an opportunity to share your preferred working location from the following: Reston, VA, USA; Atlanta, GA, USA; Austin, TX, USA; Boulder, CO, USA; Chicago, IL, USA; Addison, TX, USA; Washington D.C., DC, USA.
  
  

**Minimum qualifications:**  

* Bachelor’s degree in Engineering, Computer Science, a related field, or equivalent practical experience.
* 6 years of experience with data migration strategies and moving production systems either in on-premise/data center environments or migration to cloud scenarios.
* 6 years of experience in writing software in one or more languages, such as Java, Python, or Go.


**Preferred qualifications:**  

* Experience with database management tools for backups, recovery, snapshot management, sharding, partitioning and as well as database performance tuning.
* Experience working with cloud databases such as RDS, Aurora, DynamoDb, ElastiCache, CloudSQL, Datastore, Firestore, or Cloud Spanner.
* Experience with database technologies such as PostgreSQL, MySQL, SQL Server, Oracle.
* Knowledge of database administration techniques including storage, clustering, high availability, disaster recovery, security, logging, monitoring and auditing.
* Strong SQL skills with deep query troubleshooting knowledge such as isolating blocks of poor performing SQL, determining root cause, and developing remediation actions.


About the job
  
  

As a Cloud Data Engineer, you will guide the Air Force on how to ingest, store, process, analyze, and explore/visualize data on the Google Cloud Platform. You will work on data migrations and transformational projects, and with customers to design large-scale data processing systems, develop data pipelines optimized for scaling, and troubleshoot potential platform challenges. You will travel to the customer site to deploy solutions and deliver workshops to educate and empower customers. Additionally, you will work closely with Product Management and Product Engineering to build and constantly drive excellence in our products.
  
Must be a US Citizen to meet customer and compliance requirements, including potential access to classified information and have the ability to obtain a U.S. Government Top Secret (TS) security clearance.Google Public Sector brings the magic of Google to the mission of government and education with solutions purpose-built for enterprises. We focus on helping United States public sector institutions accelerate their digital transformations, and we continue to make significant investments and grow our team to meet the complex needs of local, state and federal government and educational institutions.
  
The US base salary range for this full-time position is $142,000-$211,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.
  
Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more aboutbenefits at Google.
  
  

Responsibilities
  
  

* Be a trusted technical advisor to the Air Force and solve complex data challenges.
* Analyze on-premises and cloud database environments and consult on the optimal design for performance and deployment on Google Cloud Platform.
* Create and deliver best practices recommendations, tutorials, blog articles, sample code, and technical presentations adapting to different levels of key business and technical stakeholders.
* Travel up to 30%of the time in-region for meetings, technical reviews, and onsite delivery activities.


Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See alsoGoogle's EEO Policy andEEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing ourAccommodations for Applicants form.","https://www.glassdoor.com/Overview/W-EI_IE9079.htm","","","","","","https://media.glassdoor.com/sql/9079/google-squarelogo-1441130773284.png","","",""
"1009480393146","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009480393146","","Senior Data Engineer","Liberty Mutual","Plano, TX","","2024-10-10","direct_data","yearly",103400.0,188800.0,"USD",False,"","","","organic","","**Pay Philosophy**
The typical starting salary range for this role is determined by a number of factors including skills, experience, education, certifications and location. The full salary range for this role reflects the competitive labor market value for all employees in these positions across the national market and provides an opportunity to progress as employees grow and develop within the role. Some roles at Liberty Mutual have a corresponding compensation plan which may include commission and/or bonus earnings at rates that vary based on multiple factors set forth in the compensation plan for the role.

 **Description**  



We deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as a tech startup within a Fortune 100 company, we are leading a digital disruption that will redefine how people experience insurance.

 ***This role has a hybrid work schedule (2 days per week in the office) and we will only consider candidates based in Portsmouth, NH, Boston, MA, Plano, TX and Indianapolis, IN.***

 **Job introduction:**

  

The US Retail Markets (USRM) **Data and Analytics Engineering** team is actively searching for a highly productive **Senior Data Engineer** for a distributed, dynamic agile team to serve as a technical expert designing, developing, analyzing & testing innovative data warehouse reporting solutions. This candidate will join an energetic and engaged Business Data Solutions Engineering team focused on delivering exceptional value to our PL Products business partners. You will work collaboratively in an agile squad to design and build data pipelines & workflows, ingest, curate & provision data workflows in a Cloud-based environment as well as own responsibility of thorough end-to-end testing.

  

This is a fast-paced environment providing rapid delivery for our business partners. You will be working in a highly collaborative environment that values speed and quality, with a strong desire to drive change and foster a positive work environment. You will have the opportunity to help lead this change with us as we grow this culture, mindset and capability.

 **We encourage you to apply if this interests you:**

* Work as ONE team committed to excellence.
* Model and promote a Data First attitude.
* Help advance Data Engineering operations into the future.
* Work with a modern data tech stack.

**About the job:**

* Work in a dynamic and exciting agile environment with Scrum Masters, Product Owners, and team members to develop creative data-driven solutions with our ETL pipeline that meet business and technical initiatives.
* Analyze, develop and execute data integration solutions, to manage the information lifecycle needs of an organization.
* Actively participates in and often leads peer development and code reviews within each Agile sprint, with focus on test driven development and Continuous Integration and Continuous Development (CICD).
* Designs and builds data provisioning workflows/pipelines, physical data schemas, extracts, data transformations, and data integrations and/or designs using ETL and API microservices.
* Builds data architecture and data applications (marts/warehouses) that enable reporting, analytics, data science, and data management and improve accessibility, efficiency, governance, processing, and quality of data.
* Improve speed to market by focusing on current data needs as well as building out the long-term strategic data solutions using AWS, Snowflake, SQL, Data Vault methodology, as well as other modern data technologies.
* Design and develop programs and tools to support ingestion, curation and provisioning of complex enterprise data to achieve analytics, reporting, and data science.
* Demonstrate open minded and collaborative approach to creating innovative technical solutions.
* Continuously learn to maintain strong knowledge of technology enablers.
* Mentor new and junior developers.
* Provide successful deployment and provisioning of data solutions to production or other required environments.
* Analyze complex technical problems and is expected to recommend process improvements that address complex technology gaps within a single business process and improve data reliability, quality, and efficiency.

**Qualifications*** Bachelor or Master`s degree in technical or business discipline or equivalent experience, technical degree preferred. Generally 5+ years of Data Engineering experience.
* Experience developing back end, data warehouse technology solutions.
* Knowledge of a variety of data platforms including Snowflake, Teradata, SQL, DB2 (Cloud based DB a plus).
* Experience with AWS (such as S3, Snowflake, Athena), Unix, Informatica (IDMC) and strong SQL skillset.
* Extensive knowledge of IT concepts, strategies, methodologies.
* Experience working with agile methodologies (Scrum, Kanban, XP) and cross-functional teams (Product Owners, Scrum Masters, Developers, Test Engineers).
* Well versed in diverse technologies and new technical architecture principles and concepts.
* Demonstrates leadership and active pursuit of optimizing CI/CD process and tools, testing frameworks and practices.
* Must be proactive, demonstrate initiative, and be a logical thinker.
* Must be team oriented with strong collaboration, prioritization, and adaptability skills required.
* Strong negotiation, facilitation and consensus building skills.
* Strong oral and written communication skills; presentation skills; Extensive knowledge of the following: IT concepts, strategies, methodologies.
* Extensive consultative skills, including the ability to understand and apply customer requirements, including drawing out unforeseen implications and making recommendations for design, the ability to define design reasoning, understanding potential impacts of design requirements
* Extensive understanding of backlog tracking, burndown metrics, and incremental delivery
* Strong collaboration, prioritization, and adaptability skills required.

 **Additional Qualifications:**

* Java, Ruby, NoSQL, Python development experience.
* Understanding of Cloud / Hybrid data architecture concepts.
* Understanding of insurance industry and products.
* Excited by trying new technology and learning new tools.

**About Us**
\\*\\*This position may have in-office requirements depending on candidate location.\\*\\*  

  

At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That's why we provide an environment focused on openness, inclusion, trust and respect. Here, you'll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession.  

  

Liberty Mutual has proudly been recognized as a ""Great Place to Work"" by Great Place to Work® US for the past several years. We were also selected as one of the ""100 Best Places to Work in IT"" on IDG's Insider Pro and Computerworld's 2020 list. For many years running, we have been named by Forbes as one of America's Best Employers for Women and one of America's Best Employers for New Graduates as well as one of America's Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusion  

  

We value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits  

  

Liberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran's status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.  

  

**Fair Chance Notices**

* California
* San Francisco
* Los Angeles
* Philadelphia","https://www.glassdoor.com/Overview/W-EI_IE2874.htm","","","","","","https://media.glassdoor.com/sql/2874/liberty-mutual-insurance-squarelogo-1550851957951.png","","",""
"1009480671619","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009480671619","","Data Engineer(Hybrid)","Smartfox LLC","Richardson, TX","","2024-10-10","direct_data","hourly",50.0,62.0,"USD",False,"","","","organic","","**Job Title: Data Engineer**

**Remote/Hybrid/In-Person: Hybrid (2 Days a week onsite Tuesday and Thursday)**

**Location: 2375 N Glenville Drive, Richardson, TX 75082**

**Duration: 6 Months - Potential to convert to FTE** 

**Resource's typical working day:**

* Prepare high-level ETL mapping specifications. Develop complex code data scripts (Primarily SQL) for ETL Troubleshoot & determine best resolution for data issues and anomalies
* Manage exploratory data analysis to support database and dashboard development, as well as advanced analytics efforts.
* Maintains technical knowledge by attending educational workshops; reviewing publications; establishing personal networks; in technical societies.
* Ensures operation of equipment by completing preventive maintenance requirements; following manufacturer's instructions; troubleshooting malfunctions; calling for repairs; evaluating new equipment and techniques.
* Contributes to team effort by accomplishing related results as needed.
* Determines changes in physical database by studying project requirements; identifying database characteristics, such as location, amount of space, and access method.
* Changes database system by coding database descriptions.
* Protects database by developing access system; specifying user level of access.
* Maintains user reference by writing and rewriting database descriptions.

**Years of Experience needed:** Typically has 3-5 years of relevant work experience.

**Level of Education:** Bachelor's degree (BA/BS) in a related field such as information systems, mathematics, or computer science or equivalent work experience

**Top Must have Skills:**

* Database Performance Tuning, Database Management, Requirements Analysis, Software Development Fundamentals, Problem Solving, Documentation Skills, Verbal Communication, Data Maintenance, Database Security, Promoting Process Improvement, System Administration.
* Advanced SQL skills - Adept at queries, report writing and presenting findings Expertise in Data Analysis, Data Profiling, and SQL Tuning Expertise in translating business requirements to project design, development, and execution.
* Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
* Ability to clearly communicate capabilities, opportunities, and recommendations to both technical and nontechnical audiences.
* Have a strong, pragmatic approach to leading architecture and development solutions, with a proven record in technology planning and delivery.
* Ability to prioritize and co-ordinate tasks efficiently ensuring all deadlines are met.
* Experience of managing product delivery is desirable Excellent interpersonal skills across all levels of the organization
* At least 3 years in an architectural or design capacity for 'large scale' enterprise systems.

Job Type: Contract

Pay: $50.00 - $62.00 per hour

Expected hours: 40.00 per week

Schedule:

* 8 hour shift

Application Question(s):

* We are looking for only local candidates. No relocation allowed !!
* We are accepting only USC & GC Candidates
* Only W2 !! No C2C

Education:

* Bachelor's (Required)

Experience:

* Data engineer: 3 years (Required)
* Data warehouse: 3 years (Required)
* SQL: 3 years (Required)
* ETL: 3 years (Required)

Ability to Commute:

* Richardson, TX 75082 (Required)

Work Location: In person","https://www.glassdoor.com/Overview/W-EI_IE9437345.htm","","","","","","","","",""
"1009481102923","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009481102923","","GCP Data Engineer","Umanist Staffing","Dallas, TX","","2024-10-10","direct_data","hourly",49.0,57.0,"USD",False,"","","","organic","","GCP Data Engineer


Overview:


The GCP Data Engineer plays a crucial role in designing, implementing, and managing data processing systems leveraging Google Cloud Platform (GCP) services. This position is essential for ensuring efficient data management, processing, and analysis to support the organization's data-driven decision-making processes and solutions.  

Key Responsibilities:

* Design, develop, and deploy GCP-based data processing systems and solutions.
* Implement scalable and reliable data pipelines for ingesting, processing, and storing large volumes of data.
* Optimize data storage and retrieval processes using GCP storage solutions.
* Collaborate with data scientists and analysts to understand data requirements and implement appropriate solutions.
* Ensure data integrity, security, and compliance with regulatory requirements.
* Monitor and troubleshoot data processing systems to ensure optimal performance and reliability.
* Develop and maintain documentation for data engineering processes and systems.
* Implement data governance best practices for data quality, lineage, and metadata management.
* Assist in the evaluation and selection of appropriate GCP services for specific data processing needs.
* Stay updated with GCP developments and recommend innovative solutions to improve data engineering processes.

  

Required Qualifications:

* Bachelor's or master's degree in Computer Science, Data Engineering, or related field.
* Proven experience in designing and implementing data processing systems on Google Cloud Platform.
* Proficiency in programming languages such as Python, Java, or Scala for data processing and ETL (Extract, Transform, Load) tasks.
* Strong understanding of big data technologies and frameworks, including Hadoop, Spark, and Kafka.
* Experience with GCP services such as BigQuery, Dataflow, Pub/Sub, and Dataproc.
* Expertise in SQL and database technologies for data manipulation and querying.
* Ability to troubleshoot and optimize data processing workflows for performance and cost-efficiency.
* Excellent communication skills and the ability to collaborate in cross-functional teams.
* Understanding of data governance principles and best practices.
* Familiarity with machine learning pipelines and model serving on GCP is a plus.
* Certifications in GCP data engineering or related areas are preferred.

Workplace Type


In-Office
Employment Type


Contract
Experience Level


Mid-Senior-Level
Hourly Compensation


USD 49 - 57
Work Experience (years)


7 - 9 years
Education


Bachelor's Degree
Skills


Hadoop


Sql


Big Data Technologies


Machine Learning Pipelines


Etl


Java


Spark


Data Engineering


Model Serving


Gcp


Kafka


Big Data


Data Governance


Database Technologies


Scala


Python","https://www.glassdoor.com/Overview/W-EI_IE8087320.htm","","","","","","https://media.glassdoor.com/sql/8087320/umanist-staffing-squareLogo-1670360096248.png","","",""
"1009481053496","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009481053496","","Cloud Data Engineer Solution Specialist","Deloitte","Dallas, TX","","2024-10-10","direct_data","yearly",93698.0,133539.0,"USD",False,"","","","organic","","Are you an experienced, passionate pioneer in technology - a solutions builder, a roll-up-your-sleeves technologist who wants a daily collaborative environment, think-tank feel and share new ideas with your colleagues - without the extensive demands of travel? If so, consider an opportunity with our US Delivery Center - we are breaking the mold of a typical Delivery Center.  

  

Our US Delivery Centers have been growing since 2014 with significant, continued growth on the horizon. Interested? Read more about our opportunity below ...  

  

**Work you'll do/Responsibilities**  

* Work with the team to evaluate business needs and priorities, liaise with key business partners and address team needs related to data systems and management.
* Translate business requirements into technical specifications; establish and define details, definitions, and requirements of applications, components and enhancements.
* Participate in project planning; identifying milestones, deliverables and resource requirements; tracks activities and task execution.
* Generate design, development, test plans, detailed functional specifications documents, user interface design, and process flow charts for execution of programming.
* Develop data pipelines / APIs using Python, SQL, potentially Spark and AWS, Azure or GCP Methods.
* Use an analytical, data-driven approach to drive a deep understanding of fast changing business.
* Build large-scale batch and real-time data pipelines with data processing frameworks in AWS, Azure or GCP cloud platform.
* Moving data from on-prem to cloud and cloud data conversions.

  

**The Team**  

  

Artificial Intelligence & Data Engineering:  

  

In this age of disruption, organizations need to navigate the future with confidence, embracing decision making with clear, data-driven choices that deliver enterprise value in a dynamic business environment.  

  

The Artificial Intelligence & Data Engineering team leverages the power of data, analytics, robotics, science and cognitive technologies to uncover hidden relationships from vast troves of data, generate insights, and inform decision-making. Together with the Strategy practice, our Strategy & Analytics portfolio helps clients transform their business by architecting organizational intelligence programs and differentiated strategies to win in their chosen markets.  

  

Artificial Intelligence & Data Engineering will work with our clients to:  

  

Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platforms.  

  

Leverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actions.  

  

Drive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvements.  

  

**Qualifications**  

  

**Required**  

* 3+ years of experience in data engineering with an emphasis on data analytics and reporting.
* 3+ years of experience with at least one of the following cloud platforms: Microsoft Azure, Amazon Web Services (AWS), Google Cloud Platform (GCP), others.
* 3+ years of experience in SQL, data transformations, statistical analysis, and troubleshooting across more than one Database Platform (Cassandra, MySQL, Snowflake, PostgreSQL, Redshift, Azure SQL Data Warehouse, Databricks, etc.).
* 3+ years of experience in the design and build of data extraction, transformation, and loading processes by writing custom data pipelines.
* 3+ years of experience with one or more of the follow scripting languages: Python, SQL, Kafka and/or other.
* 3+ years of experience designing and building solutions utilizing various Cloud services such as EC2, S3, EMR, Kinesis, RDS, Redshift/Spectrum, Lambda, Glue, Athena, API gateway, etc.
* Bachelor's degree, preferably in Computer Science, Information Technology, Computer Engineering, or related IT discipline, or equivalent experience
* Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future.
* Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve. This may include overnight travel.
* Must be able to obtain the required level of security clearance for this role
* Must live in a commutable distance (approximately 100-mile radius) to one of the following Delivery locations: Atlanta, GA; Charlotte, NC; Dallas, TX; Gilbert, AZ; Houston, TX; Lake Mary, FL; Mechanicsburg, PA; Philadelphia, PA with the ability to commute to assigned location for the day, without the need for overnight accommodations
* Expectation to co-locate in your designated Delivery location up to 30% of the time based on business needs. This may include a maximum of 10% overnight client/project travel

  

**Preferred**  

* AWS, Azure and/or Google Cloud Platform Certification.
* Master's degree or higher.
* Expertise in one or more programming languages, preferably Scala, PySpark and/or Python.
* Experience working with either a Map Reduce or an MPP system on any size/scale.
* Experience working with agile development methodologies such as Sprint and Scrum.
* Must be able to obtain the required level of security clearance for this role

  

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html  

  

#LI-JRK #engcamp2024","https://www.glassdoor.com/Overview/W-EI_IE2763.htm","","","","","","https://media.glassdoor.com/sql/2763/deloitte-squareLogo-1674210308592.png","","",""
"1009481140269","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009481140269","","Principal Data Engineer","Liberty Mutual","Plano, TX","","2024-10-10","direct_data","yearly",116700.0,218300.0,"USD",False,"","","","organic","","**Pay Philosophy**
The typical starting salary range for this role is determined by a number of factors including skills, experience, education, certifications and location. The full salary range for this role reflects the competitive labor market value for all employees in these positions across the national market and provides an opportunity to progress as employees grow and develop within the role. Some roles at Liberty Mutual have a corresponding compensation plan which may include commission and/or bonus earnings at rates that vary based on multiple factors set forth in the compensation plan for the role.

 **Description**Under general direction, acts as a technical expert who consults on highly complex projects. Responsible for the analysis, development and execution of complex data solutions, in order to manage the information lifecycle needs of an organization. Collects, integrates and analyzes organizational data with the purpose of drawing conclusions about that information. Develops, constructs, tests and maintains data architectures for data platform, database, analytical/reporting, or data science systems. Establishes and builds data systems including providing standards, policies, practice, procedures, governance and quality assurance for data deliverables. Recommends methods to improve data reliability, quality, and efficiency. Devises or modifies procedures to solve technical problems. Leads and directs the work of team members. May mentor junior team members.

 **Responsibilities**

  

Builds and designs complex data models and data architecture that improve accessibility, efficiency, governance and quality of data. Makes recommendations for how to improve data and drives those recommendations forward. Identifies business process improvements that address highly complex technology gaps within a single business process. Builds in-depth knowledge of technology enablers. Consult on highly complex technology enabled recommendations to address gaps within a single business process. Proactively identifies potential impact on business strategy. Documents existing processes, organizational structures, architectures and external systems. Consults on designing and developing of complex programs and tools to support ingestion, curation and provisioning of complex enterprise data to achieve analytics, reporting, and data science. Involved in and contributes to development and enhancement of solutions for gaps. Supports the Solutions Engineer in implementation. Support can include but is not limited to; cutover plans, post-implementation support, any issues/defects, transition planning, and knowledge sharing efforts.

**Qualifications*** Bachelor or Master`s degree in technical or business discipline or equivalent experience, technical degree preferred
* Generally 8+ years of professional experience
* In-depth knowledge of IT concepts, strategies and methodologies
* In-depth knowledge of diverse and emerging technologies and new architectural concepts and principles
* Knowledgeable in data engineering languages and tools; proficient in new and emerging technologies
* In-depth understanding of layered solutions and designs; in-depth understanding of shared data engineering concepts and product features, as well as security minded
* In-depth knowledge of business operations, objectives and strategies; in-depth understanding of global business and technology trends and the financial services industry
* Highly developed negotiation, consensus building & influencing skills, facilitation and the adaptability to respond to change quickly
* Highly developed oral and written communication skills; strong presentation skills
* Ability to effectively collaborate with all levels of the organization


Essential Skills:

* Expert knowledge of the ACORD XML canonical model.
* Experience with ACORD.org.
* Experience participating on XML governance.
* Expert in commercial insurance policy applications and their data uses.
* Expert understanding of data mapping methodologies, frameworks, and documentation.
* Experience with data mapping.

**About Us**
\\*\\*This position may have in-office requirements depending on candidate location.\\*\\*  

  

At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That's why we provide an environment focused on openness, inclusion, trust and respect. Here, you'll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession.  

  

Liberty Mutual has proudly been recognized as a ""Great Place to Work"" by Great Place to Work® US for the past several years. We were also selected as one of the ""100 Best Places to Work in IT"" on IDG's Insider Pro and Computerworld's 2020 list. For many years running, we have been named by Forbes as one of America's Best Employers for Women and one of America's Best Employers for New Graduates as well as one of America's Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusion  

  

We value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits  

  

Liberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran's status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.  

  

**Fair Chance Notices**

* California
* San Francisco
* Los Angeles
* Philadelphia","https://www.glassdoor.com/Overview/W-EI_IE2874.htm","","","","","","https://media.glassdoor.com/sql/2874/liberty-mutual-insurance-squarelogo-1550851957951.png","","",""
"1009480912622","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009480912622","","Senior Security Engineer","Umanist Staffing","Dallas, TX","","2024-10-10","direct_data","yearly",120000.0,140000.0,"USD",False,"","","","organic","","Job Description
Senior security professional with a firm understanding of cybersecurity principles and Google Cloud platform to work on threat modeling of various Google cloud services such as GKE, Cloud SQL, Cloud Storage etc. Using threat modeling, you will identify threats and specify mitigating controls that will directly reduce the risk of operating in the Google Cloud platform.

Responsibilities:* Threat Modeling using a documented process.
* Development of automation tools as required.
* Maintain a high standard of work in identifying threats and specifying mitigating controls.
* Attending to the lifecycle of identified threats and controls.
* Delivery of threat models and supporting tasks within existing timeframes.



Required Technical skills:* IT experience minimum of 10 years, with minimum a of 4 years in Cyber-Security/Information Security preferably in a highly regulated industry like financial services.
* Threat Modeling (STRIDE, PASTA, Attack trees, tooling, Attack).
* Identifying vulnerabilities using CWE or OWASP.
* Experience working in a cyber-security role.
* Extensive knowledge of Google cloud platform.
* Security practices pertaining to authentication, authorization, logging/monitoring, encryption, infrastructure security, network/segmentation.
* Operating systems and their hardening.
* Development concepts (such as: CICD, Pipelines, SDLC).
* Scripting languages, Infrastructure as Code (Terraform, CloudFormation).
* Operating in a DevOps / agile team structure.
* Understanding of Docker/K8S/serverless/helm.
* Design and review technical architectures.



Certifications:* Google Cloud Architect, Cloud Developer, Data Engineer, Network Engineer, etc.
* Google Professional Cloud Security Engineer.
* CISM, CISSP or any equivalent professional cyber security certification

Workplace Type


In-Office
Employment Type


Full-Time
Experience Level


Mid-Senior-Level
Annual Compensation


USD 120,000 - 140,000
Work Experience (years)


8 - 12 years
Education


Bachelor's Degree
Skills


Authorization


Network/Segmentation


Cism


Pipelines


Encryption


Cloud


Cicd


Cyber-Security


Cloud Developer


Google Cloud


Authentication


Scripting Languages


Infrastructure Security


Owasp


Threat Modeling


Infrastructure As Code


Docker


Network Engineer


Logging/Monitoring


Cissp


Google Professional Cloud Security Engineer


Devops


Sdlc


K8s


Agile Team Structure


Technical Architectures


Data Engineer


Cwe


Security


Operating Systems Hardening


Helm


Serverless


Google Cloud Architect


It Experience


Google Cloud Platform","https://www.glassdoor.com/Overview/W-EI_IE8087320.htm","","","","","","https://media.glassdoor.com/sql/8087320/umanist-staffing-squareLogo-1670360096248.png","","",""
"1009480536041","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009480536041","","Senior Security Engineer","Protellhirestaffingsolution.com","Dallas, TX","","2024-10-10","direct_data","yearly",130000.0,140000.0,"USD",False,"","","","organic","","Senior security professional with a firm understanding of cybersecurity principles and Google Cloud platform to work on threat modeling of various Google cloud services such as GKE, Cloud SQL, Cloud Storage etc. Using threat modeling, you will identify threats and specify mitigating controls that will directly reduce the risk of operating in the Google Cloud platform.

**Responsibilities:**

· Threat Modeling using a documented process.

· Development of automation tools as required.

· Maintain a high standard of work in identifying threats and specifying mitigating controls.

· Attending to the lifecycle of identified threats and controls.

· Delivery of threat models and supporting tasks within existing timeframes.

**Required Technical skills:**

· IT experience minimum of 10 years, with minimum a of 4 years in Cyber-Security/Information Security preferably in a highly regulated industry like financial services.

· Threat Modeling (STRIDE, PASTA, Attack trees, tooling, Attack).

· Identifying vulnerabilities using CWE or OWASP.

· Experience working in a cyber-security role.

· Extensive knowledge of Google cloud platform.

· Security practices pertaining to authentication, authorization, logging/monitoring, encryption, infrastructure security, network/segmentation.

· Operating systems and their hardening.

· Development concepts (such as: CICD, Pipelines, SDLC).

· Scripting languages, Infrastructure as Code (Terraform, CloudFormation).

· Operating in a DevOps / agile team structure.

· Understanding of Docker/K8S/serverless/helm.

· Design and review technical architectures.

**Certifications:**

· Google Cloud Architect, Cloud Developer, Data Engineer, Network Engineer, etc.

· Google Professional Cloud Security Engineer.

· CISM, CISSP or any equivalent professional cyber security certification

Job Type: Full-time

Pay: $130,000.00 - $140,000.00 per year

Benefits:

* 401(k)
* 401(k) matching
* Dental insurance
* Health insurance
* Life insurance
* Vision insurance

Schedule:

* 8 hour shift

Experience:

* GKE: 3 years (Required)
* Google cloud services: 4 years (Required)
* Information security: 7 years (Required)
* DevOps: 1 year (Required)

License/Certification:

* Google Professional Cloud Security Engineer (Required)
* CISM (Required)
* CISSP (Required)

Work Location: On the road","","","","","","","","","",""
"1009478963090","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009478963090","","Lead Product Software Engineer - Lead Cloud Data Engineer","Wolters Kluwer","Coppell, TX","","2024-10-09","direct_data","yearly",109563.0,142327.0,"USD",False,"","","","organic","","The Lead Cloud Data Engineer in Tax and Accounting innovative and fast-growing Global Audit team is responsible for designing, implementing end to end solutions in Azure Enterprise Data Lake and optimizing data pipelines, ensuring the availability, performance, scalability and security of large-scale data processing systems. This role requires deep understanding of big data technologies, data architecture, infrastructure, CI/CD and data engineering best practices. Experience with Unity Catalog is a bonus. The Lead Cloud Data Engineer will work closely with architects, leads and other stakeholders to support data driven decision making processes.
Experience Required* Minimum 8+ years of experience with 3+ years as a Lead Data Engineer or related role
* 5+ years of demonstrated experience in developing Big Data solutions that support business analytics and data science teams
* 3-5 years of proficient Data ingestion end-to-end implementation of projects in Azure Enterprise Data Lake, Azure Functions, Databricks, Blob Storage, Cosmos DB, Azure stream analytics, Python, SQL
* Extensive hands-on experience implementing Lake house architecture using Data bricks Data Engineering platform, SQL Analytics, Delta Lake, and Unity Catalog
* Good understanding of spark architecture with Databricks structured streaming, setting up Azure with Databricks, managing clusters in Databricks
* Experienced in DevOps and deployment automations with Azure DevOps - ARM, YAML, Terraform
* Strong knowledge and hands-on experience in SQL, Unix shell scripting
* Ability to research latest trends and propose advanced tooling/solutions for Cloud Data Lake & Data Science platforms
* Experience with business intelligence and analytics tools such as OBIEE, PowerBI or Tableau
* Experience with Unity Catalog preferred
* Collaborate applications teams/Business users to develop new pipelines with Cloud data migration methodologies and processes including tools like Azure Data Factory, Event Hub, etc
* Ensure data security and compliance.


Roles & Responsibilities* Lead and implement design of data schemas, drive cloud data lake platform design decisions and development standards and maintain data pipelines for data ingestion, processing, and transformation in Azure
* Extract, transform and load from sources system to Azure Data Storage services using a combination of Azure Data factory, Azure Blob Storage, T-SQL, Pyspark and Azure Databricks
* Drive analysis, architecture, design, governance and development of data warehouse, data lake, and business intelligence solutions
* Integrate data from various sources, ensuring data quality, consistency and reliability.
* Define data requirements, gather and mine large scale structured and unstructured data, and validate data using various tools in a cloud environment.
* Manage and optimize Azure Enterprise data Lake for efficient data storge and processing.
* Develop and optimize ETL processes using Databricks and related tools like Apache Spark
* Implementing data validation and cleansing procedures will ensure the quality, integrity, and dependability of the data.


Benefits:
A comprehensive benefits package that begins your first day of employment. Additional Information: Wolters Kluwer offers great benefits and programs to help meet your needs and balance your work and personal life, including Medical, Dental, & Vision Plans, 401(k), FSA/HSA, Commuter Benefits, Tuition Assistance Plan, Vacation and Sick Time, and Paid Parental Leave. Full details of our benefits are available - https://www.mywolterskluwerbenefits.com/index.html
Diversity Matters
Wolters Kluwer strives for an inclusive company culture in which we attract, develop, and retain diverse talent to achieve our strategy. As a global company, having a diverse workforce is of the utmost importance. We've been recognized by employees as a European Diversity Leader in the Financial Times, as one of Forbes America’s Best Employers for Diversity in 2022, 2021 and 2020 and as one of Forbes America’s Best Employers for Women in 2021, 2020, 2019 and 2018. In 2020, we placed third in the Female Board Index, and were recognized by the European Women on Boards Gender Diversity Index. Wolters Kluwer and all of our subsidiaries, divisions and customer/departments is an Equal Opportunity / Affirmative Action employer.","https://www.glassdoor.com/Overview/W-EI_IE10497.htm","","","","","","https://media.glassdoor.com/sql/10497/wolters-kluwer-squareLogo-1617149943307.png","","",""
"1009478993715","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009478993715","","Data Engineer","NTT DATA","Dallas, TX","","2024-10-09","direct_data","yearly",87946.0,114691.0,"USD",False,"","","","organic","","Company Overview: Req ID: 295521 NTT DATA strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now.  

  

We are currently seeking a Data Engineer to join our team in McKinney, Texas (US-TX), United States (US).  

  

**Job Summary:** We are looking for an experienced and talented technical individual to join our team as Cloud DevOps Engineer to support our Cloud Data Management and Advanced Analytics platforms. In this role, a person will work with data services, data analysts and data scientist teams to help organization build out secure, scalable, fault-tolerant and high performing cloud based architecture and make data-driven decisions.  

  

Primary Duties & Responsibilties
* Design, implement, and support Cloud Data Management and Advanced Analytics platforms.
* Provide technological guidance on Data Lake and Enterprise Data Warehouse design, development, implementation and monitoring.
* Understand, Design and Implement Data Security around cloud infrastructures.
* Provide support and guidance to Data Services and other application development teams on various AWS Products.
* Work with leadership on process improvement and strategic initiatives on Cloud Platform.


**Knowledge, Skills, & Abilities**
* **Strong coding and scripting experience with Python**
* **Strong knowledge in SQL**
* **Expertise in Redshift and AWS**
* **Experience in Python**
* Extensive hands-on experience including design and implementation across broad range of Amazon Web Services (AWS).
* Working knowledge with primary AWS Services like EC2, EBS, S3, Lambda, Batch, Glue, Athena CloudWatch, CloudTrail, ECS, ECR, EMR, IAM, SNS etc.
* Good understanding of implementing datalake and data warehouse in Cloud.
* Experience in creating and deploying CloudFormation Templates (CFTs)
* Solid understanding of various Data Management tools available in AWS

  

NTT DATA is a $30+ billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long-term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are also one of the leading providers of digital and AI infrastructure in the world. NTT DATA is part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at us.nttdata.com.  

  

NTT DATA is an equal opportunity employer and considers all applicants without regarding to race, color, religion, citizenship, national origin, ancestry, age, sex, sexual orientation, gender identity, genetic information, physical or mental disability, veteran or marital status, or any other characteristic protected by law. We are committed to creating a diverse and inclusive environment for all employees. If you need assistance or an accommodation due to a disability, please inform your recruiter so that we may connect you with the appropriate team.","https://www.glassdoor.com/Overview/W-EI_IE7649.htm","","","","","","https://media.glassdoor.com/sql/7649/ntt-data-squareLogo-1711347206855.png","","",""
"1009478067512","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009478067512","","AWS Data Engineer","Cognizant","Plano, TX","","2024-10-08","direct_data","yearly",75000.0,120000.0,"USD",False,"","","","organic","","### **About Cognizant’s AI Practice**


Digital technologies, including analytics and AI, give companies a once-in-a-generation opportunity to perform orders of magnitude better than ever before. However, clients need new business models built from analyzing customers and business operations at every angle to really understand them.


With the power to apply artificial intelligence and data science to business decisions via enterprise data management solutions, we help leading companies prototype, refine, validate, and scale the most desirable products and delivery models to enterprise scale within weeks.


### **We are Cognizant**

\\***You must be legally authorized to work in United States without the need of employer sponsorship, now or at any time in the future \\***

### **Job Summary**


We are seeking an expert enginedemonstrated abilityperience to join our diverse team. The ideal candidate will have a strong background in Informatica Control M Pyspark AWS Glue Studio AWS Glue ETL and Amazon S3. This hybrid role requires a proactive individual who can craft and implement robust data solutions. The position offers a day shift with no travel requirements.


### **Responsibilities**


* Design and implement scalable data architectures using AWS Glue Studio and AWS Glue ETL.
* Develop and maintain data pipelines to ensure efficient data processing and storage.
* Use Python to build and optimize ETL scripts for data transformation.
* Coordinate the integration of Amazon S3 for data storage and retrieval.
* Collaborate with multi-functional teams to capture and analyze data requirements.
* Ensure data quality and integrity through rigorous testing and validation.
* Provide technical mentorship and support to junior team members.
* Monitor and troubleshoot data workflows to ensure flawless operations.
* Implement best practices for data security and compliance.
* Conduct performance tuning and optimization of data processes.
* Stay updated with the latest industry trends and technologies.
* Supply to the continuous improvement of data architecture and processes.
* Document technical specifications and project plans for future reference.

### **Qualifications**


* Possess a strong proficiency in Python for data manipulation and ETL processes.
* Demonstrate extensive experience with AWS Glue Studio and AWS Glue ETL.
* Have a deep understanding of Amazon S3 for data storage solutions.
* Exhibit excellent problem-solving skills and attention to detail.
* Show ability to work effectively in a hybrid work model.
* Display strong communication skills for collaboration with team members.

### **Certifications Required**


AWS Certified Solutions Architect AWS Certified Big Data - Specialty


### **Salary and Other Compensation:**


Applications will be accepted until 10/24/2024.


The annual salary for this position is between $75,000-$120,000 depending on the experience and other qualifications of the successful candidate.


This position is also eligible for Cognizant’s discretionary annual incentive program, based on performance and subject to the terms of Cognizant’s applicable plans.


### **Benefits:**


Cognizant offers the following benefits for this position, subject to applicable eligibility requirements:


* Medical/Dental/Vision/Life Insurance
* Paid holidays plus Paid Time Off
* Long-term/Short-term Disability
* Paid Parental Leave
* Employee Stock Purchase Plan

### **Disclaimer:**


The salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law.","https://www.glassdoor.com/Overview/W-EI_IE8014.htm","","","","","","https://media.glassdoor.com/sql/8014/cognizant-technology-solutions-squareLogo-1651131366751.png","","",""
"1009477470381","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009477470381","","DATA ENGINEER III – BUSINESS INTELLIGENCE","Frost Bank","Richardson, TX","","2024-10-08","direct_data","yearly",97727.0,128830.0,"USD",False,"","","","organic","","***It’s about putting our best to the test.***

Are you described as someone with an inquisitive mind and an innovative personality? Are you never satisfied with good enough? Does solving complex problems and ensuring top-quality systems excite you? If so, being a Data Engineer III - Business Intelligence with Frost could be for you.


At Frost, it’s about more than a job. It’s about having a flourishing career where you can thrive, both in and out of work. At Frost, we’re committed to fostering an environment that reflects our values and encourages team members to be the best they can be. In joining our adaptable, integrity-driven team, you’ll become part of Frost’s over 150-year legacy of providing unparalleled banking services.

**Who you are:**

As a **Data Engineer III - Business Intelligence**, *you* will lead the development and implementation of reporting and analytics dashboards. You’ll play an important role in designing and building business intelligence solutions. You’ll use your strong problem-solving skills to ensure that the systems are performing optimally and meet our high standards. You believe in effective communication and will have the opportunity to address potential problems and solutions to complex issues.

**What you’ll do****:**

* Develop views/reports/cubes to support complex and critical BI solutions.
* Perform Ad Hoc data requests for business users and Executive Management as needed
* Assist BI management in working with business sponsors and Executive Management to support key initiatives
* Work with BI/Data Warehouse Analysts and ETL developers to understand requirements, sources of data, and transformation rules
* Assist in establishing standards for the design, coding, and testing of deliverables
* Develop and enforce data governance policies and standards
* Provide guidance to other Data Engineers as needed
* Stay up to date with industry trends and new technologies in data analytics
* Always take action using integrity, caring, and excellence to achieve all-win outcomes

**What you’ll need:**

* Bachelor's degree in Computer Science, Information Technology, or related field
* 4+ Years of experience as a Business Intelligence Analyst, Developer or in a related role
* Strong knowledge of Cognos Analytics and Tableau tools
* Advanced understanding of database technologies such as SQL and NoSQL
* Knowledge of data modeling and schema design
* Strong problem-solving and analytical skills
* Excellent written and verbal communication skills

**Our Benefits:**


At Frost, we care about your health, your family, and your future and strive to have our benefits reflect that. This includes:

* Medical, dental, vision, long-term disability, and life insurance
* 401(k) matching
* Generous holiday and paid time off schedule
* Tuition reimbursement
* Extensive health and wellness programs, including our Employee Assistance Program
* Referral bonus program + more!


Since 1868, Frost has dedicated their expertise to provide exceptional banking, investment, and insurance services to businesses and individuals throughout Texas. Frost is one of the 50 largest U.S. banks by asset size and is a leader in banking customer satisfaction. At Frost, it’s about being part of something bigger. If this sounds like you, we encourage you to apply and see what’s possible at Frost.


#LI-MF1


#LI-Hybrid","https://www.glassdoor.com/Overview/W-EI_IE1311.htm","","","","","","https://media.glassdoor.com/sql/1311/cullen-frost-bankers-squarelogo-1386890427147.png","","",""
"1009474722367","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009474722367","","Sr. Azure Data Engineer","Nuvem","Plano, TX","","2024-10-05","direct_data","yearly",115000.0,150000.0,"USD",False,"","","","organic","","Description:

 As the Sr Azure Data Engineer, you will focus on the continuous delivery of cloud-based ETL/ELT data processes and implementations. The ideal candidate will have the necessary technology and communication skills to manage hands-on highly visible and complex projects from start to finish. This role requires proficiency with developing realistic project plans to meet delivery objectives and the ability to maintain and establish required service levels. You will be a part of a fast-paced, entrepreneurial environment, which thrives on delivering transformational solutions and maximizing value to their stakeholders. As a participant of the cloud transformation process, you must be passionate about data, be a change agent and mentor, and a strong collaborator with the various business and technology stake holders. **Hybrid Role – 3 days in office (T-TH)**

* Data sourcing and source system analysis.
* Implement and build data pipelines for a data warehouse using Azure Data Engineering Stack – Adeptia (Third Party ETL/ELT tool), Azure Data Factory, Azure Synapse and ADLS.
* Combine technical expertise and problem-solving passion to work closely with clients, turning complex ideas into end-to-end solutions that transform our business offerings.
* Lead, design, develop and deliver large-scale data systems, data processing and data transformation projects that deliver business value for clients.
* Conduct technical feasibility assessments and provide project estimates for the design and development of the solution.
* Provide technical inputs to agile processes, such as user story, and task definition to resolve issues and remove barriers throughout the lifecycle of client engagements.
* Automate data platform operations and manage the post-production system and processes.
* Mentor, help and grow junior team members.
* Test, plan, creation and test programming using automated testing frameworks, data validation and quality frameworks, and data lineage frameworks.


EEO


Requirements:
* Bachelor’s or Master’s degree in Math, Statistics, Economics, Computer Science, or any other quantitative field.
* 5+ years of experience with data integration, and database technologies, including NoSQL, SQL Server, Azure SQL DB, Postgres, Cosmos DB’s etc.
* 5+ years of experience with Azure Cloud PaaS/SaaS solutions and managed services serverless technologies, including Azure Data Factory, Synapse Analytics and ADLS
* 5+ years of experience in a role encompassing industry standard ETL development techniques and implementation of end-to-end data pipelines.
* Experience with data analysis and profiling of source data while developing or
* Experience in data warehousing methodologies and dimensional data modeling.
* Experience working with Azure DevOps code repositories and continuous integration and continuous delivery.
* Hands-on experience with Azure Data Engineering Stack - ADF, Synapse, SQL, Data Lakehouse, Python Notebooks, Microsoft Fabrics
* Hands on knowledge of data validation, cleansing, transformation, consolidation, de-duplication, aggregation, de-aggregation, and enrichment

**Preferred:**

* Coding experience: Python, C#, PowerShell for Data analysis purpose
* Experience with reporting data visualization tools such as Power BI or Tableau
* Exposure to MDM and metadata management including data catalogs using Microsoft Purview

**It will be a plus:**

* Knowledge of HIPAA and SOC2
* HealthCare domain knowledge","https://www.glassdoor.com/Overview/W-EI_IE1744927.htm","","","","","","https://media.glassdoor.com/sql/1744927/340basics-squarelogo-1514985872726.png","","",""
"1009475253242","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009475253242","","IBP Sustainment Engineer","PepsiCo","Plano, TX","","2024-10-05","direct_data","yearly",102800.0,172100.0,"USD",False,"","","","organic","","Overview:

PepsiCo’s Sustain & Operations team, as part of the Digital Products and Applications (DPA) organization, delivers and sustains digital products across Strategy and Transformation’s core priorities to accelerate PepsiCo’s digital transformation. One the key remits of this team within the organization is to drive proactive risk management, improve data workflow automation and operational excellence of digital products by ensuring an optimal end-user experience through timely resolution of incidents and application downtime.
Responsibilities:
* Report directly to Sustain Lead and partner with our Data & Analytics team leadership on ITSM & SDLC ways of working
* Provide advanced technical support for complex data integration issues & root cause analysis.
* Act as 1st layer of escalation in response to data incidents & requests to support Sustainment and Operations Leadership
* Partner with the Data Analytics capabilities team to review all data interface solutions, data flows, proactive monitoring, configuration, thresholds and timings
* Ensure a data run book is documented and up to date and accessible for all support team members during triage and for onboarding purposes
* Escalate issues to & from external Capability & Sector Deployment teams, as necessary.
* Identify opportunities for process improvements and work with team to implement changes to enhance efficiency and customer satisfaction.
* Stay updated on industry trends and advancements in application support technologies.
* Review the service reports in accordance with SLA agreements partnering with the CSM
* Drive standard support processes and best practices to enhance service quality partnering with external
* Capability teams' guidance
* Act as a liaison between DP&A Sustain & Operations teams to reduce obstacles and improve visibility on external risks
* Act as a liaison between Capabilities & Sector Deployment teams to escalate and reduce global risks or respond to priority incidents (MIMs)
* Lead discussions pertaining to Service Requests requiring changes to current Production environment with Data Leads & Product teams
* Plan and monitor smooth transition of data interfaces from Hypercare to Production Support (Transition to Sustain).
* Partner with Engineering Teams Release Manager to review Hypercare Checklist
* Participate and assist in driving Quality Assurance activities where applicable
* Drive the audit and alignment of the Hypercare Checklist and confirmed completed successfully with Sustainment Manager
* Review the strategy and planning of system maintenance and updates aligned with global/sector planned downtime calendars
* Review impact and assessment of all planned maintenance across applications and shared capabilities with Operations Lead
* Review all vendor management agreements & partner with Data Management to resolve issues or improve relationship
* Ensure planned service requests are executed by partner Capability teams in a timely manner to prepare future deployment readiness across all environments in partnership with Sustain Lead &
* Operations Lead
* Review and validate Service Level reporting meets SLAs
* Celebrate success with SMILES awards or providing positive feedback to vendors & peers
* Share bright and hot spots with Sustain Lead that require celebration or attention
* Drive ideation of increased monitoring in existing or future observability reporting solutions
* Assist in the data capture and validation for Executive Summary reports on Sustain & Operations team standard KPIs using dashboards

**Compensation and Benefits:**  

* The expected compensation range for this position is between $102,800 - $172,100.
* Location, confirmed job-related skills, experience, and education will be considered in setting actual starting salary. Your recruiter can share more about the specific salary range during the hiring process.
* Bonus based on performance and eligibility target payout is 12% of annual salary paid out annually.
* Paid time off subject to eligibility, including paid parental leave, vacation, sick, and bereavement.
* In addition to salary, PepsiCo offers a comprehensive benefits package to support our employees and their families, subject to elections and eligibility: Medical, Dental, Vision, Disability, Health, and Dependent Care Reimbursement Accounts, Employee Assistance Program (EAP), Insurance (Accident, Group Legal, Life), Defined Contribution Retirement Plan.

Qualifications:
* 8 years of work experience, or 3-5 years of experience as a Data Engineer, Data Analytics Specialist, Data Steward, Data Scientist, or Data Architect, either in CPG industry or with a Top-Tier consulting firm
* The ideal Engineer will be highly quantitative, have great judgment, able to connect dots across workstreams, and efficiently work cross-functionally across teams to ensure data solutions are meeting customer/end-user expectations
* Bachelors degree required
* The candidate will take a pragmatic approach resolving data related incidents, including the ability to triangulate root causes and work effectively with external and internal teams to meet objectives.
* Exceptional business relationship skills including the ability to communicate effectively both internally and externally. You can communicate complex technical data to a non-technical person in a concise, clear, and easily understood manner.
* A firm understanding of SRE (Software Reliability Engineering) and IT Service Management (ITSM) processes with a track record for monitoring and triaging software incidents. You recognize the difference between resolving incidents, providing a seamless customer/end-user experience and proactively identifying and mitigating areas of risk
* Experience in leading high-performing teams
* Deep hands-on technical expertise, excellent verbal and written communication skills
* Sharp analytical abilities and proven process engineering & data analytical dashboarding skills

**Differentiating Competencies Required** **Driving for Results:** Demonstrates perseverance and resilience in the pursuit of goals. Confronts and works to resolve tough issues. Exhibits a “can-do” attitude and a willingness to take on significant challenges **Decision Making:** Quickly analyses complex problems to find actionable, pragmatic solutions. Sees connections in data, events, trends, etc. Consistently works against the right priorities **Collaborating:** Collaborates well with others to deliver results. Keeps others informed so there are no unnecessary surprises. Effectively listens to and understands what other people are saying.
  

Communicating and Influencing: Ability to build convincing, persuasive, and logical storyboards. Strong executive presence. Able to communicate effectively and succinctly, both verbally and on paper. **Motivating and Inspiring Others:** Demonstrates a sense of passion, enjoyment, and pride about their work. Demonstrates a positive attitude in the workplace. Embraces and adapts well to change. Creates a work environment that makes work rewarding and enjoyable. **Technical Knowledge and Skills:** Strong ServiceNow, Terraform, Octopus, AKS, Python, AppDynamics/Datadog/ELK Stack, Pager Duty or other AIOps toolsets skillsets.
>:

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.  

PepsiCo is an Equal Opportunity Employer: Female / Minority / Disability / Protected Veteran / Sexual Orientation / Gender Identity  

If you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.  

 Please view our Pay Transparency Statement","https://www.glassdoor.com/Overview/W-EI_IE522.htm","","","","","","https://media.glassdoor.com/sql/522/pepsico-squareLogo-1684858464866.png","","",""
"1009474457022","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009474457022","","Senior Data Engineer","VIZIO, Inc.","Dallas, TX","","2024-10-05","direct_data","yearly",110000.0,142000.0,"USD",False,"","","","organic","","About the Team:

We are seeking an enthusiastic Senior Data Engineer to help build the next generation of data infrastructure at Vizio. This role will develop and maintain core infrastructure critical to optimizing our data systems and platforms. This is an individual contributor position and will report directly to the Manager of Data Engineering. We are a close-knit team, focused on solving challenging problems that make a difference in our business. We concentrate on high-impact, high-value development, and in this role, you’ll be delivering the software that helps us grow. We pride ourselves on working in a collaborative environment, and to do so we are in our Denver and Dallas offices 5 days a week.  


What You Will Do:
**TOP 5 JOB RESPONSIBILITIES:**

* **Research and Design:** Research industry-leading technologies as part of design and project construction.
* **Collaboration:** Working with stakeholders including data, product and executive teams and assisting them with data-related technical issues.
* **Implementation:** Building required infrastructure for optimal extraction, transformation, and loading of data from various data sources while supporting our CICD process.
* **Analytical Tools:** Knowledge on analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including operational efficiency.
* **Review:** Regularly review team processes to identify areas of improvement, offer solutions, and increase team success and positive workplace culture.

**WHAT SUCCESS LOOKS LIKE:**

**By 3 Months…** You are up to date on the ad tech industry and the role that your team plays in achieving business objectives.


**By 6 months**… You successfully complete tasks critical to delivering the team's quarterly initiatives while contributing unique perspectives to the design of future projects.

  



**CORE COMPETENCIES:**

* You are motivated.
* You are a self-starter.
* You are a team player.
* You have excellent communication skills.


About You:
* 5+ years of professional experience as a Data Engineer
* Experience with Cloud Services (AWS/GCP/Azure)
* Experience working in environments with multiple development languages (Python/Java)
* Familiarity and experience using data warehousing solutions.
* CI/Automation testing experience
* Agile or Scrum SDLC experience
* Bachelor’s degree in CS or a related field required.


About VIZIO:
**We are Beautifully Simple.**
Headquartered in Irvine, California, VIZIO is a leading HDTV brand in America and the #1 Sound Bar Brand in America. VIZIO's mission is to deliver high performance, smarter products with the latest innovations at a significant savings that we can pass along to our consumers. Our loyal following and industry-wide praise continues to grow as we redefine what it means to be smart.  

VIZIO, Inc. is an Equal Opportunity Employer committed to diversity in the workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, gender expression, national origin, protected veteran status, or any other basis protected by applicable law, and will not be discriminated against on the basis of disability.  

We do not accept unsolicited agency resumes. We will not pay fees to any third-party agency, outside recruiter or firm without a mutually agreed-upon contract and will not be responsible for any agency fees associated with unsolicited resumes. Unsolicited resumes will be considered our property and will be processed accordingly. **For Colorado-based employment:** The target salary range is $110,000 - $142,000. In addition to base salary, the compensation package also includes eligibility for an annual bonus, as well as equity and a range of medical, dental, vision and other benefits.","https://www.glassdoor.com/Overview/W-EI_IE100251.htm","","","","","","https://media.glassdoor.com/sql/100251/vizio-squareLogo-1617230256940.png","","",""
"1009473039562","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009473039562","","Senior Software Engineer Big Data Tooling & API Development","Wells Fargo","Dallas, TX","","2024-10-04","direct_data","yearly",118180.0,152198.0,"USD",False,"","","","organic","","**About this role:**  

  

Wells Fargo is seeking a Senior Big Data Engineer in the role of a Big Data Tooling & API Development Software Engineer within its Risk Development organization  

  

**Description:**  

  

At Wells Fargo, we are looking for talented people who will put our customers at the center of everything we do. We are seeking candidates who embrace diversity, equity, and inclusion in a workplace where everyone feels valued and inspired.  

  

Help us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.  

  

Technology sets IT strategy; enhances the design, development, and operations of our systems; optimizes the Wells Fargo infrastructure; provides information security; and enables Wells Fargo global customers to have 24 hours a day, 7 days a week banking access through in-branch, online, ATMs, and other channels.  

  

Our mission is to deliver stable, secure, scalable, and innovative services at speeds that delight and satisfy our customers and unleash the skills potential of our employees.  

  

The EFT RISK & INTERNAL AUDIT group provides technology solutions and support for Risk, Audit, Finance, Marketing, Human Resources, Corporate Properties, and Stakeholder Relations business lines. In addition, EFT RISK & INTERNAL AUDIT provides unique technology solutions and innovation for Wells Fargo Technology, Enterprise Shared Services, and Enterprise Data Management. This combined portfolio of applications and tools are continually engineered to meet the challenges of stability, security, scalability, and speed.  

  

Within EFT RISK & INTERNAL AUDIT this group helps all Wells Fargo businesses identify and manage risk. We help our management and Board of Directors identify and monitor risks that may affect multiple lines of business and take appropriate action when business activities exceed the risk tolerance of the company.  

  

The Risk Data management Services group is seeking a Senior Big Data Engineer (Sr. Specialty Software Engineer) to work on building and supporting the Big Data Platform development that build inhouse tools and utilities for low code/ no code frameworks for tenants. The position will offer the opportunity to work on the latest open-stack technologies in Big Data / Java services universe.
  

  

We make extensive use of use Spark, Rest API's, Django to develop and maintain an extensive Framework to enable self-service development.  

  

**Responsibilities include:*** Standing up cutting-edge analytical capabilities, leveraging automation, cognitive and science-based techniques to manage data and models, and drive operational efficiency by offering continuous insights and improvements.
* Help in design and implementation of algorithms and tools for analytics and data scientist teams.
* Use a variety of languages, tools, and frameworks to marry data and systems together.
* Collaborate with modelers, developers, DevOps, and project managers on meeting project goals.
* Strong understanding of Python code CI/CD deployment and test automation suites.
* Drive a culture of automation, test coverage and architect for Micro Services, API, Cloud Native and Headless Architecture - Decoupling the front ends and backends of the technology stack.

**Required Qualifications*** 10+ years of software engineering experience
* 6 + years of Scala or Java experience
* 3+ years of RESTful API design and development experience
* 5+ years of experience with Big Data or Hadoop tools such as Spark, Hive, Kafka, and Map
* 2+ years of experience with building, deploying, and securing cloud platforms
* Solid understanding of distributed computing.
* Strong skills in big data, PySpark, HDFS and distributed computing.
* Experience in creating APIs using Java and Python
* Prior banking domain skills and depth knowledge in risk & finance forecasting domain

**Desired Qualifications*** A Master's degree or higher in computer science or finance
* A professional certification in technology
* Basic knowledge of industry regulations related to building technological solutions
* Knowledge and understanding of DevOps principles
* Should have leadership skills to drive work stream from technical aspects
* Should have command knowledge on story estimations, design reviews, code reviews, quality code delivery
* 5+ year of Database experience
* 2+ years of Kubernetes experience

**Job Expectations*** Ability to travel up to 10% of the time

**Posting End Date:**
  

24 Oct 2024  

**\\*Job posting may come down early due to volume of applicants.**
  

  

**We Value Diversity**  

  

At Wells Fargo, we believe in diversity, equity and inclusion in the workplace; accordingly, we welcome applications for employment from all qualified candidates, regardless of race, color, gender, national origin, religion, age, sexual orientation, gender identity, gender expression, genetic information, individuals with disabilities, pregnancy, marital status, status as a protected veteran or any other status protected by applicable law.  

  

Employees support our focus on building strong customer relationships balanced with a strong risk mitigating and compliance-driven culture which firmly establishes those disciplines as critical to the success of our customers and company. They are accountable for execution of all applicable risk programs (Credit, Market, Financial Crimes, Operational, Regulatory Compliance), which includes effectively following and adhering to applicable Wells Fargo policies and procedures, appropriately fulfilling risk and compliance obligations, timely and effective escalation and remediation of issues, and making sound risk decisions. There is emphasis on proactive monitoring, governance, risk identification and escalation, as well as making sound risk decisions commensurate with the business unit's risk appetite and all risk and compliance program requirements.  

  

Candidates applying to job openings posted in US: All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other legally protected characteristic.  

  

Candidates applying to job openings posted in Canada: Applications for employment are encouraged from all qualified candidates, including women, persons with disabilities, aboriginal peoples and visible minorities. Accommodation for applicants with disabilities is available upon request in connection with the recruitment process.  

  

**Applicants with Disabilities**  

  

To request a medical accommodation during the application or interview process, visit Disability Inclusion at Wells Fargo .  

  

**Drug and Alcohol Policy**  

  

Wells Fargo maintains a drug free workplace. Please see our Drug and Alcohol Policy to learn more.  

  

**Wells Fargo Recruitment and Hiring Requirements:**  

  

a. Third-Party recordings are prohibited unless authorized by Wells Fargo.  

  

b. Wells Fargo requires you to directly represent your own experiences during the recruiting and hiring process.","https://www.glassdoor.com/Overview/W-EI_IE8876.htm","","","","","","https://media.glassdoor.com/sql/8876/wells-fargo-squarelogo-1569533783558.png","","",""
"1009471329382","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009471329382","","AWS Architect","Cognizant","Coppell, TX","","2024-10-03","direct_data","yearly",101000.0,160000.0,"USD",False,"","","","organic","","### **We are Cognizant Artificial Intelligence**


Digital technologies, including analytics and AI, give companies a once-in-a-generation opportunity to perform orders of magnitude better than ever before! But clients need new business models built from analyzing customers and business operations at every angle to really understand them. With the power to apply artificial intelligence and data science to business decisions via enterprise data management solutions, we help leading companies prototype, refine, validate and scale the most desirable products and delivery models to enterprise scale within weeks


**\\*This role is not able to offer visa transfer or sponsorship now or in the future\\***


### **Location - Remote**


We are seeking a highly experienced Sr. Architect with 14 to 18 years of experience to join our team. The ideal candidate will have extensive expertise in Redshift PySpark Apache Hadoop AWS Glue and AWS Big Data. Experience in Property & Casualty Insurance is a plus. You will play a crucial role in designing and implementing scalable data solutions that drive our business forward.


### **Responsibilities**


* Lead the design and implementation of scalable data architectures using Redshift PySpark Apache Hadoop AWS Glue and AWS Big Data.
* Project experience in hadoop to AWS migration is preferable
* Oversee the development and deployment of data pipelines to ensure efficient data processing and storage.
* Provide technical guidance and mentorship to junior team members to foster their growth and development.
* Collaborate with multi-functional teams to understand business requirements and translate them into technical solutions.
* Optimize data workflows to improve performance and reduce costs.
* Conduct regular code reviews to maintain high-quality standards and identify areas for improvement.
* Work closely with stakeholders to deliver data solutions that meet business needs and drive pivotal initiatives.
* Implement monitoring and alerting systems to ensure the reliability and availability of data services.
* Participate in the evaluation and selection of new tools and technologies to enhance our data capabilities.

### **Qualifications**


* 14+ years in an IT related role
* Possess extensive experience in Redshift PySpark Apache Hadoop AWS Glue and AWS Big Data.
* Demonstrate strong problem-solving skills and the ability to solve complex technical issues.
* Show a deep understanding of data security and compliance standard processes.
* Have a proven track record of designing and implementing scalable data architectures.
* Display a proactive approach to learning and staying updated with industry trends.

### **Certifications Required**


AWS Certified Big Data - Specialty Cloudera Certified Professional Data Engineer


### **Salary and Other Compensation****:**


Applications will be accepted until 11/2/2024


The annual salary for this position is between $101,000- $160,000 USD depending on experience and other qualifications of the successful candidate.


This position is also eligible for Cognizant’s discretionary annual incentive program, based on performance and subject to the terms of Cognizant’s applicable plans.


**Benefits**: Cognizant offers the following benefits for this position, subject to applicable eligibility requirements:


* Medical/Dental/Vision/Life Insurance
* Paid holidays plus Paid Time Off
* 401(k) plan and contributions
* Long-term/Short-term Disability
* Paid Parental Leave
* Employee Stock Purchase Plan

**Disclaimer:** The salary, other compensation, and benefits information is accurate as of the date of this posting. Cognizant reserves the right to modify this information at any time, subject to applicable law.","https://www.glassdoor.com/Overview/W-EI_IE8014.htm","","","","","","https://media.glassdoor.com/sql/8014/cognizant-technology-solutions-squareLogo-1651131366751.png","","",""
"1009471329970","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009471329970","","Lead Data Engineer","Alcority","Dallas, TX","","2024-10-03","direct_data","yearly",130792.0,178662.0,"USD",False,"","","","organic","","The Lead Data Engineer is the senior software engineer in the Business Intelligence and Data Warehousing team. This role develops data ingestion to enable high-value business intelligence products. This is a senior individual contributor role with a focus on hands on development, collaborative problem solving, and mentorship of junior engineers. Successful candidates will directly influence solution designs to create a robust data platform to deliver a wide range of products. This role requires 12+ years of engineering experience including work on Azure Data Factory and Informatica Power Center / IICS.
Responsibilities:* Experience in designing and delivering solutions using MS Azure Data Factory, Azure Synapse Analytics, MS Fabric, AWS, or similar tools
* Ability to automate tasks and deploy production standard code with unit testing, continuous integration, and versioning
* Experience with advanced data integration techniques including ETL/ELT pipelines and data transformation
* Familiarity with cloud security best practices, including Azure Active Directory, encryption, and data privacy compliance
* Working in an Agile framework
* Liaising with Business Analysts on the technical solutions
* Assisting with Production Support activities


Required skills:* Strong recent experience working as Azure Data Engineer, with prior experience in AWS or any other cloud technology
* Strong experience in Cloud Application Integration and Cloud Data Integration
* Strong experience in DevOps platforms such as GitHub with hands-on experience in branching, merge strategy, rebasing and reviewing history
* Experience in developing application integration using SOAP/REST APIs and big data technologies such as Apache Spark
* Good knowledge of Rest V2, Swagger file generation and Python scripting
* Some experience in Kubernetes/Docker
* The current role is expected to be Azure heavy, but in future we expect to operate in hybrid environments
* Ability to work independently with minimum supervision to meet deadlines

  

Preferred skills:* Informatica IICS Or Power Center experience
* Working knowledge of SQL
* Snowflake experience

*It is impossible to list every requirement for, or responsibility of, any position. Similarly, we cannot identify all the skills a position may require since job responsibilities and the Company’s needs may change over time. Therefore, the above job description is not comprehensive or exhaustive.* *The Company reserves the right to adjust, add to or eliminate any aspect of the above description. The Company also retains the right to require all employees to undertake additional or different job responsibilities when necessary to meet business needs.*
Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future.
Benefits & Perks:* Time Off: 25 days of PTO for full-time employees and 12 company holidays.
* Company Paid Benefits: Life insurance, Short-term disability, Long-term disability, Paid parental leave, Employee Assistance Program, and medical insurance in our high deductible health plan.
* Optional Employee Paid Benefits: Medical insurance in our EPO plan, Dental benefits, and Vision benefits. We also offer Health Savings Accounts, Flexible Spending Accounts, Supplemental Life insurance, and more.
* 401(k): Eligible after 60 days. Discretionary company match of 50% up to the first 6% of contributions.

  

EQUAL OPPORTUNITY EMPLOYER
ALCORITY IS AN EQUAL EMPLOYMENT OPPORTUNITY EMPLOYER. THE COMPANY'S POLICY IS NOT TO DISCRIMINATE AGAINST ANY APPLICANT OR EMPLOYEE BASED ON RACE, COLOR, RELIGION, NATIONAL ORIGIN, GENDER, AGE, SEXUAL ORIENTATION, GENDER IDENTITY OR EXPRESSION, MARITAL STATUS, MENTAL OR PHYSICAL DISABILITY, AND GENETIC INFORMATION, OR ANY OTHER BASIS PROTECTED BY APPLICABLE LAW. THE FIRM ALSO PROHIBITS HARASSMENT OF APPLICANTS OR EMPLOYEES BASED ON ANY OF THESE PROTECTED CATEGORIES.","https://www.glassdoor.com/Overview/W-EI_IE6243571.htm","","","","","","https://media.glassdoor.com/sql/6243571/alcority-squarelogo-1647427061350.png","","",""
"1009466218390","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009466218390","","Data Architect","Ariana Solutions","Dallas, TX","","2024-10-01","direct_data","yearly",114342.0,160000.0,"USD",False,"","","","organic","","**Title - Data Architect(Azure, Databricks)**  
**Location - Dallas, TX, Day one onsite**  
**Salary Range - $180k Per Annum**

**Required Skills/Qualifications:**

* 10-14 years of relevant experience
* Bachelor's and/or master’s degree in computer science or equivalent experience.
* Strong communication, analytical and problem-solving skills with a high attention to detail.

**Desired Experience:**

* At least two years of experience building and leading highly complex, technical engineering teams.
* Strong hands-on experience in Databricks
* Implement scalable and sustainable data engineering solutions using tools such as Databricks, Azure, Apache Spark, and Python. The data pipelines must be created, maintained, and optimized as workloads move from development to production for specific use cases.
* Experience managing distributed teams preferred.
* Comfortable working with ambiguity and multiple stakeholders.
* Comfortable working cross functionality with product management and directly with customers; ability to deeply understand product and customer personas.
* Expertise on Azure Cloud platform
* Good SQL knowledge
* Knowledge on orchestrating workloads on cloud
* Ability to set and lead the technical vision while balancing business drivers
* Strong experience with PySpark, Python programming
* Proficiency with APIs, containerization and orchestration is a plus
* Experience handling large and complex sets of data from various sources and databases
* Solid grasp of database engineering and design principles.
* Experience with Unity Catalog.
* Familiarity with CI/CD methods desired
* Good to have Teradata Experience (not Mandatory)

Job Types: Full-time, Contract

Pay: $114,342.00 - $160,000.00 per year

Benefits:

* Health insurance

Schedule:

* 8 hour shift

Education:

* Bachelor's (Required)

Experience:

* Leadership: 10 years (Required)
* Computer science: 10 years (Required)
* Data Engineer: 10 years (Preferred)
* Data Bricks: 5 years (Preferred)
* Azure: 5 years (Preferred)

Work Location: In person","https://www.glassdoor.com/Overview/W-EI_IE7481478.htm","","","","","","https://media.glassdoor.com/sql/7481478/ariana-solutions-squarelogo-1659523319926.png","","",""
"1009464512453","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009464512453","","Data Engineer III","Chewy","Richardson, TX","","2024-09-29","","","","","",False,"","","","organic","CAAR@chewy.com, HR@chewy.com","**Our Opportunity:**



Chewy’s Data Analytics team has an exciting opportunity for a Senior Data Engineer (Data Engineer III) to join the pack. In this role, you will leverage your extensive expertise in data engineering to support our Speech Analytics platform. You'll be integral in building and maintaining high-quality data pipelines that drive analytical solutions, driving strategy for VOC data democratization, collecting stakeholder requirements for metrics and visualization, and integrating additional metadata fields into our Speech Analytics platform to facilitate enhanced VOC and QA reporting. You will act as a technical lead/advisor for our customer experience survey mechanisms (CSAT/NPS) and support other ad hoc VOC experimentation and customer feedback data responsibilities as needed. As a key player, you will develop and implement advanced data products and technologies to meet our evolving business needs and redefine world-class customer service standards. Our fast-paced environment presents continuous new challenges and opportunities.


**What You'll Do:**


* **Design and Optimize Data Systems:** Develop, optimize, and maintain data architecture and pipelines using advanced design and programming patterns, adhering to best practices.
* **Data Integration and Management:** Manage and enhance our SSOT tables and data marts critical for daily business decisions.
* **Collaborative Leadership:** Act as a trusted advisor to analytics teams and business partners, providing expert consultation and communicating sophisticated data-driven insights.
* **Mentorship:** Mentor and coach peers on data standards and best practices, promoting a culture of continuous learning and improvement.
* **Innovative Solutions:** Lead the evaluation and deployment of cutting-edge tools and processes for data engineering to boost overall organizational productivity.
* **Strategic Partnerships:** Collaborate with leaders, vendors, and data practitioners across Chewy to develop technical architectures for strategic projects and initiatives.
* **Documentation and Agile Practices:** Document technical details of work and adhere to agile methodologies, utilizing tools such as Jira and Confluence.


**What You'll Need:**


* **Education:** Bachelor’s or Master’s degree in Computer Science, Engineering, Information Systems, Mathematics, or a related field.
* **Professional Experience:** At least 5 years of experience in data engineering, with a strong focus on data integration and pipeline construction in cloud environments and enterprise data warehouses like Snowflake.
* **Technical Proficiency:** Expertise in SQL and programming languages such as Python; familiarity with big data technologies like Apache Hadoop, Spark, and Kafka.
* **Leadership and Communication:** Demonstrated ability to lead projects and communicate effectively with stakeholders at all levels.
* **Innovative and Analytical Mindset:** Strong problem-solving skills and the ability to adapt to new technologies and changing business requirements.


**Bonus:**


* **Advanced Programming:** Strong proficiency in Python.
* **Industry Experience:** Prior experience leveraging top Speech & Text Analytics/VOC/Customer Feedback Management software in e-commerce, retail, or startup environments.
* **Certifications:** AWS Developer or Data Analytics certifications.
* **BI and Analytics Tools:** Experience with BI tools such as Tableau, Power BI, or similar, and familiarity with Speech Analytics platforms like XM Discover, Qualtrics, or Clarabridge.

**Chewy is committed to equal opportunity. We value and embrace diversity and inclusion of all Team Members. If you have a disability under the Americans with Disabilities Act or similar law, and you need an accommodation during the application process or to perform these job requirements, or if you need a religious accommodation, please contact** **CAAR@chewy.com****.**

  


**If you have a question regarding your application, please contact** **HR@chewy.com****.**

  


**To access Chewy's Customer Privacy Policy, please click** **here****. To access Chewy's California CPRA Job Applicant Privacy Policy, please click** **here****.**","https://www.glassdoor.com/Overview/W-EI_IE815856.htm","","","","","","https://media.glassdoor.com/sql/815856/chewy-squareLogo-1630603456108.png","","",""
"1009463889758","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009463889758","","Field Engineer","Striim, Inc.","Dallas, TX","","2024-09-28","direct_data","yearly",130000.0,150000.0,"USD",False,"","","","organic","","Striim, (pronounced ""stream"" with two i's for integration and intelligence), is a unified data integration and streaming platform that connects clouds, data, and applications with unprecedented speed and simplicity to deliver the right data at the right time. Striim is used by enterprise companies to monitor events across any environment, build applications that drive digital transformation, and leverage true real-time analytics to provide a superior experience to their customers. At our company, we believe and expect all of our employees to operate as one with unlimited potential and dignity.

**Description**



Striim is hiring a field engineer to be a technical leader who will engage with our customers throughout the life cycle of the Striim Platform. A Field Engineer will partner with a Customer Success Manager to create a guided customer journey through all implementation phases, including new customer onboarding, solution architecture strategy, and technical enablement. This is a highly customer-focused role, driving toward operational excellence, continuous learning, and mission-critical innovation. This is a fully technical and hands-on position.


**Responsibilities**


* Onboard new Striim customers, delivering learning, solution strategy, technical enablement, and implementation guidance during the deployment process.
* Lead customer technical teams during development phases to implement best practices and innovate enterprise adoption challenges.
* Support the seamless transition from pre-sales prototypes to post-sales production scale experiences.
* Collaborate with customer success and account management teams to conduct periodic health checks with customers, ensuring operational excellence with Striim.
* Be the Striim product expert, coach, and trusted technical advisor during deployment.
* Be the in-house customer champion, coordinating with Striim customer support and stakeholders to drive technical advocacy, product evolution, and technical innovation.
* Proactively engage existing Striim customers to realize technology value with further adoption of the Striim platform, demonstrating new applications and use cases for Striim.
* Increase internal knowledge base by developing and/or maintaining documentation related to Striim implementations, best practices, and troubleshooting.
* Track customer issues, collaborate with support on customer-training-related matters, and work with customer to develop and track product feature requests (PFRs).
* Report on the status of key accounts, including escalations, to the manager and Customer Success Manager (if applicable).


**Requirements**


* A successful candidate must be based 100% remote somewhere in the Continental United States
* 3+ years of experience in customer-facing technical roles, e.g., Sales Engineer/Pre-sales Engineer, Solutions Architect, Data Engineer, Customer Success Engineer
* 3+ years of experience with database management systems software such as Oracle, MySQL, Microsoft SQL Server, and SQL Programming Language
* 3+ years of experience programming languages such as Java, Python, Shell scripting
* 3+ years of experience or deep core knowledge of Cloud infrastructure and Data Services such as Amazon AWS, Microsoft Azure and Google Cloud
* Principle knowledge in working with, configuring, and troubleshooting Operating Systems based on Unix/Linux and Windows
* Experience working with Message Systems such as Kafka and JMS
* Experience in working with Enterprise data environments and Mission Critical IT systems is desirable
* Knowledge of Snowflake, Google BigQuery or Databricks is a plus
* Excellent written, verbal, and presentation communication skills
* Bachelor's degree in Information Systems, Computer Science, Computer Engineering, Information Systems or equivalent experience


**Benefits**


* We offer
* Competitive salary and pre-IPO stock options
* Private Medical Insurance
* Life Insurance
* Pension Plan
* Income Protection
* Paid Time Off (Discretionary Time Off & Public Holidays)
* The chance to contribute to and shape an upbeat, fully engaged culture


**Compensation**



$130,000 - $150,000 USD on an annualized basis


Our company culture fosters entrepreneurship and nurtures our team members to grow with the company. Come join a Silicon Valley startup focused on delivering a product that's loved by its customers and primed to be a core part of the cloud data stack.



We are an equal opportunity employer, and we value diversity at our company.It is in our best interest to continue to foster an environment of diversity, equity, and inclusion to bring the most value to our workforce, customers, and partners. All applicants are considered for employment without attention to race, color, religion, sex, age, marital status, sexual orientation, gender identity, national origin, veteran status, or disability status.



For more information on Striim's Privacy Policy, click here.","https://www.glassdoor.com/Overview/W-EI_IE1293214.htm","","","","","","https://media.glassdoor.com/sql/1293214/striim-squarelogo-1472701235341.png","","",""
"1009463927567","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009463927567","","Data Platform Engineer","Brown & Brown Insurance","Plano, TX","","2024-09-28","direct_data","yearly",90000.0,100000.0,"USD",False,"","","","organic","","Built on meritocracy, our unique company culture rewards self-starters and those who are committed to doing what is best for our customers.
Brown & Brown is an independent insurance intermediary that through its licensed subsidiaries provides a variety of insurance and reinsurance products and services to corporate, public entity, institutional, trade, professional, association, and individual clients. Headquartered in Daytona Beach, Florida, offices are located across the United States, with products and services offered through four major business divisions. We are listed on the NYSE at BRO. Our drive to be the best has made Brown & Brown one of the largest and most respected independent insurance intermediaries in the nation, with over 75 years of continuous service. The Company is ranked as the sixth largest such organization in the United States and seventh in the World by Business Insurance magazine.
The Data Platform Engineer is a member of the Enterprise Data Platform team reporting to the Head of Data Engineering. This experienced individual will develop, automate and manage cloud-based data capabilities and technologies in support of both the overall data strategy, architecture and roadmap and the delivery of divisional, corporate and enterprise data assets and insights. Partnering with the operations and delivery teams, they will ensure the availability, stability, performance and scalability of data capabilities and technologies.
Responsibilities:* Engineer, deliver and support automated, Azure cloud-based data capabilities and technologies in support of the Modern Data Platform (MDP) strategy and roadmap.
* Develop, deliver and support Infrastructure As Code templates for MDP capability deployments.
* Monitor, measure and report on the utilization, performance, and cost of MDP capabilities.
* Identify and implement enhancements to further automate and scale the MDP capabilities.
* Provide implementation, production and consulting support to delivery teams leveraging the MDP.
* Collaborate with the Enterprise Data Architecture and Enterprise Data Enablement teams on data solutions and roadmaps.
* Define and automate data platform controls in support of Software Development Lifecycle (SDLC) requirements.
* Mentor and provide guidance to Data Engineers with respect to MDP capabilities.
* Work well with co-located and distributed team members and partners.
* Demonstrate a high degree of creativity and problem-solving skills.
* Other duties as assigned.


Required:* Bachelor’s degree in computer science or related field or equivalent work experience.
* Experience implementing data capabilities and technologies supporting data pipelines, data integration, data transformation, analytics, reporting and modeling (e.g. AI/ML).
* Strong understanding of engineering, implementing, and supporting data platforms and solutions in a cloud environment.
* Hands on experience implementing and using cloud-based storage, data lake, analytics, visualization, SQL, container, dev ops and security services.
* Hands on experience developing and supporting Infrastructure As Code templates.
* Hands on experience working with Python, Java, SQL and JSON.
* Deep understanding of data management and data governance principles.
* Passion for learning new technologies and enhancing existing skills.
* Experience developing, implementing and supporting integrated frameworks across data capabilities and technologies.
* Experience implementing and using CI/CD pipelines and automation.
* Experience in end-to-end Software Development Life Cycle (SDLC) projects.
* Experience working with key stakeholders and technology peers.
* Excellent verbal and written communication skills.
* Self-starter with the ability to build strong relationships and work collaboratively.
* Ability to adapt and respond in a rapidly evolving business environment.
* 5+ years of related work experience.


Preferred:* Experience in the insurance industry and/or basic knowledge of insurance.
* Experience engineering, implementing, and supporting solutions covering multiple geographies.
* Microsoft Azure Solutions Architect Expert, Azure Data Engineer Associate or equivalent certification(s).
* Experience with Azure Data Factory, Azure Synapse Analytics, Azure Databricks, Snowflake and/or equivalent cloud data technologies and platforms.
* Experience with data platforms supporting Data as a Product, Data as a Service, Data Mesh, Data Virtualization, Delta Lake, Lakehouse and/or Data Fabric.


What we offer:* Excellent growth and advancement opportunities
* Competitive pay based on experience.
* Discretionary Time Off (DTO)
* Generous benefits package: health, dental, vision, 401(k), etc.
* Employee Stock Purchase Plan
* Tuition Reimbursement and Student Loan Repayment Assistance
* Mental Health Resources


Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $90,000/year in our lowest geographic market up to $100,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience.
We are an Equal Opportunity Employer. We take pride in the diversity of our team and seek diversity in our applicants.","https://www.glassdoor.com/Overview/W-EI_IE2587.htm","","","","","","https://media.glassdoor.com/sql/2587/brown-and-brown-insurance-squarelogo-1526582112870.png","","",""
"1009460838868","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009460838868","","Product Software Engineer - Data Engineer","Capgemini","Dallas, TX","","2024-09-26","","","","","",False,"","","","organic","","#### **Job location:****Hybrid**

**Job description:**

  

As Senior Software Engineer, you will work on one of the world's largest social media platforms which deals with a few petabytes of data coming to the system daily. You will contribute as part of R&D self-organized team working in a challenging, innovative environment for our client.  

Investigate, create, and implement the solutions for many technical challenges using cutting edge technologies, including building/enhancing Data processing platform enabling work of software used by hundreds of millions of users.


#### **Key Responsibilities:**

* Obtains tasks from the project lead or Team Lead (TL), prepares functional and design specifications, approves them with all stakeholders.
* Ensures that assigned area/areas are delivered within set deadlines and required quality objectives.
* Provides estimations, agrees task duration with the manager and contributes to project plan of assigned area.
* Evaluating existing data systems.
* Developing best practices for data coding to ensure consistency within the system.
* Updating and optimizing local and metadata models.
* Evaluating implemented data systems for variances, discrepancies, and efficiency.
* Troubleshooting and optimizing data systems.
* Understand the business drivers and analytical use-cases and translate these to data products.
* Design, implement and maintain pipelines that produce business critical data reliably and efficiently using cloud technology.
* Addresses area-level risks, provides and implements mitigation plan.
* Reports about area readiness/quality, and raise red flags in crisis situations which are beyond his/her AOR.
* Responsible for resolving crisis situations within his/her AOR.
* Initiates and conducts code reviews, creates code standards, conventions, and guidelines.
* Suggests technical and functional improvements to add value to the product.
* Constantly improves his/her professional level.
* Collaborates with other teams.

  


#### **Required Skills:**

* 5+ years of experience as Software Engineer with Solid Java coding skill
* Must have experience doing channel support and answer question regarding to service SLO.
* Ability to organize and document solutions.
* A passion for streamlining systems and processes to make the difficult trivial  

 Strong OOP skills
* Effective communication (oral & written), collaboration, and interpersonal skills.
* Experience with AWS & K8S and Apache Flink is a plus.

#### **Life at Capgemini**



Capgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:


* Collaborating with teams of creative, fun, and driven colleagues
* Flexible work options enabling time and location-based flexibility
* Company-provided home office equipment
* Virtual collaboration and productivity tools to enable hybrid teams
* Comprehensive benefits program (Health, Welfare, Retirement and Paid time off)
* Other perks and wellness benefits like discount programs, and gym/studio access.
* Paid Parental Leave and coaching, baby welcome gift, and family care/illness days
* Back-up childcare/elder care, childcare discounts, and subsidized virtual tutoring
* Tuition assistance and weekly hot skill development opportunities
* Experiential, high-impact learning series events
* Access to mental health resources and mindfulness programs
* Access to join Capgemini Employee Resource Groups around communities of interest

#### **About Capgemini**



Capgemini is a global business and technology transformation partner, helping organizations to accelerate their dual transition to a digital and sustainable world, while creating tangible impact for enterprises and society. It is a responsible and diverse group of 340,000 team members in more than 50 countries. With its strong over 55-year heritage, Capgemini is trusted by its clients to unlock the value of technology to address the entire breadth of their business needs. It delivers end-to-end services and solutions leveraging strengths from strategy and design to engineering, all fueled by its market leading capabilities in AI, cloud and data, combined with its deep industry expertise and partner ecosystem. The Group reported 2023 global revenues of €22.5 billion.



Get The Future You Want | www.capgemini.com


**Disclaimer**



Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.



This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.



Capgemini is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.

  



Please be aware that Capgemini may capture your image (video or screenshot) during the interview process and that image may be used for verification, including during the hiring and onboarding process.



Applicants for employment in Canada must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in Canada by Capgemini.

  

**Job** Programmer/Analyst**Schedule** Full-time**Primary Location** US-TX-Dallas**Organization** ERD PPL US","https://www.glassdoor.com/Overview/W-EI_IE3803.htm","","","","","","https://media.glassdoor.com/sql/3803/capgemini-squareLogo-1688367853815.png","","",""
"1009459084786","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009459084786","","Senior Cloud Data Engineer (Snowflake/Databricks)","Deloitte","Dallas, TX","","2024-09-25","direct_data","yearly",90732.0,125616.0,"USD",False,"","","","organic","","Are you an experienced, passionate pioneer in technology - a solutions builder, a roll-up-your-sleeves technologist who wants a daily collaborative environment, think-tank feel and share new ideas with your colleagues - without the extensive demands of travel? If so, consider an opportunity with our US Delivery Center - we are breaking the mold of a typical Delivery Center.  

  

Our US Delivery Centers have been growing since 2014 with significant, continued growth on the horizon. Interested? Read more about our opportunity below ...  

  

**Work you'll do/Responsibilities**  

* Work with the team to evaluate business needs and priorities, liaise with key business partners and address team needs related to data systems and management
* Translate business requirements into technical specifications; establish and define details, definitions, and requirements of applications, components and enhancements
* Participate in project planning; identifying milestones, deliverables and resource requirements; tracks activities and task execution.
* Generate design, development, test plans, detailed functional specifications documents, user interface design, and process flow charts for execution of programming
* Develop data pipelines / APIs using Python, SQL, potentially Spark and AWS, Azure or GCP Methods
* Use an analytical, data-driven approach to drive a deep understanding of fast changing business
* Build large-scale batch and real-time data pipelines with data processing frameworks in AWS, Azure or GCP cloud platform
* Moving data from on-prem to cloud and cloud data conversions

  

**The Team**  

  

Artificial Intelligence & Data Engineering:  

  

In this age of disruption, organizations need to navigate the future with confidence, embracing decision making with clear, data-driven choices that deliver enterprise value in a dynamic business environment.  

  

The Artificial Intelligence & Data Engineering team leverages the power of data, analytics, robotics, science and cognitive technologies to uncover hidden relationships from vast troves of data, generate insights, and inform decision-making. Together with the Strategy practice, our Strategy & Analytics portfolio helps clients transform their business by architecting organizational intelligence programs and differentiated strategies to win in their chosen markets.  

  

Artificial Intelligence & Data Engineering will work with our clients to:  

* Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platforms
* Leverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actions
* Drive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvements

  

**Qualifications**  

  

**Required**  

* 6+ years of experience in data engineering with an emphasis on data analytics and reporting
* 6+ years of experience with at least one of the following cloud platforms: Microsoft Azure, Amazon Web Services (AWS), Google Cloud Platform (GCP), others
* 6+ years of experience in SQL, data transformations, statistical analysis, and troubleshooting across more than one Database Platform (Cassandra, MySQL, Snowflake, PostgreSQL, Redshift, Azure SQL Data Warehouse, Databricks, etc.)
* 6+ years of experience in the design and build of data extraction, transformation, and loading processes by writing custom data pipelines
* 6+ years of experience with one or more of the follow scripting languages: Python, SQL, Kafka and/or other
* 6+ years of experience designing and building solutions utilizing various Cloud services such as EC2, S3, EMR, Kinesis, RDS, Redshift/Spectrum, Lambda, Glue, Athena, API gateway, etc.
* Bachelor's degree, preferably in Computer Science, Information Technology, Computer Engineering, or related IT discipline, or equivalent experience
* Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future.
* Ability to travel 10%, on average, based on the work you do and the clients and industries/sectors you serve. This may include overnight travel.
* Must be able to obtain the required level of security clearance for this role
* Must live in a commutable distance (approximately 100-mile radius) to one of the following Delivery locations: Atlanta, GA; Charlotte, NC; Dallas, TX; Gilbert, AZ; Houston, TX; Lake Mary, FL; Mechanicsburg, PA; Philadelphia, PA with the ability to commute to assigned location for the day, without the need for overnight accommodations
* Expectation to co-locate in your designated Delivery location up to 30% of the time based on business needs. This may include a maximum of 10% overnight client/project travel

  

**Preferred**  

* AWS, Azure and/or Google Cloud Platform Certification
* Master's degree or higher
* Expertise in one or more programming languages, preferably Scala, PySpark and/or Python
* Experience working with either a Map Reduce or an MPP system on any size/scale
* Experience working with agile development methodologies such as Sprint and Scrum

  

Information for applicants with a need for accommodation: https://www2.deloitte.com/us/en/pages/careers/articles/join-deloitte-assistance-for-disabled-applicants.html","https://www.glassdoor.com/Overview/W-EI_IE2763.htm","","","","","","https://media.glassdoor.com/sql/2763/deloitte-squareLogo-1674210308592.png","","",""
"1009455335860","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009455335860","","Senior Data Engineer","McKesson","Irving, TX","","2024-09-21","direct_data","yearly",110800.0,184600.0,"USD",False,"","","","organic","","McKesson is an impact-driven, Fortune 10 company that touches virtually every aspect of healthcare. We are known for delivering insights, products, and services that make quality care more accessible and affordable. Here, we focus on the health, happiness, and well-being of you and those we serve – we care.


What you do at McKesson matters. We foster a culture where you can grow, make an impact, and are empowered to bring new ideas. Together, we thrive as we shape the future of health for patients, our communities, and our people. If you want to be part of tomorrow’s health today, we want to hear from you.

**Current Need**


As a Data Engineer at McKesson, you will play a crucial role in designing, implementing, and maintaining data architectures, databases, and large-scale processing systems. You will collaborate closely with cross-functional teams to develop eAicient data pipelines and contribute to our organization's data modernization eAorts. This position requires a strong understanding of data engineering principles, cloud technologies, and a commitment to delivering high-quality solutions.


Genospace is looking for a talented team player who wants to solve novel problems and help us build and deliver our data and AI platform. As the leading provider of information technology services in molecular medicine, our precision medicine platform is used today by clinicians and researchers across the country and around the globe to improve patient care.


At Genospace, our mission is to be the leading information platform for applied precision medicine.


Our interdisciplinary team is merging the tools and techniques of genomics, healthcare, data analytics, web development, and cloud computing. We serve research, clinical development, pathology, and clinical care customers who work with high- dimensional genomic and other biomedical data. Many of the most advanced precision medicine organizations are powered by Genospace.

**Your Impact**


Your work as a Data Engineer at Genospace will impact individuals and organizations across the healthcare landscape: patients searching for the best treatment options, researchers seeking to make advances based on a sea of high-dimensional data, physicians deploying personalized medicine in everyday practice, and laboratories conducting some of the most advanced analyses in the world.

**What You’ll Do**

* Work on a small team to design and implement scalable and eAicient data pipelines to support various data-driven initiatives.
* Provide feedback to your teammates through code and design reviews, collaborating with and learning from each other while delivering great data and AI foundation.
* Help define, plan, and implement enhancements to our data engineering process, products, and technology platform

**Some of the things we’re looking for:**

**Minimum Requirement**

Degree or equivalent and typically requires 4+ years of relevant experience.

**Critical Skills**

* At least 4+yrs of proven experience as a Data Engineer
* Deep technical expertise in building and optimizing data pipelines and large-scale processing systems.
* Proven experience with Azure Cloud and Databricks.
* Experience working with cloud solutions and contributing to data modernization eAorts.
* Strong programming skills (e.g., Python, Pyspark or Scala) for data manipulation and transformation.
* Good understanding of data engineering principles, data architecture, and database management. Strong problem-solving skills and attention to detail.
* Strong communication skills, with the ability to convey technical concepts to both technical and non-technical stakeholders.

**Additional Skills**

* Knowledge of the healthcare, distribution, or software industries is a plus.
* Strong technical aptitude and experience with a wide variety of data technologies
* Ability to rapidly learn and if required evaluate a new tool or technology.
* Strong verbal & written communication skills
* Demonstrated technical experience.
* Be an innovative thinker.
* Strong customer and quality focus.
* Knowledge of MongoDB, Elasticsearch and/ or OrientDB is a plus


We are proud to offer a competitive compensation package at McKesson as part of our Total Rewards. This is determined by several factors, including performance, experience and skills, equity, regular job market evaluations, and geographical markets. In addition to base pay, other compensation, such as an annual bonus or long-term incentive opportunities may be offered. For more information regarding benefits at McKesson, please click here.

**Our Base Pay Range for this position**


$110,800 - $184,600**McKesson is an Equal Opportunity Employer**

  

McKesson provides equal employment opportunities to applicants and employees and is committed to a diverse and inclusive environment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability, age or genetic information. For additional information on McKesson’s full Equal Employment Opportunity policies, visit our Equal Employment Opportunity page.

 **Join us at McKesson!**","https://www.glassdoor.com/Overview/W-EI_IE434.htm","","","","","","https://media.glassdoor.com/sql/434/mckesson-squareLogo-1709128121638.png","","",""
"1009454071890","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009454071890","","Senior GCP Data Engineer","Prodapt","Irving, TX","","2024-09-20","direct_data","yearly",94862.0,128269.0,"USD",False,"","","","organic","","Overview:

We are looking for **Senior** **GCP Data Engineer**, this role involves working closely with stakeholders to understand their data requirements and implementing data models that align with organizational goals.


This role is essential for organizations aiming to leverage Google Cloud Platform (GCP) to develop and maintain high-performance cloud solutions, ensuring scalability, reliability, and efficiency.


Responsibilities:
* Design and optimize database models to store and retrieve company information.
* Migrate data from legacy systems to new solutions.
* Create conceptual and logical data models and flowcharts.
* Develop and implement Google Cloud Platform (GCP) based solutions tailored to business needs.
* Experience in building high-performing data processing frameworks leveraging Google Cloud Platform


 and Teradata

* Experience in building data pipelines supporting both batch and real-time streams to enable data


 collection, storage, processing, transformation and aggregation.

* Experience in utilizing GCP Services like Big Query, Composer, Dataflow, Pub-Sub, Data Proc and Cloud


 Monitoring

* Experience in scheduling like Airflow, Cloud Composer etc.
* Understand ETL application design, data sources, data targets, relationships, and business rules.


Requirements:
* Proficiency in SQL, Oracle, and other database management systems.
* Deep understanding of GCP services like Big Query, Composer, Dataflow, Pub-Sub, Data Proc, GCP


 Cloud Storage.

* Proficiency in languages such as Python, Java, R and SQL.
* Perform thorough technical discovery, identifying problem areas, technical and business requirements.
* Evaluate potential solutions using both technical and commercial criteria.
* Manage clients and/or projects, ensuring successful delivery of solutions.
* Strong problem-solving abilities to address data-related issues.
* Capability to analyze and interpret complex data sets.
* Precision in designing and implementing data models.","https://www.glassdoor.com/Overview/W-EI_IE518979.htm","","","","","","https://media.glassdoor.com/sql/518979/prodapt-solutions-squarelogo-1427103947570.png","","",""
"258faf72e1ee03c1","indeed","https://www.indeed.com/viewjob?jk=258faf72e1ee03c1","https://concentrajobs-selectmedicalcorp.icims.com/jobs/305693/job?utm_source=indeed_integration&iis=Job%20Board&iisn=Indeed&indeed-apply-token=73a2d2b2a8d6d5c0a62696875eaebd669103652d3f0c2cd5445d3e66b1592b0f","Engineer, Data - Clinical Analytics","Concentra","Addison, TX, US","fulltime","2024-10-09","direct_data","yearly",77597.0,98255.0,"USD",False,"","","","","","Overview:

The Data Engineer - Clinical Analytics is primarily focused on analytical processes with ability to implement database solutions and best practices in the realm of data science and machine learning projects. Essential software engineering skills with foundational knowledge on data movement and orchestration both on-premises and cloud environment. The Data Engineer supports and aligns with business decisions within Concentra by analyzing raw data, constructing, and maintaining data systems, and improving data quality and efficiency. Implements programming languages to develop and test architectures that enables data operations for predictive (i.e., machine learning/AI) or prescriptive modeling.
Responsibilities:
- 

Analyze, develop, combine raw information, and maintain various data sources
  

- 

Identify opportunities for data acquisition and collaborate with Application owners and Subject Matter Experts (SME) to document data domain knowledge
  

- 

Implement ETL methods to prepare both structured and unstructured data for predictive and prescriptive modeling
  

- 

Leverage data serialization techniques to meet project needs for use in various reporting platforms
  

- 

Understand enterprise project life cycle and prepare for integration and user acceptance testing methods.
  

- 

Produce technical documentation by following enterprise standards and guidelines
  

- 

Participate in relevant information-sharing activities
  

- 

Proactive identification of issues and opportunities that will have an impact on the business use of reports and ensure managerial awareness
  

- 

Understand troubleshooting and resolutions processes  

This job description is not designed to cover or contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this job. Duties, responsibilities, and activities may change at any time with or without notice.  


Qualifications:
**Education Level:**
Bachelor’s Degree in Computer Science or Computer Engineering preferred  

Degree must be from an accredited college or university.  

**Job-Related Experience**- 

Customarily has at least 6 months to 1 year in software development and data pipelines
  

- 

Relational Database exposure/experience
  

- 

Documentation and publication  

**Job-Related Skills/Competencies*** Concentra Core Competencies of Service Mentality, Attention to Detail, Sense of Urgency, Initiative and Flexibility
* Ability to make decisions or solve problems by using logic to identify key facts, explore alternatives, and propose quality solutions
* Outstanding customer service skills as well as the ability to deal with people in a manner which shows tact and professionalism
* The ability to properly handle sensitive and confidential information (including HIPAA and PHI) in accordance with federal and state laws and company policies
  

- 

Ability to write SQL queries, develop and tune query performance
  

- 

Develop skills for appropriate use of technology to align with project needs
  

- 

Familiarize and scale tools such as: SQL Server, SSIS, Python, Azure, Docker, Git, and Visual Studio
  

- 

Ability to understand and interact with cloud technology such as: Azure, AWS and/or GCP preferred
  

- 

Understand data management process
  

- 

Support current and future initiatives of application development
  

- 

Participate in peer-review of codes and maintain repositories
  

- 

Concentra Core Competencies of Service Mentality, Attention to Detail, Sense of Urgency, Initiative and Flexibility
  

- 

Ability to make decisions or solve problems by using logic to identify key facts
  

- 

Highly organized
  

- 

Good communication skills to effectively speak and write in a clear and professional manner
  

- 

Skilled at listening, understanding and providing feedback  


Additional Data:
**Employee Benefits*** 401(k) Retirement Plan with Employer Match
* Medical, Vision, Prescription, Telehealth, & Dental Plans
* Life & Disability Insurance
* Paid Time Off
* Colleague Referral Bonus Program
* Tuition Reimbursement
* Commuter Benefits
* Dependent Care Spending Account
* Employee Discounts

We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation, if required.  

\\*This job requires access to confidential and sensitive information, requiring ongoing discretion and secure information management\\* **Concentra is an Equal Opportunity Employer, including disability/veterans**","https://www.indeed.com/cmp/Concentra-bf37d3e6","https://www.concentra.com","Addison, TX","10,000+","Decline to state","Concentra is the leader in occupational health for 40+ years. We’re defining the future of workplace health - today.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/56df5588b2006fee1bbf652a24d1ada2","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/bcc9af5adc6c31f8d9f7c9ab47c43faf","Keith Newton","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/89e30f05c3b6c92385caf8bd2660f33f"
"228a2253e3695526","indeed","https://www.indeed.com/viewjob?jk=228a2253e3695526","https://app.pyjamahr.com/careers?company=Umanist%20Staffing%20LLC&job_id=139279&company_uuid=9CEA3DD003&utm_source=false&source=false&isHeaderVisible=true","GCP Data Engineer","Umanist Staffing","Dallas, TX, US","contract","2024-10-09","direct_data","hourly",49.0,57.0,"USD",False,"","","","","","GCP Data Engineer


Overview:


The GCP Data Engineer plays a crucial role in designing, implementing, and managing data processing systems leveraging Google Cloud Platform (GCP) services. This position is essential for ensuring efficient data management, processing, and analysis to support the organization's data-driven decision-making processes and solutions.  

Key Responsibilities:

* Design, develop, and deploy GCP-based data processing systems and solutions.
* Implement scalable and reliable data pipelines for ingesting, processing, and storing large volumes of data.
* Optimize data storage and retrieval processes using GCP storage solutions.
* Collaborate with data scientists and analysts to understand data requirements and implement appropriate solutions.
* Ensure data integrity, security, and compliance with regulatory requirements.
* Monitor and troubleshoot data processing systems to ensure optimal performance and reliability.
* Develop and maintain documentation for data engineering processes and systems.
* Implement data governance best practices for data quality, lineage, and metadata management.
* Assist in the evaluation and selection of appropriate GCP services for specific data processing needs.
* Stay updated with GCP developments and recommend innovative solutions to improve data engineering processes.

  

Required Qualifications:

* Bachelor's or master's degree in Computer Science, Data Engineering, or related field.
* Proven experience in designing and implementing data processing systems on Google Cloud Platform.
* Proficiency in programming languages such as Python, Java, or Scala for data processing and ETL (Extract, Transform, Load) tasks.
* Strong understanding of big data technologies and frameworks, including Hadoop, Spark, and Kafka.
* Experience with GCP services such as BigQuery, Dataflow, Pub/Sub, and Dataproc.
* Expertise in SQL and database technologies for data manipulation and querying.
* Ability to troubleshoot and optimize data processing workflows for performance and cost-efficiency.
* Excellent communication skills and the ability to collaborate in cross-functional teams.
* Understanding of data governance principles and best practices.
* Familiarity with machine learning pipelines and model serving on GCP is a plus.
* Certifications in GCP data engineering or related areas are preferred.

Workplace Type


In-Office
Employment Type


Contract
Experience Level


Mid-Senior-Level
Hourly Compensation


USD 49 - 57
Work Experience (years)


7 - 9 years
Education


Bachelor's Degree
Skills


Hadoop


Sql


Big Data Technologies


Machine Learning Pipelines


Etl


Java


Spark


Data Engineering


Model Serving


Gcp


Kafka


Big Data


Data Governance


Database Technologies


Scala


Python","https://www.indeed.com/cmp/Umanist-Staffing","","","","","","","","",""
"9537c55c4995b674","indeed","https://www.indeed.com/viewjob?jk=9537c55c4995b674","https://app.pyjamahr.com/careers?company=Umanist%20Staffing%20LLC&job_id=135476&company_uuid=9CEA3DD003&utm_source=false&source=false&isHeaderVisible=true","Senior Security Engineer","Umanist Staffing","Dallas, TX, US","fulltime","2024-10-09","direct_data","yearly",120000.0,140000.0,"USD",False,"","","","","","Job Description
Senior security professional with a firm understanding of cybersecurity principles and Google Cloud platform to work on threat modeling of various Google cloud services such as GKE, Cloud SQL, Cloud Storage etc. Using threat modeling, you will identify threats and specify mitigating controls that will directly reduce the risk of operating in the Google Cloud platform.

Responsibilities:* Threat Modeling using a documented process.
* Development of automation tools as required.
* Maintain a high standard of work in identifying threats and specifying mitigating controls.
* Attending to the lifecycle of identified threats and controls.
* Delivery of threat models and supporting tasks within existing timeframes.



Required Technical skills:* IT experience minimum of 10 years, with minimum a of 4 years in Cyber-Security/Information Security preferably in a highly regulated industry like financial services.
* Threat Modeling (STRIDE, PASTA, Attack trees, tooling, Attack).
* Identifying vulnerabilities using CWE or OWASP.
* Experience working in a cyber-security role.
* Extensive knowledge of Google cloud platform.
* Security practices pertaining to authentication, authorization, logging/monitoring, encryption, infrastructure security, network/segmentation.
* Operating systems and their hardening.
* Development concepts (such as: CICD, Pipelines, SDLC).
* Scripting languages, Infrastructure as Code (Terraform, CloudFormation).
* Operating in a DevOps / agile team structure.
* Understanding of Docker/K8S/serverless/helm.
* Design and review technical architectures.



Certifications:* Google Cloud Architect, Cloud Developer, Data Engineer, Network Engineer, etc.
* Google Professional Cloud Security Engineer.
* CISM, CISSP or any equivalent professional cyber security certification

Workplace Type


In-Office
Employment Type


Full-Time
Experience Level


Mid-Senior-Level
Annual Compensation


USD 120,000 - 140,000
Work Experience (years)


8 - 12 years
Education


Bachelor's Degree
Skills


Authorization


Network/Segmentation


Cism


Pipelines


Encryption


Cloud


Cicd


Cyber-Security


Cloud Developer


Google Cloud


Authentication


Scripting Languages


Infrastructure Security


Owasp


Threat Modeling


Infrastructure As Code


Docker


Network Engineer


Logging/Monitoring


Cissp


Google Professional Cloud Security Engineer


Devops


Sdlc


K8s


Agile Team Structure


Technical Architectures


Data Engineer


Cwe


Security


Operating Systems Hardening


Helm


Serverless


Google Cloud Architect


It Experience


Google Cloud Platform","https://www.indeed.com/cmp/Umanist-Staffing","","","","","","","","",""
"097a998f0d5530aa","indeed","https://www.indeed.com/viewjob?jk=097a998f0d5530aa","https://inabia.applytojob.com/apply/Ogs3tBZH6s/Sr-Data-Engineer?source=INDE&~","Sr Data Engineer","Inabia Software & Consulting Inc.","Frisco, TX, US","contract","2024-10-09","direct_data","yearly",118357.0,149867.0,"USD",False,"","","","","","**Title: Sr Data Engineer**  

**Duration: Contract**  

**Location: Atlanta, GA,/Frisco, TX / Bellevue, WA(Onsite)**  

  

**Locals Required.**  

Client looking for 10+ Years of experience.  

  

**Job Description :**  

  

Data Engineer / Architect, Who can Lead a Team of Data Engineers working on an Onshore / Offshore model Collaborating with Customer SMEs  

  

**Skills needed**  

* Snowflake
* Azure Services
* Azure DataBricks
* Python
* SQL
* Azure Data Factory
* GitLab
* Data Modeling Expertise
* Data Analysis Expertise

  

**Test Automation Experience and Skills (Nice to Have)**  

  

**Responsibilities-**  

* AT least five years of experience in Data Engineering, Analysis
* Design, build and deploy efficient & reliable data pipelines to move and transform data
* Optimize existing pipelines and maintenance of all source-related data pipelines
* Support on-call shift as needed to support the team
* Build and Deploy extensive data quality checks to ensure high quality of data
* Build high-performance scalable data warehouses and data products
* Partner with leadership, engineers, product managers and data scientists to understand data needs.
* Improve existing data movement frameworks and add more features
* Extreme focus on automation
* Expert level SQL skills needed
* Data Modeling expertise is required
* CI/CD Pipeline and DevOps practices
* Agile fundamentals
* Prior use of Jira and GitLab





Ogs3tBZH6s","https://www.indeed.com/cmp/Inabia-Software-&-Consulting-Inc.","https://www.inabia.com","Redmond","11 to 50","$1M to $5M (USD)","","","","",""
"413a9238e0c0fac5","indeed","https://www.indeed.com/viewjob?jk=413a9238e0c0fac5","https://lennar.wd1.myworkdayjobs.com/en-US/Lennar_Jobs/job/Irving-TX-Job-Posting-Location/Data-Engineer-II_R24_0000002142-1","Data Engineer II","Lennar","Irving, TX, US","fulltime","2024-10-09","","","","","",False,"","","","","","We are Lennar
Lennar is one of the nation's leading homebuilders, dedicated to making an impact and creating an extraordinary experience for their Homeowners, Communities, and Associates by building quality homes and providing exceptional customer service, giving back to the communities in which we work and live in, and fostering a culture of opportunity and growth for our Associates throughout their career. Lennar has been recognized as a Fortune 500® company and consistently ranked among the top homebuilders in the United States.
Join a Company that Empowers you to Build your Future
The primary mission of the Data Engineer II role is to help our business evolve into a data and insights-driven organization. This position sits in our Enterprise Data and Analytics team, which aims to drive improved business outcomes using insights gleaned from data and analytics, infusing them into Lennar’s corporate fabric.
The Data Engineer II will be involved in technical planning & solutions implementation as part of our data platform engineering team. This is done by helping implement our next generation data and analytics platforms and products using Data engineering best practices. This position will also help mentor more junior associates, such as recent college graduates and early career teammates. The Data Engineer II is a key role in operationalizing Lennar’s enterprise data fabric.* A career with purpose.
* A career built on making dreams come true.
* A career built on building zero defect homes, cost management, and adherence to schedules.


Your Responsibilities on the Team* Build and operationalize data engineering solutions for Lennar’s data and analytics platforms and products.
* Be part of the operational support excellence rotation team, available to provide insight and troubleshoot during support calls.
* Implement ETL, ELT and streaming data ingestion data delivery processes across multiple sources.
* Experience in data modeling, cloud data lake, cloud data warehouse
* Instrument data analytics platforms with robust metrics and monitoring.
* Improve data ingestion architecture, emphasizing data quality, maintainability, and extensibility.
* Support process improvement on the team to enable rapid development of data products.
* Implement standards and best practices for data analytics team, including code modularization, versioning, testing, automation of CI/CD workflows, code reviews etc.
* Gain an understanding of core business processes and align data development with business strategy.
* Wrangle and integrate data from disparate systems to allow data analysts and data scientists to leverage end-to-end data and information.


Requirements
Technical Requirements* At least 4+, prefers 5+ years in:
	+ Data Architecture design
	+ Data modeling & Data warehousing concepts
	+ Data transformations and standardizations
	+ ETL processes & strategies
	+ Monitoring and error handling
	+ SDLC & workflow best practices
		- Code Reviews
		- QA/Testing methodologies
* At least 2+, prefers 3+ years with the following technologies and platforms:
	+ AWS platform: S3, EC2, EMR, EKS, Glue, Lambda, AppFlow, Cloudwatch etc.
	+ AWS certification is big plus
	+ Snowflake Data Cloud
		- Account Administration
		- Virtual warehouse strategies
		- Snowflake feature implementation: Data Sharing, Time Travel, and Zero-copy cloning
		- Role-based Access Control strategies
	+ Dbt
		- Managing dbt cloud environment
		- Managing multi-repository dbt projects
		- Creating and managing dbt models
		- Creating and leveraging dbt macros
	+ Version control & branching strategies (Github a plus)
	+ Proficient in languages: SQL, Python
	+ Data governance, security, and compliance concepts
	+ Data Ingestion
		- Incremental and CDC ingestion methods
		- REST APIs
* Familiarity (At least 1+ years of experience) with:
	+ Orchestration & scheduling tools (Prefect, Airflow is a plus)
	+ Qlik Replicate


Other Requirements* Willingness and availability to be:
	+ On-site at a Lennar designated office location up to 5 days a week.
	+ Part of on-call support calls, which could happen during off hours and weekends.
* Ability to work collaboratively and productively with other team members to achieve Lennar’s objectives.
* Thirst to help transform Lennar into an insights-driven organization.
* Demonstrated some experience in all aspects of development including, but not limited to, gathering requirements, development of technical components related to process scope and supporting testing and post implementation support.
* Ability to work and partner with users and stakeholders to gather solution requirements.
* Experience working with business users to understand how to optimally deliver insights within their operational workflows & decision-making processes.
* Ability and willingness to quickly learn new technologies.
* Ability and willingness to learn about the business, its strategy, objectives, and core business processes.


Additional Requirements:* Travel up to 10% of the time to Divisions within the Lennar family.
* Interact well with co-workers.
* Cross train for position(s) within the team organizational structure from time to time, as required by the Leadership Team.
* Comply with and implement company policies and procedures.
* Accept constructive criticism.
* Strong work ethic.
* Team player.

  

This description outlines the basic responsibilities and requirements for the position noted. This is not a comprehensive listing of all job duties of the Associates. Duties, responsibilities and activities may change at any time with or without notice.
#LI-GC1
Physical & Office/Site Presence Requirements:
This is primarily a sedentary office position which requires he position to have the ability to operate computer equipment. Finger dexterity is necessary.
Life at Lennar
At Lennar, we are committed to fostering a supportive and enriching environment for our Associates, offering a comprehensive array of benefits designed to enhance their well-being and professional growth. Our Associates have access to robust health insurance plans, including Medical, Dental, and Vision coverage, ensuring their health needs are well taken care of. Our 401(k) Retirement Plan, complete with a $1 for $1 Company Match up to 5%, helps secure their financial future, while Paid Parental Leave and an Associate Assistance Plan provide essential support during life's critical moments. To further support our Associates, we provide an Education Assistance Program and up to $30,000 in Adoption Assistance, underscoring our commitment to their diverse needs and aspirations. From the moment of hire, they can enjoy up to three weeks of vacation annually, alongside generous Holiday, Sick Leave, and Personal Day policies. Additionally, we offer a New Hire Referral Bonus Program, significant Home Purchase Discounts, and unique opportunities such as the Everyone’s Included Day. At Lennar, we believe in investing in our Associates, empowering them to thrive both personally and professionally. Lennar Associates will have access to these benefits as outlined by Lennar’s policies and applicable plan terms. Visit Lennartotalrewards.com to view our suite of benefits.
Join the fun and follow us on social media to see what's happening at our company, and don't forget to connect with us on Lennar: Overview | LinkedIn<https://www.linkedin.com/company/lennar/> for the latest job opportunities.
Lennar is an equal opportunity employer and complies with all applicable federal, state, and local fair employment practices laws.","https://www.indeed.com/cmp/Lennar-e9dbb56c","http://www.lennar.com","Miami, FL","5,001 to 10,000","$5B to $10B (USD)","Headquartered in Miami, Lennar Corporation is one of America's leading homebuilders.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/de47f80d161ed972d5fd383223126db6","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/949c8c993fc057e03a1819400ed4ceb8","",""
"e7672b837687aa63","indeed","https://www.indeed.com/viewjob?jk=e7672b837687aa63","http://www.indeed.com/job/data-engineerhybrid-e7672b837687aa63","Data Engineer(Hybrid)","Smartfox LLC","Richardson, TX, US","contract","2024-10-09","direct_data","hourly",50.0,62.0,"USD",True,"","","","","","**Job Title: Data Engineer**

**Remote/Hybrid/In-Person: Hybrid (2 Days a week onsite Tuesday and Thursday)**

**Location: 2375 N Glenville Drive, Richardson, TX 75082**

**Duration: 6 Months - Potential to convert to FTE** 

**Resource's typical working day:**

* Prepare high-level ETL mapping specifications. Develop complex code data scripts (Primarily SQL) for ETL Troubleshoot & determine best resolution for data issues and anomalies
* Manage exploratory data analysis to support database and dashboard development, as well as advanced analytics efforts.
* Maintains technical knowledge by attending educational workshops; reviewing publications; establishing personal networks; in technical societies.
* Ensures operation of equipment by completing preventive maintenance requirements; following manufacturer's instructions; troubleshooting malfunctions; calling for repairs; evaluating new equipment and techniques.
* Contributes to team effort by accomplishing related results as needed.
* Determines changes in physical database by studying project requirements; identifying database characteristics, such as location, amount of space, and access method.
* Changes database system by coding database descriptions.
* Protects database by developing access system; specifying user level of access.
* Maintains user reference by writing and rewriting database descriptions.

**Years of Experience needed:** Typically has 3-5 years of relevant work experience.

**Level of Education:** Bachelor's degree (BA/BS) in a related field such as information systems, mathematics, or computer science or equivalent work experience

**Top Must have Skills:**

* Database Performance Tuning, Database Management, Requirements Analysis, Software Development Fundamentals, Problem Solving, Documentation Skills, Verbal Communication, Data Maintenance, Database Security, Promoting Process Improvement, System Administration.
* Advanced SQL skills - Adept at queries, report writing and presenting findings Expertise in Data Analysis, Data Profiling, and SQL Tuning Expertise in translating business requirements to project design, development, and execution.
* Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy.
* Ability to clearly communicate capabilities, opportunities, and recommendations to both technical and nontechnical audiences.
* Have a strong, pragmatic approach to leading architecture and development solutions, with a proven record in technology planning and delivery.
* Ability to prioritize and co-ordinate tasks efficiently ensuring all deadlines are met.
* Experience of managing product delivery is desirable Excellent interpersonal skills across all levels of the organization
* At least 3 years in an architectural or design capacity for 'large scale' enterprise systems.

Job Type: Contract

Pay: $50.00 - $62.00 per hour

Expected hours: 40.00 per week

Schedule:

* 8 hour shift

Application Question(s):

* We are looking for only local candidates. No relocation allowed !!
* We are accepting only USC & GC Candidates
* Only W2 !! No C2C

Education:

* Bachelor's (Required)

Experience:

* Data engineer: 3 years (Required)
* Data warehouse: 3 years (Required)
* SQL: 3 years (Required)
* ETL: 3 years (Required)

Ability to Commute:

* Richardson, TX 75082 (Required)

Work Location: In person","https://www.indeed.com/cmp/Smartfox-LLC-2","","","","","","","","",""
"c561bf8779c7b582","indeed","https://www.indeed.com/viewjob?jk=c561bf8779c7b582","http://www.indeed.com/job/senior-security-engineer-c561bf8779c7b582","Senior Security Engineer","Protellhirestaffingsolution.com","Dallas, TX, US","fulltime","2024-10-09","direct_data","yearly",130000.0,140000.0,"USD",False,"","","","","","Senior security professional with a firm understanding of cybersecurity principles and Google Cloud platform to work on threat modeling of various Google cloud services such as GKE, Cloud SQL, Cloud Storage etc. Using threat modeling, you will identify threats and specify mitigating controls that will directly reduce the risk of operating in the Google Cloud platform.

**Responsibilities:**

· Threat Modeling using a documented process.

· Development of automation tools as required.

· Maintain a high standard of work in identifying threats and specifying mitigating controls.

· Attending to the lifecycle of identified threats and controls.

· Delivery of threat models and supporting tasks within existing timeframes.

**Required Technical skills:**

· IT experience minimum of 10 years, with minimum a of 4 years in Cyber-Security/Information Security preferably in a highly regulated industry like financial services.

· Threat Modeling (STRIDE, PASTA, Attack trees, tooling, Attack).

· Identifying vulnerabilities using CWE or OWASP.

· Experience working in a cyber-security role.

· Extensive knowledge of Google cloud platform.

· Security practices pertaining to authentication, authorization, logging/monitoring, encryption, infrastructure security, network/segmentation.

· Operating systems and their hardening.

· Development concepts (such as: CICD, Pipelines, SDLC).

· Scripting languages, Infrastructure as Code (Terraform, CloudFormation).

· Operating in a DevOps / agile team structure.

· Understanding of Docker/K8S/serverless/helm.

· Design and review technical architectures.

**Certifications:**

· Google Cloud Architect, Cloud Developer, Data Engineer, Network Engineer, etc.

· Google Professional Cloud Security Engineer.

· CISM, CISSP or any equivalent professional cyber security certification

Job Type: Full-time

Pay: $130,000.00 - $140,000.00 per year

Benefits:

* 401(k)
* 401(k) matching
* Dental insurance
* Health insurance
* Life insurance
* Vision insurance

Schedule:

* 8 hour shift

Experience:

* GKE: 3 years (Required)
* Google cloud services: 4 years (Required)
* Information security: 7 years (Required)
* DevOps: 1 year (Required)

License/Certification:

* Google Professional Cloud Security Engineer (Required)
* CISM (Required)
* CISSP (Required)

Work Location: On the road","https://www.indeed.com/cmp/Protellhirestaffingsolution.com","","","","","","","","",""
"8b2c0911a4f38420","indeed","https://www.indeed.com/viewjob?jk=8b2c0911a4f38420","http://www.indeed.com/job/data-engineer-8b2c0911a4f38420","Data Engineer","Emfoi","Plano, TX, US","contract","2024-10-09","direct_data","hourly",40.0,50.0,"USD",False,"","","","","","Hi

Today we have a new role with us

Position: Data Engineer with AWS

Location: Hybrid - Plano, TX

Client: Data Engineer with AWS - Hybrid - Plano, TX - Ex-Capital One needed with PWC/CAP ONE

Responsibilities :

BS/BA degree or equivalent experience

General: Strong organizational, problem-solving, and critical thinking skills; Strong documentation skills

Coding: Proficiency in Java (Preferable) & Python

Cluster Computing frameworks: Proficiency in Spark

AWS Data Services: Proficiency in Lake formation, Glue ETL (or) EMR, S3, Glue Catalog, Athena, Kinesis (or) MSK, Airflow (or) Lambda + Step Functions + Event Bridge

Data De/Serialization: Expertise in atleast 2 of the formats: Parquet, Iceberg, AVRO, JSON-LD

DevOps: Linux Scripting, Jenkins, Git, CI/CD, JIRA, TDD

AWS Data Security: Good Understanding of security concepts such as: Lake formation, IAM, Service roles, Encryption, KMS, Secrets Manager

Job Type: Contract

Pay: $40.00 - $50.00 per hour

Expected hours: 40 per week

Benefits:

* 401(k)
* Dental insurance
* Health insurance

Schedule:

* 8 hour shift

Work Location: In person","https://www.indeed.com/cmp/Emfoi","","","","","","","","",""
"4b1fc704340c6256","indeed","https://www.indeed.com/viewjob?jk=4b1fc704340c6256","https://jobs.aa.com/job/Dallas-Data-EngineerSr-Data-Engineer%2C-IT-Analytics-TX-75201/1221098500/?feedId=198700&utm_source=Indeed&utm_campaign=AA_Indeed","Data Engineer/Sr Data Engineer, IT Analytics","American Airlines","Dallas, TX, US","","2024-10-08","direct_data","yearly",118236.0,149713.0,"USD",False,"","","","","","**Intro**
---------


Are you ready to explore a world of possibilities, both at work and duringyour time off? Join our American Airlines family, and you’ll travel the world, grow your expertise and become the best version of you. As you embark on a new journey, you’ll tackle challenges with flexibility and grace, learning new skills and advancing your career while having the time of your life. Feel free to enrich both your personal and work life and hop on board!

**Why you'll love this job**
----------------------------

* You will help enable data engineering solutions at AA
* You will be part of a team that innovates.
* This role is a part of the Data Engineering and Analytics team within our Technology group. You’ll bring your data engineering, collaboration and analytics skills to help cultivate a data driven culture by designing and delivering analytics solutions and making data analytics easier and more effective for American Airlines.
**What you'll do**
------------------

*As noted above, this list is intended to reflect the current job but there may be additional essential functions (and certainly non-essential job functions) that are not referenced. Management will modify the job or require other tasks be performed whenever it is deemed appropriate to do so, observing, of course, any legal obligations including any collective bargaining obligations.*


* Work closely with source data application teams and product owners to design, implement, and support analytics solutions that provide insights to make better decisions.
* Implement data migration and data engineering solutions using Azure products and services: (Azure Data Lake Storage, Azure Data Factory, Azure Functions, Event Hub, Azure Stream Analytics, Azure Databricks, etc.) and traditional data warehouse tools.
* Perform multiple aspects involved in the development lifecycle – design, cloud engineering (Infrastructure, network, security, and administration), ingestion, preparation, data modeling, testing, CICD pipelines, performance tuning, deployments, consumption, BI, alerting, prod support.
* Provide technical leadership and collaborate within a team environment as well as work independently.
* Be a part of a DevOps team that completely owns and supports their product.
* Implement batch and streaming data pipelines using cloud technologies.
* Leads development of coding standards, best practices and privacy and security guidelines.
* Mentor others on technical and domain skills to create multi-functional teams.
**All you'll need for success**
-------------------------------

* **Minimum Qualifications- Education & Prior Job Experience**
	+ Bachelor's degree in Computer Science, Computer Engineering, Technology, Information Systems (CIS/MIS), Engineering or related technical discipline, or equivalent experience/training
	+ 3 years software solution development using agile, DevOps, operating in a product model that includes designing, developing, and implementing large-scale applications or data engineering solutions
	+ 3 years data analytics experience using SQL
	+ 2 years of cloud development and data lake experience (prefer Microsoft Azure) including Azure EventHub, Azure Data Factory, Azure Databricks, Azure DevOps, Azure Blob Storage, Azure Data Lake, Azure Power Apps and Power BI.
	+ Combination of Development, Administration & Support experience in several of the following tools/platforms required:
		- Scripting: Python, Spark, Unix, SQL
		- Data Platforms: Teradata, Cassandra, MongoDB, Oracle, SQL Server, ADLS, Snowflake
		- Azure Data Explorer. Administration skills a plus
		- Azure Cloud Technologies: Azure Data Factory, Azure Databricks, Azure Blob Storage, Azure Data Lake, Azure Power Apps and Azure Functions
		- CI/CD: GitHub, Jenkins, Azure DevOps, Terraform
		- BI Analytics Tool Stack - Cognos, Tableau, Power BI, Alteryx, Denodo, and Grafana
		- Data Warehousing: DataStage, Informatica
		- Data Governance and Privacy: Informatica Axon and EDC, BigID
* **Preferred Qualifications- Education & Prior Job Experience**
	+ 5+ years software solution development using agile, dev ops, product model that includes designing, developing, and implementing large-scale applications or data engineering solutions.
	+ 5+ years data analytics experience using SQL
	+ 3+ years full-stack development experience, preferably in Azure
	+ 3+ years of cloud development and data lake experience (prefer Microsoft Azure) including Azure EventHub, Azure Data Factory, Azure Functions, ADX, ASA, Azure Databricks, Azure DevOps, Azure Blob Storage, Azure Data Lake, Azure Power Apps and Power BI.
	+ Airline Industry Experience
* **Skills, Licenses & Certifications**
	+ Expertise with the Azure Technology stack for data management, data ingestion, capture, processing, curation and creating consumption layers.
	+ Expertise in providing practical direction within the Azure Native cloud services.
	+ Azure Development Track Certification (preferred)
	+ Spark Certification (preferred)
**What you'll get**
-------------------


Feel free to take advantage of all that American Airlines has to offer:


* Travel Perks: Ready to explore the world? You, your family and your friends can reach 365 destinations on more than 6,800 daily flights across our global network.
* Health Benefits: On day one, you’ll have access to your health, dental, prescription and vision benefits to help you stay well. And that’s just the start, we also offer virtual doctor visits, flexible spending accounts and more.
* Wellness Programs: We want you to be the best version of yourself – that’s why our wellness programs provide you with all the right tools, resources and support you need.
* 401(k) Program: Available upon hire and, depending on the workgroup, employer contributions to your 401(k) program are available after one year.
* Additional Benefits: Other great benefits include our Employee Assistance Program, pet insurance and discounts on hotels, cars, cruises and more
**Feel free to be yourself at American**
----------------------------------------


From the team members we hire to the customers we serve, inclusion and diversity are the foundation of the dynamic workforce at American Airlines. Our 20+ Employee Business Resource Groups are focused on connecting our team members to our customers, suppliers, communities and shareholders, helping team members reach their full potential and creating an inclusive work environment to meet and exceed the needs of our diverse world.

  



Are you ready to feel a tremendous sense of pride and satisfaction as you do your part to keep the largest airline in the world running smoothly as we care for people on life’s journey? Feel free to be yourself at American.","https://www.indeed.com/cmp/American-Airlines","http://jobs.aa.com","Fort Worth, TX","10,000+","more than $10B (USD)","","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/e3c27172642fbec0755db09067a127bf","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/b647e62fc22a19072353499ba6a0199b","Robert Isom","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/45527035e51c7504eebcf6b8e1f5490a"
"8490bcfb6336d2bd","indeed","https://www.indeed.com/viewjob?jk=8490bcfb6336d2bd","https://glownetworks.hrmdirect.com/employment/view.php?req=3212276&jbsrc=1014&location=60337bc8-7a1f-5f21-e005-e40eff89ddbd","Data Engineer","Glow Networks","Dallas, TX, US","","2024-10-08","direct_data","yearly",100332.0,127043.0,"USD",False,"","","","","","**Job Description**


**Location: PA - Philadelphia, 19102 (Onsite Only)**


**\\*\\*\\*Must be US citizen or Green Card Holder.**


**Data Engineer**  

  

As a technical team member, you will leverage your expertise in cloud technologies and data engineering to ensure high performance and scalability of our data solutions. This position requires a passion for data, a commitment to innovation, and a focus on delivering efficient and effective solutions.  

  

**Key Responsibilities:**


* Ability to build data pipelines for different ingestion patterns.
* Ability to analyze data and support data preparation
* Optimize data capture, ingestion, and processing workflows to enable advanced analytics, data science, and operational intelligence.
* Collaborate with Data Platform Architects and Client Engineers to integrate feature stores, manage model deployment, and implement data preparation workflows.
* Ensure data engineering processes are designed for high performance, scalability, and resource efficiency.
* Provide technical leadership and mentorship, fostering an environment of continuous improvement and innovation.
* Design and maintain data pipelines for streaming data, batch processing, and real-time analytics.
* Implement secure and scalable data capture and ingestion workflows.
* Support data preparation, exploration, and visualization to facilitate data-driven decision-making.
* Work closely with other engineering teams to ensure data pipelines are secure, efficient, and aligned with business requirements.


**Qualifications:**


* Bachelor’s degree in Computer Science, a technical field, or a related business discipline. Equivalent experience, certifications, or training will be considered.
* 2+years of experience with Databricks
* 5+ years of experience in designing and delivering secure cloud solutions.
* Experience with Client and Client Ops preferred
* Experience with Agile methodology
* Strong problem-solving, analytical, and communication skills.","https://www.indeed.com/cmp/Glow-Networks","","","","","","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/c9c4b530878cbdbb5117eda41749610e","","",""
"3688c3598b965ccc","indeed","https://www.indeed.com/viewjob?jk=3688c3598b965ccc","https://wk.wd3.myworkdayjobs.com/en-US/External/job/USA---Coppell-TX/Lead-Product-Software-Engineer----Lead-Cloud-Data-Engineer_R0044181","Lead Product Software Engineer - Lead Cloud Data Engineer","Wolters Kluwer","Coppell, TX, US","fulltime","2024-10-08","direct_data","yearly",125117.0,158426.0,"USD",False,"","","","","","The Lead Cloud Data Engineer in Tax and Accounting innovative and fast-growing Global Audit team is responsible for designing, implementing end to end solutions in Azure Enterprise Data Lake and optimizing data pipelines, ensuring the availability, performance, scalability and security of large-scale data processing systems. This role requires deep understanding of big data technologies, data architecture, infrastructure, CI/CD and data engineering best practices. Experience with Unity Catalog is a bonus. The Lead Cloud Data Engineer will work closely with architects, leads and other stakeholders to support data driven decision making processes.
Experience Required* Minimum 8+ years of experience with 3+ years as a Lead Data Engineer or related role
* 5+ years of demonstrated experience in developing Big Data solutions that support business analytics and data science teams
* 3-5 years of proficient Data ingestion end-to-end implementation of projects in Azure Enterprise Data Lake, Azure Functions, Databricks, Blob Storage, Cosmos DB, Azure stream analytics, Python, SQL
* Extensive hands-on experience implementing Lake house architecture using Data bricks Data Engineering platform, SQL Analytics, Delta Lake, and Unity Catalog
* Good understanding of spark architecture with Databricks structured streaming, setting up Azure with Databricks, managing clusters in Databricks
* Experienced in DevOps and deployment automations with Azure DevOps - ARM, YAML, Terraform
* Strong knowledge and hands-on experience in SQL, Unix shell scripting
* Ability to research latest trends and propose advanced tooling/solutions for Cloud Data Lake & Data Science platforms
* Experience with business intelligence and analytics tools such as OBIEE, PowerBI or Tableau
* Experience with Unity Catalog preferred
* Collaborate applications teams/Business users to develop new pipelines with Cloud data migration methodologies and processes including tools like Azure Data Factory, Event Hub, etc
* Ensure data security and compliance.


Roles & Responsibilities* Lead and implement design of data schemas, drive cloud data lake platform design decisions and development standards and maintain data pipelines for data ingestion, processing, and transformation in Azure
* Extract, transform and load from sources system to Azure Data Storage services using a combination of Azure Data factory, Azure Blob Storage, T-SQL, Pyspark and Azure Databricks
* Drive analysis, architecture, design, governance and development of data warehouse, data lake, and business intelligence solutions
* Integrate data from various sources, ensuring data quality, consistency and reliability.
* Define data requirements, gather and mine large scale structured and unstructured data, and validate data using various tools in a cloud environment.
* Manage and optimize Azure Enterprise data Lake for efficient data storge and processing.
* Develop and optimize ETL processes using Databricks and related tools like Apache Spark
* Implementing data validation and cleansing procedures will ensure the quality, integrity, and dependability of the data.


Benefits:
A comprehensive benefits package that begins your first day of employment. Additional Information: Wolters Kluwer offers great benefits and programs to help meet your needs and balance your work and personal life, including Medical, Dental, & Vision Plans, 401(k), FSA/HSA, Commuter Benefits, Tuition Assistance Plan, Vacation and Sick Time, and Paid Parental Leave. Full details of our benefits are available - https://www.mywolterskluwerbenefits.com/index.html
Diversity Matters
Wolters Kluwer strives for an inclusive company culture in which we attract, develop, and retain diverse talent to achieve our strategy. As a global company, having a diverse workforce is of the utmost importance. We've been recognized by employees as a European Diversity Leader in the Financial Times, as one of Forbes America’s Best Employers for Diversity in 2022, 2021 and 2020 and as one of Forbes America’s Best Employers for Women in 2021, 2020, 2019 and 2018. In 2020, we placed third in the Female Board Index, and were recognized by the European Women on Boards Gender Diversity Index. Wolters Kluwer and all of our subsidiaries, divisions and customer/departments is an Equal Opportunity / Affirmative Action employer.","https://www.indeed.com/cmp/Wolters-Kluwer","https://careers.wolterskluwer.com/de-de","Alphen aan den Rijn","10,000+","$1B to $5B (USD)","Wolters Kluwer is a global provider of professional information, software solutions.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/0e686c67da1bd46cee95a528fd1cb51e","","Nancy McKinstry","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/8ef379ad69c27c9d24ebc202166b6af8"
"5d2fde3f4626d8ef","indeed","https://www.indeed.com/viewjob?jk=5d2fde3f4626d8ef","https://inabia.applytojob.com/apply/Y9Zedv4m8R/Data-Engineer?source=INDE&~","Data Engineer","Inabia Software & Consulting Inc.","McKinney, TX, US","","2024-10-08","","hourly","","","USD",False,"","","","","","**Job Title:** Data Engineer
  
**Location:** McKinney, TX (Hybrid)(need only locals)
  
**Duration:** 12+ months
  
Rate $45/hr on c2c.
  
Need 10 plus years candidate.
  
  

**Job Description:**  

At least 5 yrs. of experience in Data Engineering and Big data
  
Strong knowledge in SQL
  
Expertise in Redshift and AWS
  
Experience in Python
  
  

Y9Zedv4m8R","https://www.indeed.com/cmp/Inabia-Software-&-Consulting-Inc.","https://www.inabia.com","Redmond","11 to 50","$1M to $5M (USD)","","","","",""
"58c40711bcec5565","indeed","https://www.indeed.com/viewjob?jk=58c40711bcec5565","https://d.hodes.com/r/tp2?e=se&tv=pixel_tracker&aid=jpmorgan&p=web&se_ca=indeed&se_ac=click&se_la=21123690&u=https%3A%2F%2Fjpmc.fa.oraclecloud.com%2FhcmUI%2FCandidateExperience%2Fen%2Fsites%2FCX_1001%2Fjob%2F210563222%3Futm_medium%3Djobboard%26utm_campaign%3DDefault%2520Campaign%26utm_content%3DData%2520Engineer%26utm_term%3D210563222%26utm_source%3DIndeed&se_pr=d378060057c4b216&se_va=10789&tr_af=organic&ti_id=2245_210563222","Data Engineer","JPMorganChase","Plano, TX, US","fulltime","2024-10-07","","","","","",False,"","","","","","**JOB DESCRIPTION**  

DESCRIPTION:


Duties: Identify, analyze and interpret trends or patterns in complex datasets. Acquire data from primary and secondary platforms. Transform existing ETL logic into hadoop/AWS platform compatible data load. Innovate new solutions/technologies to analyze, transform and validate data. Establish and enforce guidelines to ensure quality, consistency and completeness of data. Partner with stakeholders to understand business requirement on a daily basis to stay focused on common goals. Analyze, design and code business related solutions as well as architectural changes, using agile methodologies resulting software solutions delivered in time and in budget. Work with development teams, using agile techniques, object oriented development, scripting languages and software development life cycle.


QUALIFICATIONS:


Minimum education and experience required: Master's degree in Business Analytics, Data Analytics, Data Science, Computer Science, Information Technology, or related field of study plus 3 years of experience in the job offered or as a Data Engineer, Data Analyst, Data Scientist, or related occupation.


Skills Required: Requires experience in the following: Linux; Unix; Windows; Agile SDLC; Hybrid SDLC; Data Architecture Disciplines; Infrastructure Architecture Disciplines; Apache Kafka; Docker; Jenkins; Python; Shell Scripting; SQL; Bootstrap; REST; JSON; Kubernetes; AWS Cloud Services; Hadoop; MongoDB; Oracle; Teradata; Apache Spark; Qlikview; Splunk; Tableau; GIT; Unit Testing; User Acceptance Testing.


Job Location: 8181 Communications Pkwy, Plano, TX 75024. Telecommuting permitted up to 40% of the week.


**ABOUT US**  


JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world’s most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.
We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. Those in eligible roles may receive commission-based pay and/or discretionary incentive compensation awarded in recognition of individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.


We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. We also make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as mental health or physical disability needs. Visit our FAQs for more information about requesting an accommodation.


JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans

  

  

  

**ABOUT THE TEAM**  

  

Commercial Banking is focused on helping our clients succeed and making a positive difference in our communities. We provide credit and financing, treasury and payment services, international banking and real estate services to clients including corporations, municipalities, institutions, real estate investors and owners, and nonprofit organizations.","https://www.indeed.com/cmp/Jpmorganchase-2","https://www.jpmorganchase.com/","New York, NY","10,000+","more than $10B (USD)","Headquartered in New York City, JPMorgan Chase is the largest bank in the United States.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/62e186e96c7550325814ef6880fae379","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/e5f2926890cd9374a94016d6281c3e40","",""
"490fdc7bb0c215dd","indeed","https://www.indeed.com/viewjob?jk=490fdc7bb0c215dd","https://www.capitalonecareers.com/job/-/-/1732/70917503040","Senior Data Engineer (Python, SQL, Spark)","Capital One","Plano, TX, US","fulltime","2024-10-07","","","","","",False,"","","","","RecruitingAccommodation@capitalone.com, Careers@capitalone.com","Plano 6 (31066), United States of America, Plano, Texas
Senior Data Engineer (Python, SQL, Spark)
Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking Data Engineers who are passionate about marrying data with emerging technologies. As a Capital One Data Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One.

**What You’ll Do:**

* Be a part of team designing and building Enterprise Level scalable, low-latency, fault-tolerant streaming data platform that provides meaningful and timely insights
* Build the next generation Distributed Streaming Data Pipelines and Analytics Data Stores using streaming frameworks (Flink, Spark Streaming) using programming languages like Java, Scala, Python
* Be part of a group of engineers building data pipelines using big data technologies (Spark, Flink, Kafka, Snowflake, AWS Big Data Services, Snowflake, Redshift) on medium to large scale datasets
* Work in a creative & collaborative environment driven by agile methodologies with focus on CI/CD, Application Resiliency Standards, and partnership with Cyber & Security teams
* Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community
* Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies
* Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems
* Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment
* Perform unit tests and conduct reviews with other team members to make sure your code is rigorously designed, elegantly coded, and effectively tuned for performance

**Basic Qualifications:**

* Bachelor’s Degree
* At least 3 years of experience in application development (Internship experience does not apply)
* At least 1 year of experience in big data technologies

**Preferred Qualifications:**

* 5+ years of experience in application development including Python, SQL, Scala, or Java
* 2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud)
* 3+ years experience with Distributed data computing tools (Kafka, Spark, Flink)
* 2+ year experience working on real-time data and streaming applications
* 2+ years of experience with NoSQL implementation (DynamoDB, OpenSearch)
* 2+ years of data warehousing experience (Redshift or Snowflake)
* 3+ years of experience with UNIX/Linux including basic commands and shell scripting
* 2+ years of experience with Agile engineering practices

*At this time, Capital One will not sponsor a new applicant for employment authorization, or offer any immigration related support for this position (i.e. H1B, F-1 OPT, F-1 STEM OPT, F-1 CPT, J-1, TN, or another type of work authorization).*


Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.


This role is expected to accept applications for a minimum of 5 business days.
No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.
If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.


For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com


Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.


Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).","https://www.indeed.com/cmp/Capital-One","https://www.capitalonecareers.com","Mc Lean, VA","10,000+","more than $10B (USD)","Help change banking for good while getting opportunities, support and benefits you need.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/231e72fed9b08e7f098ab59080cc2dd6","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/d4ea35e3c8e9f1cf00273e94311e3d01","Richard Fairbank","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/ade05761927a23791c675cd8e04b9df9"
"5cfc2bfd30c1f034","indeed","https://www.indeed.com/viewjob?jk=5cfc2bfd30c1f034","https://careers.frostbank.com/us/en/job/R241863/Data-Engineer-III-Business-Intelligence","DATA ENGINEER III – BUSINESS INTELLIGENCE","Frost","Richardson, TX, US","fulltime","2024-10-07","direct_data","yearly",115566.0,146332.0,"USD",False,"","","Banks And Financial Services","","","***It’s about putting our best to the test.***

Are you described as someone with an inquisitive mind and an innovative personality? Are you never satisfied with good enough? Does solving complex problems and ensuring top-quality systems excite you? If so, being a Data Engineer III - Business Intelligence with Frost could be for you.


At Frost, it’s about more than a job. It’s about having a flourishing career where you can thrive, both in and out of work. At Frost, we’re committed to fostering an environment that reflects our values and encourages team members to be the best they can be. In joining our adaptable, integrity-driven team, you’ll become part of Frost’s over 150-year legacy of providing unparalleled banking services.

**Who you are:**

As a **Data Engineer III - Business Intelligence**, *you* will lead the development and implementation of reporting and analytics dashboards. You’ll play an important role in designing and building business intelligence solutions. You’ll use your strong problem-solving skills to ensure that the systems are performing optimally and meet our high standards. You believe in effective communication and will have the opportunity to address potential problems and solutions to complex issues.

**What you’ll do****:**

* Develop views/reports/cubes to support complex and critical BI solutions.
* Perform Ad Hoc data requests for business users and Executive Management as needed
* Assist BI management in working with business sponsors and Executive Management to support key initiatives
* Work with BI/Data Warehouse Analysts and ETL developers to understand requirements, sources of data, and transformation rules
* Assist in establishing standards for the design, coding, and testing of deliverables
* Develop and enforce data governance policies and standards
* Provide guidance to other Data Engineers as needed
* Stay up to date with industry trends and new technologies in data analytics
* Always take action using integrity, caring, and excellence to achieve all-win outcomes

**What you’ll need:**

* Bachelor's degree in Computer Science, Information Technology, or related field
* 4+ Years of experience as a Business Intelligence Analyst, Developer or in a related role
* Strong knowledge of Cognos Analytics and Tableau tools
* Advanced understanding of database technologies such as SQL and NoSQL
* Knowledge of data modeling and schema design
* Strong problem-solving and analytical skills
* Excellent written and verbal communication skills

**Our Benefits:**


At Frost, we care about your health, your family, and your future and strive to have our benefits reflect that. This includes:

* Medical, dental, vision, long-term disability, and life insurance
* 401(k) matching
* Generous holiday and paid time off schedule
* Tuition reimbursement
* Extensive health and wellness programs, including our Employee Assistance Program
* Referral bonus program + more!


Since 1868, Frost has dedicated their expertise to provide exceptional banking, investment, and insurance services to businesses and individuals throughout Texas. Frost is one of the 50 largest U.S. banks by asset size and is a leader in banking customer satisfaction. At Frost, it’s about being part of something bigger. If this sounds like you, we encourage you to apply and see what’s possible at Frost.


#LI-MF1


#LI-Hybrid","https://www.indeed.com/cmp/Frost","https://www.frostbank.com","San Antonio Texas, United States","1,001 to 5,000","$1B to $5B (USD)","","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/9f0a82cd39ee5cae7084ed06f2794ead","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/6dfddd46d64e9f81df49dca773a0b9bc","Phillip D. Green",""
"909b264288b882f9","indeed","https://www.indeed.com/viewjob?jk=909b264288b882f9","https://pepsicojobs.com/jobs/334908/job?utm_source=indeed_integration&iis=Job%20Board&iisn=Indeed&indeed-apply-token=73a2d2b2a8d6d5c0a62696875eaebd669103652d3f0c2cd5445d3e66b1592b0f","IBP Sustainment Engineer","PepsiCo Beverages North America","Plano, TX, US","","2024-10-04","direct_data","yearly",102800.0,172100.0,"USD",False,"","","","","","Overview:

PepsiCo’s Sustain & Operations team, as part of the Digital Products and Applications (DPA) organization, delivers and sustains digital products across Strategy and Transformation’s core priorities to accelerate PepsiCo’s digital transformation. One the key remits of this team within the organization is to drive proactive risk management, improve data workflow automation and operational excellence of digital products by ensuring an optimal end-user experience through timely resolution of incidents and application downtime.
Responsibilities:
* Report directly to Sustain Lead and partner with our Data & Analytics team leadership on ITSM & SDLC ways of working
* Provide advanced technical support for complex data integration issues & root cause analysis.
* Act as 1st layer of escalation in response to data incidents & requests to support Sustainment and Operations Leadership
* Partner with the Data Analytics capabilities team to review all data interface solutions, data flows, proactive monitoring, configuration, thresholds and timings
* Ensure a data run book is documented and up to date and accessible for all support team members during triage and for onboarding purposes
* Escalate issues to & from external Capability & Sector Deployment teams, as necessary.
* Identify opportunities for process improvements and work with team to implement changes to enhance efficiency and customer satisfaction.
* Stay updated on industry trends and advancements in application support technologies.
* Review the service reports in accordance with SLA agreements partnering with the CSM
* Drive standard support processes and best practices to enhance service quality partnering with external
* Capability teams' guidance
* Act as a liaison between DP&A Sustain & Operations teams to reduce obstacles and improve visibility on external risks
* Act as a liaison between Capabilities & Sector Deployment teams to escalate and reduce global risks or respond to priority incidents (MIMs)
* Lead discussions pertaining to Service Requests requiring changes to current Production environment with Data Leads & Product teams
* Plan and monitor smooth transition of data interfaces from Hypercare to Production Support (Transition to Sustain).
* Partner with Engineering Teams Release Manager to review Hypercare Checklist
* Participate and assist in driving Quality Assurance activities where applicable
* Drive the audit and alignment of the Hypercare Checklist and confirmed completed successfully with Sustainment Manager
* Review the strategy and planning of system maintenance and updates aligned with global/sector planned downtime calendars
* Review impact and assessment of all planned maintenance across applications and shared capabilities with Operations Lead
* Review all vendor management agreements & partner with Data Management to resolve issues or improve relationship
* Ensure planned service requests are executed by partner Capability teams in a timely manner to prepare future deployment readiness across all environments in partnership with Sustain Lead &
* Operations Lead
* Review and validate Service Level reporting meets SLAs
* Celebrate success with SMILES awards or providing positive feedback to vendors & peers
* Share bright and hot spots with Sustain Lead that require celebration or attention
* Drive ideation of increased monitoring in existing or future observability reporting solutions
* Assist in the data capture and validation for Executive Summary reports on Sustain & Operations team standard KPIs using dashboards

**Compensation and Benefits:**  

* The expected compensation range for this position is between $102,800 - $172,100.
* Location, confirmed job-related skills, experience, and education will be considered in setting actual starting salary. Your recruiter can share more about the specific salary range during the hiring process.
* Bonus based on performance and eligibility target payout is 12% of annual salary paid out annually.
* Paid time off subject to eligibility, including paid parental leave, vacation, sick, and bereavement.
* In addition to salary, PepsiCo offers a comprehensive benefits package to support our employees and their families, subject to elections and eligibility: Medical, Dental, Vision, Disability, Health, and Dependent Care Reimbursement Accounts, Employee Assistance Program (EAP), Insurance (Accident, Group Legal, Life), Defined Contribution Retirement Plan.

Qualifications:
* 8 years of work experience, or 3-5 years of experience as a Data Engineer, Data Analytics Specialist, Data Steward, Data Scientist, or Data Architect, either in CPG industry or with a Top-Tier consulting firm
* The ideal Engineer will be highly quantitative, have great judgment, able to connect dots across workstreams, and efficiently work cross-functionally across teams to ensure data solutions are meeting customer/end-user expectations
* Bachelors degree required
* The candidate will take a pragmatic approach resolving data related incidents, including the ability to triangulate root causes and work effectively with external and internal teams to meet objectives.
* Exceptional business relationship skills including the ability to communicate effectively both internally and externally. You can communicate complex technical data to a non-technical person in a concise, clear, and easily understood manner.
* A firm understanding of SRE (Software Reliability Engineering) and IT Service Management (ITSM) processes with a track record for monitoring and triaging software incidents. You recognize the difference between resolving incidents, providing a seamless customer/end-user experience and proactively identifying and mitigating areas of risk
* Experience in leading high-performing teams
* Deep hands-on technical expertise, excellent verbal and written communication skills
* Sharp analytical abilities and proven process engineering & data analytical dashboarding skills

**Differentiating Competencies Required** **Driving for Results:** Demonstrates perseverance and resilience in the pursuit of goals. Confronts and works to resolve tough issues. Exhibits a “can-do” attitude and a willingness to take on significant challenges **Decision Making:** Quickly analyses complex problems to find actionable, pragmatic solutions. Sees connections in data, events, trends, etc. Consistently works against the right priorities **Collaborating:** Collaborates well with others to deliver results. Keeps others informed so there are no unnecessary surprises. Effectively listens to and understands what other people are saying.
  

Communicating and Influencing: Ability to build convincing, persuasive, and logical storyboards. Strong executive presence. Able to communicate effectively and succinctly, both verbally and on paper. **Motivating and Inspiring Others:** Demonstrates a sense of passion, enjoyment, and pride about their work. Demonstrates a positive attitude in the workplace. Embraces and adapts well to change. Creates a work environment that makes work rewarding and enjoyable. **Technical Knowledge and Skills:** Strong ServiceNow, Terraform, Octopus, AKS, Python, AppDynamics/Datadog/ELK Stack, Pager Duty or other AIOps toolsets skillsets.
>:

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.  

PepsiCo is an Equal Opportunity Employer: Female / Minority / Disability / Protected Veteran / Sexual Orientation / Gender Identity  

If you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law & EEO is the Law Supplement documents. View PepsiCo EEO Policy.  

 Please view our Pay Transparency Statement","https://www.indeed.com/cmp/PepsiCo","http://www.pepsico.com","Purchase, NY","10,000+","more than $10B (USD)","PepsiCo products are enjoyed by consumers more than one billion times a day in more than 200 countries and territories around the world.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/0fb965a11f33a21c3ef029f421a814cd","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/3e18ac1b8f01ab69489e1768e32e67a3","Ramon Laguarta","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/22714a23c6ab698430d9c1e3e6ac1060"
"a38350dce2019146","indeed","https://www.indeed.com/viewjob?jk=a38350dce2019146","https://recruiting.paylocity.com/recruiting/jobs/Details/2775260/Nuvem/Sr-Azure-Data-Engineer?source=Indeed_Feed","Sr. Azure Data Engineer","Nuvem","Plano, TX, US","fulltime","2024-10-04","direct_data","yearly",115000.0,150000.0,"USD",False,"","","","","","Description:

 As the Sr Azure Data Engineer, you will focus on the continuous delivery of cloud-based ETL/ELT data processes and implementations. The ideal candidate will have the necessary technology and communication skills to manage hands-on highly visible and complex projects from start to finish. This role requires proficiency with developing realistic project plans to meet delivery objectives and the ability to maintain and establish required service levels. You will be a part of a fast-paced, entrepreneurial environment, which thrives on delivering transformational solutions and maximizing value to their stakeholders. As a participant of the cloud transformation process, you must be passionate about data, be a change agent and mentor, and a strong collaborator with the various business and technology stake holders. **Hybrid Role – 3 days in office (T-TH)**

* Data sourcing and source system analysis.
* Implement and build data pipelines for a data warehouse using Azure Data Engineering Stack – Adeptia (Third Party ETL/ELT tool), Azure Data Factory, Azure Synapse and ADLS.
* Combine technical expertise and problem-solving passion to work closely with clients, turning complex ideas into end-to-end solutions that transform our business offerings.
* Lead, design, develop and deliver large-scale data systems, data processing and data transformation projects that deliver business value for clients.
* Conduct technical feasibility assessments and provide project estimates for the design and development of the solution.
* Provide technical inputs to agile processes, such as user story, and task definition to resolve issues and remove barriers throughout the lifecycle of client engagements.
* Automate data platform operations and manage the post-production system and processes.
* Mentor, help and grow junior team members.
* Test, plan, creation and test programming using automated testing frameworks, data validation and quality frameworks, and data lineage frameworks.


EEO


Requirements:
* Bachelor’s or Master’s degree in Math, Statistics, Economics, Computer Science, or any other quantitative field.
* 5+ years of experience with data integration, and database technologies, including NoSQL, SQL Server, Azure SQL DB, Postgres, Cosmos DB’s etc.
* 5+ years of experience with Azure Cloud PaaS/SaaS solutions and managed services serverless technologies, including Azure Data Factory, Synapse Analytics and ADLS
* 5+ years of experience in a role encompassing industry standard ETL development techniques and implementation of end-to-end data pipelines.
* Experience with data analysis and profiling of source data while developing or
* Experience in data warehousing methodologies and dimensional data modeling.
* Experience working with Azure DevOps code repositories and continuous integration and continuous delivery.
* Hands-on experience with Azure Data Engineering Stack - ADF, Synapse, SQL, Data Lakehouse, Python Notebooks, Microsoft Fabrics
* Hands on knowledge of data validation, cleansing, transformation, consolidation, de-duplication, aggregation, de-aggregation, and enrichment

**Preferred:**

* Coding experience: Python, C#, PowerShell for Data analysis purpose
* Experience with reporting data visualization tools such as Power BI or Tableau
* Exposure to MDM and metadata management including data catalogs using Microsoft Purview

**It will be a plus:**

* Knowledge of HIPAA and SOC2
* HealthCare domain knowledge","https://www.indeed.com/cmp/Nuvem-3","http://www.nuvem.com","","","","","","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/5bee18292b4eb89021732c2983ed6643","",""
"185c5b123af78ec9","indeed","https://www.indeed.com/viewjob?jk=185c5b123af78ec9","http://www.indeed.com/job/data-engineer-185c5b123af78ec9","Data Engineer","Ideal Business Advisors","McKinney, TX, US","fulltime, contract","2024-10-04","direct_data","yearly",115249.0,189968.0,"USD",False,"","","","","","Join our innovative team as a Data Engineer, where you will play a pivotal role in shaping the future of our data infrastructure. This position offers a unique opportunity to design, develop, and maintain cutting-edge data pipelines that drive our enterprise data products. You will work closely with visionary product managers, collaborate with top-tier Principal Architects, and join an elite Data Platform team. Your efforts will be key in integrating data from vital systems, including banking, Salesforce CRM, and mortgage platforms, ensuring our data models are robust and forward-thinking.

**Key Responsibilities**

· **Innovate and Build:** Design, develop, and maintain state-of-the-art data pipelines to support our next-generation enterprise data products.

· **Collaborate and Create:** Work with product managers to translate requirements into reality, ensuring our data solutions meet and exceed expectations.

· **Lead and Inspire:** Partner with cross-functional teams, including Principal Architects and the Data Platform team, to champion best practices and drive our data strategy forward.

· **Model and Transform:** Apply your expertise in data modeling to develop raw, canonical, and semantic data zones that set new standards for excellence.

· **Communicate and Influence:** Craft compelling narratives around our ingested data, making complex information accessible and impactful.

· **Integrate and Elevate:** Seamlessly integrate data from core banking systems, Salesforce CRM, and mortgage origination and servicing platforms.

· **Utilize Cutting-Edge Tools:** Leverage a blend of legacy and modern platforms, including MS-SQL, Snowflake, and Azure SQL DB, to deliver superior data solutions.

· **Transform and Optimize:** Use advanced ETL tools such as SSIS, ADF, and DBT to ensure data is transformed and optimized for maximum impact.

· **Automate and Streamline:** Implement CI/CD practices using Azure DevOps and ADO to automate and streamline our data processes.

· **Manage and Maintain:** Utilize container tools like AKS to expertly manage the data lifecycle expertly, ensuring reliability and scalability.

**Qualifications:**

· **Educational Excellence:** Bachelor’s degree in Computer Science, Information Technology, or a related field.

· **Experience and Expertise:** 5+ years in data engineering or a related role, with 3+ years in SQL programming and proficiency in programming languages like Python, Java, or C#.

· **Technical Mastery:** 2+ years using Git, with strong proficiency in MS-SQL, Snowflake, and Azure SQL DB.

· **Hands-On Skills:** Extensive experience with ETL tools such as SSIS, ADF, and DBT, and familiarity with CI/CD tools like Azure DevOps and ADO.

· **Containerization Proficiency:** Experience with container tools, specifically AKS, and streaming processing technologies such as Kafka, Spark Streaming, and Azure Service Bus.

· **Data Savvy:** Deep understanding of data warehousing, data modeling, and data architecture principles.

· **Communication Skills:** Exceptional ability to convey the story of data clearly and effectively.

· **Team Player:** Proven track record of working collaboratively in cross-functional team environments.

· Ability to work 3 days in office in McKinney, Texas.

**Preferred Skills:**

· **Industry Insight:** Experience in banking, mortgage, treasury, wealth management, or insurance industries.

· **Platform Agility:** Familiarity with both legacy and modern data platforms.

· **Problem Solver:** Strong analytical skills with an eye for detail and a knack for solving complex problems.

Job Types: Full-time, Contract

Pay: $115,249.00 - $189,968.00 per year

Experience:

* Informatica: 1 year (Preferred)
* SQL: 1 year (Preferred)
* Data warehouse: 1 year (Preferred)

Ability to Relocate:

* McKinney, TX 75069: Relocate before starting work (Required)

Work Location: In person","https://www.indeed.com/cmp/Ideal-Business-Advisors","","","","","","","","",""
"e8a29074651b1f5e","indeed","https://www.indeed.com/viewjob?jk=e8a29074651b1f5e","https://accenture.com/us-en/careers/jobdetails?id=R00217862_en","Data Engineering Senior Analyst","Accenture","Irving, TX, US","fulltime","2024-10-04","","","","","",False,"","","","","","**We are:**


The Advanced Technology Centers (ATCs) is the engine for reinvention in our clients’ transformation journey. Powered by more than 255,000\\* people across 24 countries, ATCs will provide our clients seamless access to industry insights and innovative technology solutions.

**Stronger together!**


The Advanced Technology Centers (ATCs) make tremendous impact in solving our clients’ business problems leveraging Innovation, Intelligence, Industry insights, new IT and new technology skills. Now, with the global environment changing at a faster pace, our clients are facing unprecedented challenges and they need us more than ever before. As a Network, ATCs are positioned to unlock greater opportunities and exponential value for our clients.

**The value for our clients and our people**


For our clients, the Network provides the strength of our geographic diversity, greater resilience, and seamless access to the deepest industry knowledge, the latest in Gen AI solutions, and tech expertise from around the world.


For our people, it brings an opportunity to shape truly boundaryless career paths in a highly collaborative team of experts where they can learn from each other and solve the world’s most complex client challenges.

**You are:**


An experienced Data Engineer

**The Work:**


There will never be a typical day and that’s why people love it here. The opportunities to make a difference within exciting client initiatives are unlimited in the ever-changing technology landscape. You will be part of a highly collaborative and growing network of technology and data experts, who are taking on today’s biggest, most complex business challenges using the latest data and analytics technologies. We will nurture your talent in an inclusive culture that values diversity. You will have an opportunity to work in roles such as Data Scientist, Data Engineer, or Chief Data Officer covering all aspects of Data including Data Management, Data Governance, Data Intelligence, Knowledge Graphs, and IoT. Come grow your career in Technology at Accenture!


This role will requires 3 days per week at the local office.


The preferred hiring locations for this role are Columbus, OH; Tampa, FL and Nashville, TN. May consider qualified applicants in Atlanta or Dallas.


  

**What you need**:

* Minimum of 1 year of experience using any of the following: Python, Spark/ Spark SQL, Hive, or Databricks
* A Bachelor’s Degree or equivalent work experience (12 years) or an Associate’s Degree with 6 years of work experience

**Bonus points if you have:**

* Experience with any language such as C#, Golang, Java, React JS or others
* Experience with any of the following: NoSQL / DW CosmosDB, Synapse, Cassandra, DynomoDB, or PostgreSQL
* Experience working with AWS/GCP/Microsoft Azure
* Create a value chain to help address the challenges of acquiring data, evaluating its value, distilling & analyzing.
* Lead data modeling activities to capture and model data requirements, business rules, and logical and physical models
* Examine data from multiple sources, and share insights which provide competitive advantage


Compensation at Accenture varies depending on a wide array of factors, which may include but are not limited to the specific office location, role, skill set, and level of experience. As required by local law, Accenture provides a reasonable range of compensation for roles that may be hired in California, Colorado, District of Columbia, Maryland, New York or Washington as set forth below.  

We accept applications on an on-going basis and there is no fixed deadline to apply.


Information on benefits is here.


Role Location Hourly Salary Range


California $26.20 to $77.88


Colorado $26.20 to $67.31


District of Columbia $27.93 to $71.63


New York $24.28 to $77.88


Maryland $24.28 to $62.31


Washington $27.93 to $71.63

 ***What We Believe***

 *We have an unwavering commitment to diversity with the aim that every one of our people has a full sense of belonging within our organization. As a business imperative, every person at Accenture has the responsibility to create and sustain an inclusive environment.*

 *Inclusion and diversity are fundamental to our culture and core values. Our rich diversity makes us more innovative and more creative, which helps us better serve our clients and our communities.* *Read more here*

 ***Equal Employment Opportunity Statement***

 *Accenture is an Equal Opportunity Employer. We believe that no one should be discriminated against because of their differences, such as age, disability, ethnicity, gender, gender identity and expression, religion or sexual orientation.*

 *All employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law.*

 *Accenture is committed to providing veteran employment opportunities to our service men and women.*

 *For details, view a copy of the* *Accenture Equal Employment Opportunity and Affirmative Action Policy Statement**.*

 ***Requesting An Accommodation***

 *Accenture is committed to providing equal employment opportunities for persons with disabilities or religious observances, including reasonable accommodation when needed. If you are hired by Accenture and require accommodation to perform the essential functions of your role, you will be asked to participate in our reasonable accommodation process. Accommodations made to facilitate the recruiting process are not a guarantee of future or continued accommodations once hired.*

 *If you would like to be considered for employment opportunities with Accenture and have accommodation needs for a disability or religious observance, please call us toll free at 1 (877) 889-9009, send us an* *email* *or speak with your recruiter.*

 ***Other Employment Statements***

 *Applicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States.*

 *Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration.*

 *Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.*

 *The Company will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. Additionally, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the Company's legal duty to furnish information.*","https://www.indeed.com/cmp/Accenture","https://www.accenture.com","Dublin, Dublin","10,000+","more than $10B (USD)","With 505,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/e1bd47363c07b64a9578dbf71edbf4e4","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/f7be8a6231fd0ad5ccfe0d58b57e6ac3","Julie Sweet","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/2c0997a3c011aace284cc9a6fb9b0114"
"313293aeb0478e14","indeed","https://www.indeed.com/viewjob?jk=313293aeb0478e14","https://careers.vizio.com/jobs/3306/job?utm_source=indeed_integration&iis=Job%20Board&iisn=Indeed&indeed-apply-token=73a2d2b2a8d6d5c0a62696875eaebd669103652d3f0c2cd5445d3e66b1592b0f","Senior Data Engineer","VIZIO","Dallas, TX, US","fulltime","2024-10-04","direct_data","yearly",110000.0,142000.0,"USD",False,"","","","","","About the Team:

We are seeking an enthusiastic Senior Data Engineer to help build the next generation of data infrastructure at Vizio. This role will develop and maintain core infrastructure critical to optimizing our data systems and platforms. This is an individual contributor position and will report directly to the Manager of Data Engineering. We are a close-knit team, focused on solving challenging problems that make a difference in our business. We concentrate on high-impact, high-value development, and in this role, you’ll be delivering the software that helps us grow. We pride ourselves on working in a collaborative environment, and to do so we are in our Denver and Dallas offices 5 days a week.  


What You Will Do:
**TOP 5 JOB RESPONSIBILITIES:**

* **Research and Design:** Research industry-leading technologies as part of design and project construction.
* **Collaboration:** Working with stakeholders including data, product and executive teams and assisting them with data-related technical issues.
* **Implementation:** Building required infrastructure for optimal extraction, transformation, and loading of data from various data sources while supporting our CICD process.
* **Analytical Tools:** Knowledge on analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including operational efficiency.
* **Review:** Regularly review team processes to identify areas of improvement, offer solutions, and increase team success and positive workplace culture.

**WHAT SUCCESS LOOKS LIKE:**

**By 3 Months…** You are up to date on the ad tech industry and the role that your team plays in achieving business objectives.


**By 6 months**… You successfully complete tasks critical to delivering the team's quarterly initiatives while contributing unique perspectives to the design of future projects.

  



**CORE COMPETENCIES:**

* You are motivated.
* You are a self-starter.
* You are a team player.
* You have excellent communication skills.


About You:
* 5+ years of professional experience as a Data Engineer
* Experience with Cloud Services (AWS/GCP/Azure)
* Experience working in environments with multiple development languages (Python/Java)
* Familiarity and experience using data warehousing solutions.
* CI/Automation testing experience
* Agile or Scrum SDLC experience
* Bachelor’s degree in CS or a related field required.


About VIZIO:
**We are Beautifully Simple.**
Headquartered in Irvine, California, VIZIO is a leading HDTV brand in America and the #1 Sound Bar Brand in America. VIZIO's mission is to deliver high performance, smarter products with the latest innovations at a significant savings that we can pass along to our consumers. Our loyal following and industry-wide praise continues to grow as we redefine what it means to be smart.  

VIZIO, Inc. is an Equal Opportunity Employer committed to diversity in the workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, gender expression, national origin, protected veteran status, or any other basis protected by applicable law, and will not be discriminated against on the basis of disability.  

We do not accept unsolicited agency resumes. We will not pay fees to any third-party agency, outside recruiter or firm without a mutually agreed-upon contract and will not be responsible for any agency fees associated with unsolicited resumes. Unsolicited resumes will be considered our property and will be processed accordingly. **For Colorado-based employment:** The target salary range is $110,000 - $142,000. In addition to base salary, the compensation package also includes eligibility for an annual bonus, as well as equity and a range of medical, dental, vision and other benefits.","https://www.indeed.com/cmp/Vizio-5","http://www.vizio.com","Irvine, CA","501 to 1,000","$1B to $5B (USD)","Founded in Southern California, VIZIO is a leading HDTV company and America's #1 Sound Bar Brand. At VIZIO, we believe that technology should make life simpler.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/bad701e0d08edb1815ec31b42fab68a7","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/8251415e48113047792ea3a0d63510f5","William Wang","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/f46f01ea89ce9b629a3e8d7a911a2b97"
"21279cda0cc92ec1","indeed","https://www.indeed.com/viewjob?jk=21279cda0cc92ec1","http://www.indeed.com/job/data-engineer-21279cda0cc92ec1","Data Engineer","ConglomerateIT LLC","Dallas, TX, US","contract","2024-10-04","direct_data","hourly",45.0,48.0,"USD",False,"","","","","","**Role:** Data Engineer

**Location:** Dallas, TX (Hybrid)

**Work Authorization**: USC, GC, H4-EAD, H1-B Transfer & GC-EAD

**Job Type:** Contract

**Tax Term:** W2/1099

**Job Description:**

We are seeking a skilled Data Engineer with a strong background in Python, SQL, ETL automation, and Unix/Linux scripting. The ideal candidate will have expertise in data modeling, warehousing concepts, and hands-on experience with AWS services, DevOps, and CI/CD tools. This role requires a technical professional with the ability to manage, automate, and optimize complex data pipelines.

**Key Responsibilities**:

* Design, develop, and maintain ETL processes for data integration and automation.
* Implement data modeling and data warehousing solutions to optimize data architecture.
* Collaborate with cross-functional teams to integrate data from multiple sources using Python and SQL.
* Develop and maintain scripts for Unix/Linux environments to support data processing workflows.
* Utilize AWS services like S3, Athena, EMR, Glue, Redshift, Kinesis, and SageMaker to build and manage scalable data solutions.
* Perform testing using Ab Initio and Informatica to ensure data integrity and performance.
* Apply DevOps and DataOps best practices for CI/CD using tools like Jenkins and GitLab.
* Troubleshoot and resolve issues in data pipelines to ensure optimal performance.

**Skills and Qualifications**:

* Proficient in Python, SQL, and Unix/Linux scripting.
* Strong experience with ETL automation and data modeling concepts.
* In-depth knowledge of AWS services (S3, Athena, EMR, Glue, Redshift, Kinesis, SageMaker).
* Hands-on experience with testing tools like Ab Initio and Informatica.
* Familiarity with DevOps practices and CI/CD tools (Jenkins, GitLab).
* Strong analytical and problem-solving skills.
* Excellent communication and collaboration skills.

Job Type: Contract

Pay: $45.00 - $48.00 per hour

Expected hours: 40 per week

Benefits:

* 401(k)
* Dental insurance
* Health insurance

Schedule:

* Monday to Friday

Application Question(s):

* Are you willing to work on w2 or 1099? (NO C2C )
* How many years of experience do you have with data engineering?
* How many years of experience do you have with AWS services such as S3, Athena, EMR, Glue, Redshift, Kinesis, and SageMaker?
* How many years of work experience do you have with Python (Programming Language)?
* How many years of experience do you have with ETL automation?
* How many years of experience do you have with AB Initio and Informatica?

Experience:

* Informatica: 8 years (Required)
* SQL: 7 years (Required)
* Data warehouse: 9 years (Required)

Work Location: On the road","https://www.indeed.com/cmp/Conglomerateit-LLC-8","","","","","","","","",""
"106319540ff5f0de","indeed","https://www.indeed.com/viewjob?jk=106319540ff5f0de","https://rapid-eagle-inc.careerplug.com/j/02f9p7w","GCP Data Engineer","Rapid Eagle Inc","Dallas, TX, US","fulltime","2024-10-04","direct_data","hourly",65.0,75.0,"USD",False,"","","","","","**Benefits:**  

* 401(k)
* Donation matching
* Help or transport service

  

**GCP Data Engineer**  

**Onsite**  

**Dallas TX**  

  

**Skills:-**  

* 8+ Years as a Data Engineer
* Exp with Google Cloud, Big Query
* Apache Hive, Pig etc
* Cloud engineering
* Kubernetes
* Excellent comm skills","https://www.indeed.com/cmp/Rapid-Eagle-Inc","","","","","","","","",""
"a69ad4ba28e295dd","indeed","https://www.indeed.com/viewjob?jk=a69ad4ba28e295dd","https://tnl2.jometer.com/v2/job?jz=581jnf0c28a35989e8493bd616923c75cd87dFAAAKAAAAABQ&utm_source=joveo&publisher=Indeed-organic","Senior Software Engineer Big Data Tooling & API Development","Wells Fargo","Dallas, TX, US","fulltime","2024-10-03","direct_data","yearly",156127.0,197692.0,"USD",False,"","","","","","**About this role:**  

  

Wells Fargo is seeking a Senior Big Data Engineer in the role of a Big Data Tooling & API Development Software Engineer within its Risk Development organization  

  

**Description:**  

  

At Wells Fargo, we are looking for talented people who will put our customers at the center of everything we do. We are seeking candidates who embrace diversity, equity, and inclusion in a workplace where everyone feels valued and inspired.  

  

Help us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.  

  

Technology sets IT strategy; enhances the design, development, and operations of our systems; optimizes the Wells Fargo infrastructure; provides information security; and enables Wells Fargo global customers to have 24 hours a day, 7 days a week banking access through in-branch, online, ATMs, and other channels.  

  

Our mission is to deliver stable, secure, scalable, and innovative services at speeds that delight and satisfy our customers and unleash the skills potential of our employees.  

  

The EFT RISK & INTERNAL AUDIT group provides technology solutions and support for Risk, Audit, Finance, Marketing, Human Resources, Corporate Properties, and Stakeholder Relations business lines. In addition, EFT RISK & INTERNAL AUDIT provides unique technology solutions and innovation for Wells Fargo Technology, Enterprise Shared Services, and Enterprise Data Management. This combined portfolio of applications and tools are continually engineered to meet the challenges of stability, security, scalability, and speed.  

  

Within EFT RISK & INTERNAL AUDIT this group helps all Wells Fargo businesses identify and manage risk. We help our management and Board of Directors identify and monitor risks that may affect multiple lines of business and take appropriate action when business activities exceed the risk tolerance of the company.  

  

The Risk Data management Services group is seeking a Senior Big Data Engineer (Sr. Specialty Software Engineer) to work on building and supporting the Big Data Platform development that build inhouse tools and utilities for low code/ no code frameworks for tenants. The position will offer the opportunity to work on the latest open-stack technologies in Big Data / Java services universe.
  

  

We make extensive use of use Spark, Rest API's, Django to develop and maintain an extensive Framework to enable self-service development.  

  

**Responsibilities include:*** Standing up cutting-edge analytical capabilities, leveraging automation, cognitive and science-based techniques to manage data and models, and drive operational efficiency by offering continuous insights and improvements.
* Help in design and implementation of algorithms and tools for analytics and data scientist teams.
* Use a variety of languages, tools, and frameworks to marry data and systems together.
* Collaborate with modelers, developers, DevOps, and project managers on meeting project goals.
* Strong understanding of Python code CI/CD deployment and test automation suites.
* Drive a culture of automation, test coverage and architect for Micro Services, API, Cloud Native and Headless Architecture - Decoupling the front ends and backends of the technology stack.

**Required Qualifications*** 10+ years of software engineering experience
* 6 + years of Scala or Java experience
* 3+ years of RESTful API design and development experience
* 5+ years of experience with Big Data or Hadoop tools such as Spark, Hive, Kafka, and Map
* 2+ years of experience with building, deploying, and securing cloud platforms
* Solid understanding of distributed computing.
* Strong skills in big data, PySpark, HDFS and distributed computing.
* Experience in creating APIs using Java and Python
* Prior banking domain skills and depth knowledge in risk & finance forecasting domain

**Desired Qualifications*** A Master's degree or higher in computer science or finance
* A professional certification in technology
* Basic knowledge of industry regulations related to building technological solutions
* Knowledge and understanding of DevOps principles
* Should have leadership skills to drive work stream from technical aspects
* Should have command knowledge on story estimations, design reviews, code reviews, quality code delivery
* 5+ year of Database experience
* 2+ years of Kubernetes experience

**Job Expectations*** Ability to travel up to 10% of the time

**Posting End Date:**
  

24 Oct 2024  

**\\*Job posting may come down early due to volume of applicants.**
  

  

**We Value Diversity**  

  

At Wells Fargo, we believe in diversity, equity and inclusion in the workplace; accordingly, we welcome applications for employment from all qualified candidates, regardless of race, color, gender, national origin, religion, age, sexual orientation, gender identity, gender expression, genetic information, individuals with disabilities, pregnancy, marital status, status as a protected veteran or any other status protected by applicable law.  

  

Employees support our focus on building strong customer relationships balanced with a strong risk mitigating and compliance-driven culture which firmly establishes those disciplines as critical to the success of our customers and company. They are accountable for execution of all applicable risk programs (Credit, Market, Financial Crimes, Operational, Regulatory Compliance), which includes effectively following and adhering to applicable Wells Fargo policies and procedures, appropriately fulfilling risk and compliance obligations, timely and effective escalation and remediation of issues, and making sound risk decisions. There is emphasis on proactive monitoring, governance, risk identification and escalation, as well as making sound risk decisions commensurate with the business unit's risk appetite and all risk and compliance program requirements.  

  

Candidates applying to job openings posted in US: All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other legally protected characteristic.  

  

Candidates applying to job openings posted in Canada: Applications for employment are encouraged from all qualified candidates, including women, persons with disabilities, aboriginal peoples and visible minorities. Accommodation for applicants with disabilities is available upon request in connection with the recruitment process.  

  

**Applicants with Disabilities**  

  

To request a medical accommodation during the application or interview process, visit Disability Inclusion at Wells Fargo .  

  

**Drug and Alcohol Policy**  

  

Wells Fargo maintains a drug free workplace. Please see our Drug and Alcohol Policy to learn more.  

  

**Wells Fargo Recruitment and Hiring Requirements:**  

  

a. Third-Party recordings are prohibited unless authorized by Wells Fargo.  

  

b. Wells Fargo requires you to directly represent your own experiences during the recruiting and hiring process.","https://www.indeed.com/cmp/Wells-Fargo","https://www.wellsfargojobs.com/en/well-life/","San Francisco, CA","10,000+","more than $10B (USD)","At Wells Fargo, we provide opportunities that go beyond just your career. Whatever living a well life looks like to you, you'll find it here. Learn more at wellsfargojobs.com/well-life. ","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/2ced2b321a964f69975fedbffe05c4bb","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/d9382fa80fb2a458bedd3afaab6d916c","Charlie Scharf, CEO and President","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/37bca88e561f55969a6a51885eca1f9a"
"aa2958bfcafefe6a","indeed","https://www.indeed.com/viewjob?jk=aa2958bfcafefe6a","https://nationstar.wd5.myworkdayjobs.com/en-US/MrCooper/job/Lake-Vista-4---Lewisville-TX/XMLNAME-2025-Spring-Intern-Program---Data-Engineer-Intern--Onsite--DFW-_022972","2025 Spring Intern Program – Data Engineer Intern (Onsite- DFW)","Mr. Cooper","Lewisville, TX, US","fulltime","2024-10-03","direct_data","yearly",44237.0,56014.0,"USD",False,"","","Banks And Financial Services","","","At Mr. Cooper Group, You Make the Dream Possible.
Our purpose is simple: Keeping the dream of homeownership alive. As a Mr. Cooper Group team member, you play a big role in making that dream possible. Around here, we know our roles and work together, volunteer to make a difference, and challenge the status quo when needed. Everything we do is in the care and service of our teammates and our customers.
Join us and make the dream of home ownership possible!
Mr. Cooper's spring internship program offers college students the chance to discover what it's like to work at a leading financial services organization. Our interns deliver innovative solutions to real business challenges and build enduring relationships with their manager and an assigned mentor. While gaining insight into the industry, interns are immediately part of Mr. Cooper's collaborative culture. Spend your spring at Mr. Cooper and gain a career where you can make a difference! Our spring internship program begins in January 2025 and ends in April 2025.
The Data Engineer Interns will have access to a wide range of projects and opportunities to apply their skills in real-world scenarios. They will gain hands-on experience and enhance their knowledge in their field of interest. Interns will work alongside a team of experienced professionals who are passionate about mentorship.
Roles and Responsibilities
Assist in extracting data from various sources, including databases, APIs, logs, GCP services, and Kafka streams
Be apart of building, maintaining, and optimizing data pipelines, ensuring data quality and data reliability.
 Performing ETL tasks, data cleansing and data management
Stay updated on the latest data engineering tools, technologies, and best practices, especially those related to GCP, Snowflake, Databricks, and Kafka.
Basic Qualifications
Expertise in programming languages such as Python, Java, Scala, or SQL.
Be enrolled full-time and pursuing an undergraduate or graduate degree in Computer Science from an accredited college/university or have graduated within one year of start (June 2025)
Proficiency in working with databases (SQL and NoSQL) and ETL (Extract, Transform, Load)
Familiarity with cloud platforms like Google Cloud Platform (GCP) and the ability to understand and use cloud-based data storage, processing, and analysis services
Demonstrable experience with GCP or similar cloud platforms can be a significant qualification
Candidates must have authorization to work permanently in the US without the need for sponsorship (Currently, our organization is unable to support candidates that are on OPT, CPT or candidates that will need sponsorship, now or in the future)
Local to DFW and able to commute to our Lewisville office.
Mr. Cooper Group is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, or status as a protected veteran. EOE/M/F/D/V
Job Requisition ID:
022972
Job Category:
Administrative Services
Primary Location City:
Lewisville
Primary Location Region:
Texas
Primary Location Postal Code:
75067
Primary Location Country:
United States of America
Additional Posting Location(s):","https://www.indeed.com/cmp/Mr.-Cooper","https://www.mrcooper.com","8950 Cypress Waters Boulevard
Dallas, TX 75019","5,001 to 10,000","$1B to $5B (USD)","We want to show the world that transparency, candor and collaboration aren’t just good values. They’re good business.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/4d56dab8aa8f1418414c6d2140ee21e3","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/12f8bba3211ec522b5fd821955f490be","Jay Bray","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/080ffe7ff6c4a336c4be107a34af11c8"
"90810dd704fc7a20","indeed","https://www.indeed.com/viewjob?jk=90810dd704fc7a20","https://searchjobs.libertymutualgroup.com/careers/job/618500693428?microsite=libertymutual.com&domain=libertymutual.com","Senior Data Engineer","Liberty Mutual Insurance","Plano, TX, US","fulltime","2024-10-02","direct_data","yearly",103400.0,188800.0,"USD",False,"","","","","","**Pay Philosophy**
The typical starting salary range for this role is determined by a number of factors including skills, experience, education, certifications and location. The full salary range for this role reflects the competitive labor market value for all employees in these positions across the national market and provides an opportunity to progress as employees grow and develop within the role. Some roles at Liberty Mutual have a corresponding compensation plan which may include commission and/or bonus earnings at rates that vary based on multiple factors set forth in the compensation plan for the role.

 **Description**  



We deliver our customers peace of mind every day by helping them protect what they value most. Our passion for placing the customer at the center of everything we do is driving a transformational shift at Liberty Mutual. Operating as a tech startup within a Fortune 100 company, we are leading a digital disruption that will redefine how people experience insurance.

 ***This role has a hybrid work schedule (2 days per week in the office) and we will only consider candidates based in Portsmouth, NH, Boston, MA, Plano, TX and Indianapolis, IN.***

 **Job introduction:**

  

The US Retail Markets (USRM) **Data and Analytics Engineering** team is actively searching for a highly productive **Senior Data Engineer** for a distributed, dynamic agile team to serve as a technical expert designing, developing, analyzing & testing innovative data warehouse reporting solutions. This candidate will join an energetic and engaged Business Data Solutions Engineering team focused on delivering exceptional value to our PL Products business partners. You will work collaboratively in an agile squad to design and build data pipelines & workflows, ingest, curate & provision data workflows in a Cloud-based environment as well as own responsibility of thorough end-to-end testing.

  

This is a fast-paced environment providing rapid delivery for our business partners. You will be working in a highly collaborative environment that values speed and quality, with a strong desire to drive change and foster a positive work environment. You will have the opportunity to help lead this change with us as we grow this culture, mindset and capability.

 **We encourage you to apply if this interests you:**

* Work as ONE team committed to excellence.
* Model and promote a Data First attitude.
* Help advance Data Engineering operations into the future.
* Work with a modern data tech stack.

**About the job:**

* Work in a dynamic and exciting agile environment with Scrum Masters, Product Owners, and team members to develop creative data-driven solutions with our ETL pipeline that meet business and technical initiatives.
* Analyze, develop and execute data integration solutions, to manage the information lifecycle needs of an organization.
* Actively participates in and often leads peer development and code reviews within each Agile sprint, with focus on test driven development and Continuous Integration and Continuous Development (CICD).
* Designs and builds data provisioning workflows/pipelines, physical data schemas, extracts, data transformations, and data integrations and/or designs using ETL and API microservices.
* Builds data architecture and data applications (marts/warehouses) that enable reporting, analytics, data science, and data management and improve accessibility, efficiency, governance, processing, and quality of data.
* Improve speed to market by focusing on current data needs as well as building out the long-term strategic data solutions using AWS, Snowflake, SQL, Data Vault methodology, as well as other modern data technologies.
* Design and develop programs and tools to support ingestion, curation and provisioning of complex enterprise data to achieve analytics, reporting, and data science.
* Demonstrate open minded and collaborative approach to creating innovative technical solutions.
* Continuously learn to maintain strong knowledge of technology enablers.
* Mentor new and junior developers.
* Provide successful deployment and provisioning of data solutions to production or other required environments.
* Analyze complex technical problems and is expected to recommend process improvements that address complex technology gaps within a single business process and improve data reliability, quality, and efficiency.

**Qualifications*** Bachelor or Master`s degree in technical or business discipline or equivalent experience, technical degree preferred. Generally 5+ years of Data Engineering experience.
* Experience developing back end, data warehouse technology solutions.
* Knowledge of a variety of data platforms including Snowflake, Teradata, SQL, DB2 (Cloud based DB a plus).
* Experience with AWS (such as S3, Snowflake, Athena), Unix, Informatica (IDMC) and strong SQL skillset.
* Extensive knowledge of IT concepts, strategies, methodologies.
* Experience working with agile methodologies (Scrum, Kanban, XP) and cross-functional teams (Product Owners, Scrum Masters, Developers, Test Engineers).
* Well versed in diverse technologies and new technical architecture principles and concepts.
* Demonstrates leadership and active pursuit of optimizing CI/CD process and tools, testing frameworks and practices.
* Must be proactive, demonstrate initiative, and be a logical thinker.
* Must be team oriented with strong collaboration, prioritization, and adaptability skills required.
* Strong negotiation, facilitation and consensus building skills.
* Strong oral and written communication skills; presentation skills; Extensive knowledge of the following: IT concepts, strategies, methodologies.
* Extensive consultative skills, including the ability to understand and apply customer requirements, including drawing out unforeseen implications and making recommendations for design, the ability to define design reasoning, understanding potential impacts of design requirements
* Extensive understanding of backlog tracking, burndown metrics, and incremental delivery
* Strong collaboration, prioritization, and adaptability skills required.

 **Additional Qualifications:**

* Java, Ruby, NoSQL, Python development experience.
* Understanding of Cloud / Hybrid data architecture concepts.
* Understanding of insurance industry and products.
* Excited by trying new technology and learning new tools.

**About Us**
\\*\\*This position may have in-office requirements depending on candidate location.\\*\\*  

  

At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That's why we provide an environment focused on openness, inclusion, trust and respect. Here, you'll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession.  

  

Liberty Mutual has proudly been recognized as a ""Great Place to Work"" by Great Place to Work® US for the past several years. We were also selected as one of the ""100 Best Places to Work in IT"" on IDG's Insider Pro and Computerworld's 2020 list. For many years running, we have been named by Forbes as one of America's Best Employers for Women and one of America's Best Employers for New Graduates as well as one of America's Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusion  

  

We value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits  

  

Liberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran's status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.  

  

**Fair Chance Notices**

* California
* San Francisco
* Los Angeles
* Philadelphia","https://www.indeed.com/cmp/Liberty-Mutual-Insurance","http://www.libertymutualgroup.com","Boston, MA","10,000+","more than $10B (USD)","Liberty Mutual Insurance is a diversified global insurer with over 50,000 employees located in more than 900 offices throughout the world.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/bf1eb916777af10bec37abe480366b5c","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/5037aab342ca36a4903ca2eb66a448b3","Tim Sweeney","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/cac32de8c853f4f5dba4ec82f9eda463"
"0dd4bc1654ad0c12","indeed","https://www.indeed.com/viewjob?jk=0dd4bc1654ad0c12","https://www.fidelitytalentsource.com/job-details/21130255/data-engineer-1/","Data Engineer 1","Fidelity TalentSource","Westlake, TX, US","temporary","2024-10-02","direct_data","yearly",80034.0,101342.0,"USD",False,"","","","","accommodations@fmr.com","**Data Engineer 1**
Fidelity TalentSource is your destination for discovering your next temporary role at Fidelity Investments. We are currently sourcing for a Data Engineer to work in Westlake TX.


**The Role**  

Fidelity’s Financial Intelligence Unit is looking for a data technologist to join our technology enablement team. This team deploys advanced analytics to detect and combat cyber risks for financial products and services. Builds and develops databases, using DB2, PostgreSQL, Snowflake, NoSQL, and ETL processes. Designs solutions with databases and data modeling. Ensures data access and processes flows in a heterogeneous environment. Writes database stored procedures, functions, automation routines, and loaders. Performs SQL tuning and optimization. Designs and implements database technologies for fraud detection and prevention engine.  

**Required Technical Skills**


* Bachelor’s or master’s degree in Data Analytics.
* 0-2 years of experience working in a financial services company analyzing large data sets.
* Ensures alignment with enterprise data architecture strategies.
* Improves data availability via APIs and shared services and recommends optimization solutions using cloud technologies for data processing, storage, and advanced analytics.
* Performs SQL tuning and data integration activities.
* Provides technical guidance for cyber security on database technologies.
* Performs risk assessments and execute tests of data processing system to ensure functioning of data processing activities and security measures.
* Performs independent and complex technical and functional analysis for multiple projects supporting several divisional initiatives.
* Building technical infrastructure required for efficient Extraction, Transformation, and Loading (ETL) of data from a wide variety of data sources by leveraging, object-oriented/object function scripting languages such as Python.
* Expertise with relational databases, Splunk, Snowflake, YugabyteDB, Aerospike, S3 and similar data management platforms.
* Experience working with and handling large data sets in DB2 with SQL; writing sophisticated stored procedures to process data.
* Object oriented Python programming and solid experience with machine learning libraries – Pandas, NumPy, Scikit-learn, TensorFlow, etc.
* Data parsing/analytics experience in large data sets using Python, scripting, and other similar technologies, integrating with and consuming APIs.
* Familiarity with quantitative techniques and methods, statistics, econometrics – including probability, linear regression, time series data analysis and optimizations.
* Knowledge of hybrid on-prem and cloud data architectures and services, especially data streaming, storage and processing functionality
* Awareness of event-based systems, functional programming, emerging technologies and messaging frameworks such as Kafka.
* Experience in Agile methodologies (Kanban and SCRUM) is a plus.

**The Value You Deliver**


* Strong analytical skills and ability to take on issues and work through ambiguous situations by making timely decisions based on facts, knowledge, experience and judgment.
* Good interpersonal and client-handling skills with the ability to handle expectations and explain technical detail. Consistent track record to multitask, prioritizes tasks, and quickly adjusts in a constantly evolving environment.
* Collaborate with business and technology groups and should be able to present formal and informal presentations in various settings: one-on-one, small, and large groups, with peers, and senior management.
* Ability to navigate organizationally to accomplish tasks and work on multiple efforts simultaneously and ability to work with multi-functional teams located across geographies.
* Excellent conflict management and negotiation skills; eager to learn and continuously develop personal and technical capabilities.
* High level of dedication, initiative, vision, passion and professional approach to time, costs, and deadlines.
* Ability to handle production issues with accuracy and attention to detail; a methodical, investigative, and inquisitive mind; together with creative abilities.
* Design robust batch and streaming programs and adhering to standards and best-practices for these databases.
* Enjoy analyzing data, identifying gaps, issues, patterns, and trends and can analyze application dependencies and conduct impact assessment of changes.

**The Team**  

Financial Intelligence Unit deploys advanced analytics to detect and combat cybercrime for Fidelity’s enterprise-wide financial products and services. The team works closely with Cyber Fraud Investigators and technology groups including enterprise cyber security and customer protection teams to assemble and analyze fraud and risk signals in near real time manner, with a goal to prevent or reduce monetary losses for our clients and protect Fidelity reputation.  

**Company Overview**  

At Fidelity, we are passionate about making our financial expertise broadly accessible and effective in helping people live the lives they want! We are a privately held company that places a high degree of value in creating and nurturing a work environment that attracts the best talent and reflects our commitment to our associates. We are proud of our diverse and inclusive workplace where we respect and value our associates for their unique perspectives and experiences. For information about working at Fidelity, visit FidelityCareers.com. Fidelity Investments is an equal opportunity employer.  

Fidelity will reasonably accommodate applicants with disabilities who need adjustments to complete the application or interview process. Please email us at accommodations@fmr.com or call 800-835-5099, prompt 2, option 2 if you would like to request an accommodation.


**Company Overview**


Fidelity TalentSource is the in-house temporary staffing provider for Fidelity Investments, one of the largest and most diversified global financial services firms in the industry. We welcome individuals from all backgrounds, including technology and customer service, to fill assignments across Fidelity’s U.S.-based regional and investor center locations. If you would like to experience Fidelity’s supportive and collaborative culture while expanding your skill set and developing your professional network, consider a role with Fidelity TalentSource. Apply today at FTSJobs.com.


*We believe that the most effective way to attract, develop and retain a diverse workforce is to build an enduring culture of inclusion and belonging.*  

*Fidelity TalentSource will reasonably accommodate applicants with disabilities who need adjustments to participate in the application or interview process. To initiate a request for an accommodation, please contact our HR team at* *HR@ ftsjobs.com**.*


**Information about Fidelity investments**


At Fidelity Investments, our customers are at the heart of everything we do. As a privately held company with a rich 75-year history, our mission has remained the same since our founding: *to strengthen the financial well-being of our clients*. We help people invest and plan for their future. We assist companies and non-profit organizations in delivering benefits to their employees. And we provide institutions and independent advisors with investment and technology solutions to help invest their own clients’ money. For information about working at Fidelity, visit FidelityCareers.com.


Fidelity TalentSource’s working model blends the best of working offsite with maximizing time together in person to meet associate and business needs. Currently, most hybrid roles require associates to work onsite all business days of one assigned week per four-week period (beginning in September 2024, the requirement will be two full assigned weeks).


Fidelity Investments and Fidelity TalentSource are equal opportunity employers.","https://www.indeed.com/cmp/Fidelity-Talentsource","http://www.fidelitytalentsource.com","Boston, MA","51 to 200","Decline to state","Expand your skillset and discover what it is like to work at Fidelity Investments through a temporary assignment with Fidelity TalentSource, the company's in-house contingent staffing provider.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/4630577b0160aeea641e462095dbed8d","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/96e3ba4c160a2288c6940c3b1530be11","Abby Johnson","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/8054b9bd1f79df28a9e645765e6fd7d8"
"2c77b58423e43a73","indeed","https://www.indeed.com/viewjob?jk=2c77b58423e43a73","https://alcority.wd1.myworkdayjobs.com/en-US/Alcority/job/Dallas-TX/Lead-Data-Engineer_R11306","Lead Data Engineer","Alcority","Dallas, TX, US","fulltime","2024-10-02","direct_data","yearly",132044.0,167197.0,"USD",False,"","","","","","The Lead Data Engineer is the senior software engineer in the Business Intelligence and Data Warehousing team. This role develops data ingestion to enable high-value business intelligence products. This is a senior individual contributor role with a focus on hands on development, collaborative problem solving, and mentorship of junior engineers. Successful candidates will directly influence solution designs to create a robust data platform to deliver a wide range of products. This role requires 12+ years of engineering experience including work on Azure Data Factory and Informatica Power Center / IICS.
Responsibilities:* Experience in designing and delivering solutions using MS Azure Data Factory, Azure Synapse Analytics, MS Fabric, AWS, or similar tools
* Ability to automate tasks and deploy production standard code with unit testing, continuous integration, and versioning
* Experience with advanced data integration techniques including ETL/ELT pipelines and data transformation
* Familiarity with cloud security best practices, including Azure Active Directory, encryption, and data privacy compliance
* Working in an Agile framework
* Liaising with Business Analysts on the technical solutions
* Assisting with Production Support activities


Required skills:* Strong recent experience working as Azure Data Engineer, with prior experience in AWS or any other cloud technology
* Strong experience in Cloud Application Integration and Cloud Data Integration
* Strong experience in DevOps platforms such as GitHub with hands-on experience in branching, merge strategy, rebasing and reviewing history
* Experience in developing application integration using SOAP/REST APIs and big data technologies such as Apache Spark
* Good knowledge of Rest V2, Swagger file generation and Python scripting
* Some experience in Kubernetes/Docker
* The current role is expected to be Azure heavy, but in future we expect to operate in hybrid environments
* Ability to work independently with minimum supervision to meet deadlines

  

Preferred skills:* Informatica IICS Or Power Center experience
* Working knowledge of SQL
* Snowflake experience

*It is impossible to list every requirement for, or responsibility of, any position. Similarly, we cannot identify all the skills a position may require since job responsibilities and the Company’s needs may change over time. Therefore, the above job description is not comprehensive or exhaustive.* *The Company reserves the right to adjust, add to or eliminate any aspect of the above description. The Company also retains the right to require all employees to undertake additional or different job responsibilities when necessary to meet business needs.*
Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future.
Benefits & Perks:* Time Off: 25 days of PTO for full-time employees and 12 company holidays.
* Company Paid Benefits: Life insurance, Short-term disability, Long-term disability, Paid parental leave, Employee Assistance Program, and medical insurance in our high deductible health plan.
* Optional Employee Paid Benefits: Medical insurance in our EPO plan, Dental benefits, and Vision benefits. We also offer Health Savings Accounts, Flexible Spending Accounts, Supplemental Life insurance, and more.
* 401(k): Eligible after 60 days. Discretionary company match of 50% up to the first 6% of contributions.

  

EQUAL OPPORTUNITY EMPLOYER
ALCORITY IS AN EQUAL EMPLOYMENT OPPORTUNITY EMPLOYER. THE COMPANY'S POLICY IS NOT TO DISCRIMINATE AGAINST ANY APPLICANT OR EMPLOYEE BASED ON RACE, COLOR, RELIGION, NATIONAL ORIGIN, GENDER, AGE, SEXUAL ORIENTATION, GENDER IDENTITY OR EXPRESSION, MARITAL STATUS, MENTAL OR PHYSICAL DISABILITY, AND GENETIC INFORMATION, OR ANY OTHER BASIS PROTECTED BY APPLICABLE LAW. THE FIRM ALSO PROHIBITS HARASSMENT OF APPLICANTS OR EMPLOYEES BASED ON ANY OF THESE PROTECTED CATEGORIES.","https://www.indeed.com/cmp/Alcority","","","","","","","","",""
"ee61e4a2cdd61204","indeed","https://www.indeed.com/viewjob?jk=ee61e4a2cdd61204","https://iquasar-llc.careerplug.com/j/02f7nqo","Senior Data Engineer","iQuasar LLC","Dallas, TX, US","fulltime","2024-10-02","","hourly","","","USD",True,"","","","","sal.farooqui@iquasar.com, sal.farooqui@iquasar.com","**Benefits:**  

* 401(k)
* 401(k) matching
* Health insurance
* Paid time off
* Competitive salary
* Dental insurance
* Vision insurance

  

**Devout Inc.** is seeking to fill the position of **Senior Data Engineer**. We strive to provide the next generation of cutting-edge technologies. Our growth means exciting career opportunities for talented professionals in engineering, software development, and other key areas. We offer competitive compensation and benefits including Health, Vision, and Dental Insurance, a matching 401k plan, and other benefits given below, excellent training, and a vibrant working environment. Our employees are exceptional, giving us a competitive advantage by innovating solutions with a strong sense of mission and integrity.  

  

One of our clients needs a **Senior Data Engineer for** a contract position.  

  

* **Position:** Senior Data Engineer
* **Location:** Woonsocket, RI or Dallas, TX
* **Position Type:** Contract
* **Salary:** $40/hour
* **Clearance:** N/A
* **Travel:** Remote

  

**Responsibilities:**  

* Design, build, and optimize scalable data pipelines in Python and SQL.
* Work with Snowflake or GCP to manage and analyze large datasets.
* Collaborate with data analysts, data scientists, and other stakeholders to understand business requirements and provide technical solutions.
* Implement best practices for data management, performance, and security in a cloud-based environment.
* Troubleshoot and resolve complex data issues to ensure high-quality data delivery

**Required Skills:**  

* 6+ years of experience in data engineering.
* Proficiency in Python and SQL.
* Hands-on experience with Snowflake or GCP.
* Strong knowledge of data architecture and cloud infrastructure.
* Excellent communication and teamwork skills

If you are interested in this position, please send me a copy of your latest resume at sal.farooqui@iquasar.com with the information requested below: Also, please let me know what time/number is best to call to discuss this great opportunity. In case you are not interested in this position, or this is not a right fit for you, please feel free to share this opportunity with your friends/networks or anyone you know who may be interested in this position. Thank you!  

  

* Availability to start a new job.
* Best Rates
* Contact #


  

Please don’t hesitate to contact me with any questions (s) you may have. All employment is decided based on qualifications, merit, and business needs.  

  

Regards,  

Sal Farooqui | Recruiter  

sal.farooqui@iquasar.com  

  

  

**Devout Inc.** is proud to be an Equal Employment Opportunity Employer. We do not discriminate based on race, religion, color, national origin, political affiliation, sex, sexual orientation, gender identity, age, marital/parental /veteran status, disability, genetic information, membership in an employee organization, retaliation, military service, other non-merit factors, or any other applicable characteristics protected by law.","https://www.indeed.com/cmp/Iquasar-LLC","https://www.iquasar.com","Sterling","11 to 50","$1M to $5M (USD)","","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/ed6a19828cfcfbbde865c5d5348285b4","","",""
"59c89c7279ffaec6","indeed","https://www.indeed.com/viewjob?jk=59c89c7279ffaec6","https://usource.ripplehire.com/candidate/?token=xHQWoFn4C242POo7xMpH&source=CAREERSITE#detail/job/25962","Data Engineer","UST","Grand Prairie, TX, US","fulltime","2024-10-02","direct_data","yearly",82000.0,125000.0,"USD",True,"","","","","","1 Opening
Grand Prairie  


### **Role description**


**Data Engineer**


**Lead I - Software Engineering**

  


**Who We Are:**



Born digital, UST transforms lives through the power of technology. We walk alongside our clients and partners, embedding innovation and agility into everything they do. We help them create transformative experiences and human-centered solutions for a better world.



UST is a mission-driven group of 29,000+ practical problem solvers and creative thinkers in more than 30 countries. Our entrepreneurial teams are empowered to innovate, act nimbly, and create a lasting and sustainable impact for our clients, their customers, and the communities in which we live.



With us, you’ll create a boundless impact that transforms your career—and the lives of people across the world.



Visit us at UST.com.

  


**You Are:**



The Data Engineer will be instrumental in building and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for cross-functional teams. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing data systems and building them from the ground up. The Data Engineer will support our software developers, database architects, data analysts, and data scientists on data initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects.

  


**The opportunity:**


* Data Pipeline Architecture: Design and implement scalable and reliable data pipelines within AWS cloud environments, leveraging technologies such as Snowflake, SQL Server, Oracle, Python, Apache Airflow, SSIS, DataStage or Informatica.


* Database Management: Administer, maintain, and optimize SQL Server or Oracle databases to ensure high performance, availability, and security.


* ETL Development: Develop and maintain ELT/ETL processes using latest data pipeline technologies PySpark, Kafka, Python and knowledge on using legacy ETL - SSIS, DataStage or Informatica to extract data from various sources, transform it according to business rules, and load it into data warehouses or data lakes.


* Cloud Services Management: Leverage AWS services (e.g., Amazon S3, RDS, Redshift, Lambda, Glue), GCP to build and maintain a highly efficient data infrastructure.


* Performance Tuning: Monitor, identify, and rectify database performance issues. Optimize data processing and ELT/ETL jobs for maximum efficiency.


* Data Security and Compliance: Implement and maintain data security measures, ensuring compliance with data protection regulations and best practices in the cloud.


* Collaboration: Work with team members across departments to identify and implement data improvements, integrations, and new technologies to enhance the business’s data ecosystem.

  



This position description identifies the responsibilities and tasks typically associated with the performance of the position. Other relevant essential functions may be required.

  


**What you** **need:**


* Bachelor’s degree in computer science, Engineering, Information Technology, or a related field.


* 5+ years of experience in Data Engineering.


* Strong experience with AWS, Azure cloud services related to Data Engineering, Data Storage, Processing, and Analytics.


* Proficient in managing and optimizing Snowflake, SQL Server, Oracle databases.


* Extensive experience with ETL tools, specifically Airflow, PySpark, Kafka, Python, SSIS, DataStage or Informatica.


* Solid understanding of SQL, Python, and other programming languages.


* Knowledge of data modeling, data governance, data security practices, and compliance frameworks.


* Excellent problem-solving skills and the ability to work and collaborative with teams in a dynamic and challenging environment.


* Healthcare experience is preferred.


* Working Conditions:


* The role may require on-call duties for critical system support.


* Flexibility to work across different time zones when collaborating with global teams

  



Compensation can differ depending on factors including but not limited to the specific office location, role, skill set, education, and level of experience. UST provides a reasonable range of compensation for roles that may be hired in various U.S. markets as set forth below.


**Role Location:**Remote


**Compensation Range:** $82,000-$125,000

  


**Benefits**



Full-time, regular employees accrue a minimum of 10 days of paid vacation per year, receive 6 days of paid sick leave each year (pro-rated for new hires throughout the year), 10 paid holidays, and are eligible for paid bereavement leave and jury duty. They are eligible to participate in the Company’s 401(k) Retirement Plan with employer matching. They and their dependents residing in the US are eligible for medical, dental, and vision insurance, as well as the following Company-paid Employee Only benefits: basic life insurance, accidental death and disability insurance, and short- and long-term disability benefits. Regular employees may purchase additional voluntary short-term disability benefits, and participate in a Health Savings Account (HSA) as well as a Flexible Spending Account (FSA) for healthcare, dependent child care, and/or commuting expenses as allowable under IRS guidelines. Benefits offerings vary in Puerto Rico.



Part-time employees receive 6 days of paid sick leave each year (pro-rated for new hires throughout the year) and are eligible to participate in the Company’s 401(k) Retirement Plan with employer matching.



Full-time temporary employees receive 6 days of paid sick leave each year (pro-rated for new hires throughout the year) and are eligible to participate in the Company’s 401(k) program with employer matching. They and their dependents residing in the US are eligible for medical, dental, and vision insurance.



Part-time temporary employees receive 6 days of paid sick leave each year (pro-rated for new hires throughout the year).



All US employees who work in a state or locality with more generous paid sick leave benefits than specified here will receive the benefit of those sick leave laws.

  


**What we believe:**



We proudly embrace the values that have shaped UST since day one. We build our culture of Humility, Humanity, and Integrity. These values inspire us to nurture a people-first, human centric culture that fosters diversity, prioritizes sustainable solutions, and keeps our people and clients at the forefront of all decisions.

  


**Humility:**



We will listen, learn, be empathetic and help selflessly in our interactions with everyone.


**Humanity:**



Through business, we will better the lives of those less fortunate than ourselves.


**Integrity:**



We honor our commitments and act with responsibility in all our relationships.

  


**Equal Employment Opportunity Statement**  

UST is an Equal Opportunity Employer.  



All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other applicable characteristics protected by law. We will consider qualified applicants with arrest or conviction records in accordance with state and local laws and “fair chance” ordinances.



UST reserves the right to periodically redefine your roles and responsibilities based on the requirements of the organization and/or your performance.  



#UST

#CB

#LI-SJ1

#LI-Remote
### **Skills**


Aws,Azure Cloud,Etl Tools


### **Benefits**


### **Compensation range: $ 82,000.00 to 125,000.00 per year**


  
### **About UST**


UST is a global digital transformation solutions provider. For more than 20 years, UST has worked side by side with the world’s best companies to make a real impact through transformation. Powered by technology, inspired by people and led by purpose, UST partners with their clients from design to operation. With deep domain expertise and a future-proof philosophy, UST embeds innovation and agility into their clients’ organizations. With over 30,000 employees in 30 countries, UST builds for boundless impact—touching billions of lives in the process.","https://www.indeed.com/cmp/Ust-2","https://www.ust.com/","Aliso Viejo, CA","10,000+","Decline to state","UST is a global digital transformations solutions provider.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/07ea3746bef405d42fc8185242f1222b","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/cf90c56bbfeccf3ba0e9613e084da868","Krishna Sudheendra","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/932980a52f934677c71ff6d2ff94d138"
"1a82e853fe077af3","indeed","https://www.indeed.com/viewjob?jk=1a82e853fe077af3","https://teachingstrategies.applicantpool.com/jobs/1147337-9373.html","Staff Data Engineer (Remote)","Teaching Strategies, LLC","Denton, TX, US","fulltime","2024-10-01","direct_data","yearly",101811.0,128916.0,"USD",True,"","","","","","**Be a Part of our Team!**


Join a working family that is dedicated to the mission of the work we do!


Teaching Strategies is an innovative edtech organization focused on connecting teachers, children, and families. As front runners in the early childhood education market, we build dynamic, top-quality digital products that integrate all of the essential elements of a high-quality solution: curriculum, assessment, professional development, and family engagement. We are building a team of results-oriented individuals who will thrive in a collaborative, work-hard/play-hard culture. We pride ourselves on the impact we have on the early childhood field through supporting teachers who are doing the most important work there is, teaching children to become creative, confident thinkers.

**Position Overview**


Data is our key to success, and a data platform is a necessary component. As we take steps to modernize our customer facing reports and advance our data strategy, we are looking for a Staff Data Engineer to build and advance our data platform vision. In this role, you will be able to show your passion for data, demonstrate your exceptional problem-solving skills as you articulate intricate technical details with clarity. You will be a major contributor in defining and building out our data platform as you develop, optimize and maintain our data pipelines. You will be instrumental in maintaining a healthy data ecosystem ensuring the availability, accuracy and consistency of our data. You will work in close partnership with the VP of Data and AI/ML, the Senior Manager of Data, and your data engineering and analytics colleagues to achieve a strong foundations data platform upon which our internal and external customers will benefit. Come join our team!


**Specific Roles & Responsibilities:**

* Partake in proofs of concept for tools and data platforms to inform the data platform design
* Design, construct, install, and maintain large-scale systems and other infrastructure
* Set up high volume, scalable data pipelines to process structured and unstructured data
* Enhance data quality through testing, tooling, and continuously evaluating performance
* Work on expanding and optimizing our data and data pipeline architecture
* Improve data reliability, efficiency, and quality of our data
* Conduct data analysis and troubleshoot data-related issues in real-time
* Keep current with state-of-the-art data processing technologies and practices
* Document intricate procedures, architectures, and design strategies

**Qualifications:**

* Strong collaborator and self-starter with outstanding verbal and written communication abilities
* Experience in building and optimizing 'big data' pipelines and architectures
* Proficiency in SQL, Python, and other data processing languages
* Expertise with Spark, EMR and other big data tools like Hadoop, Delta Tables, Kafka, etc.
* Solid grasp on data modeling, data warehousing, and ETL techniques
* Experience in relational databases
* Knowledge of best practices for integration patterns and maintenance of the data platform
* Experience standing up and utilizing Snowflake is preferred
* A bachelor's degree in computer science, engineering, or a related field; master's degree preferred
* High attention to detail and proven problem-solving prowess

**Why Teaching Strategies**


At Teaching Strategies, our solutions and services are only as strong as the teams that create them. By bringing passion, dedication, and creativity to your job every day, there's no telling what you can do and where you can go! We provide a competitive compensation and benefits package, flexible work schedules, opportunities to engage with co-workers, access to career advancement and professional development opportunities, and the chance to make a difference in the communities we serve.


Let's open the door to your career at Teaching Strategies!

**Some additional benefits & perks while working with Teaching Strategies**


Teaching Strategies offers our employees a robust suite of benefits and other perks which include:

* Competitive compensation package
* Employee Equity Appreciation Program
* Health and wellness insurance benefits
* 401k with employer match
* Flexible work environment
* Unlimited paid time off (which includes paid holidays and Winter Break)
* Paid parental leave
* Tuition assistance, professional development, and opportunities for career growth
* Best in class technology equipment for every employee
* Penthouse suite in downtown DC seconds away from Washington Nationals Stadium and Audi Field

**Teaching Strategies, LLC is committed to creating a diverse workplace and is proud to be an equal opportunity employer of Minorities, all Genders, Protected Veterans, and Individuals with Disabilities.**


Equal Employment Opportunity (EEO)


Family and Medical Leave Act (FMLA)


Employee Polygraph Protection Act (EPPA)","https://www.indeed.com/cmp/Teaching-Strategies,-LLC","","","","","","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/43e3167b3473789a92dab9e2c8382d36","","",""
"5256b7fabe07b768","indeed","https://www.indeed.com/viewjob?jk=5256b7fabe07b768","https://rr.jobsyn.org/5D8C38D3572C44BCAEB8E2E7130FFA211554","Jr Client Data Engineer","Mosaic North America","Dallas, TX, US","fulltime","2024-10-01","direct_data","yearly",61500.0,76900.0,"USD",False,"","","","","","**DESCRIPTION**


**Jr Client Data Engineer**


The Jr Client Data Engineer position will assist in developing and managing the ingestion, storage, modeling, and consumption of data for Mosaic and our clients. This role involves transforming raw data into usable formats, ensuring efficient data storage and processing, and supporting the back end of our data environment. The Jr Client Data Engineer will work closely with senior engineers and other teams to create and monitor data solutions, resolve incidents, optimize workloads, and explore emerging technologies.


**RESPONSIBILITIES**


* Work with the broader team and Client Service to understand and implement solutions based on high level designs and requirements.
* Help create datasets for analytics by designing logical data models and turning them into physical data structures.
* Support the integration of data from disparate sources and systems, including databases, APIs, files, and streaming platforms.
* Assist in ensuring analytics-ready data is of sufficient quality to make critical operational, tactical, and business decisions.
* Participate in the software development lifecycle, including requirements gathering, design, development, testing, deployment, and maintenance of data solutions.
* Develop resources which aid data platform users such as data catalogues, lineage documentation, and user guides.
* Support the development and maintenance of infrastructure on Google Cloud Platform and/or Azure.
* Develop understanding of all areas of Mosaic business to find new opportunities for optimization.
* Stay current with technology trends to continually develop ingestion, ETL/ELT, and general data/software skills, and evangelize within the team.
* Ensure data security and compliance with company policies.

**QUALIFICATIONS**


**Minimum Qualifications** :


* A bachelor’s degree in computer science, Engineering, Information Technology, or equivalent.
* Proficiency in SQL and familiarity with programming languages such as Python.
* Experience with software version control with Git and Git management platforms such as GitHub or GitLab.
* Basic understanding of Cloud Computing platforms such as GCP/AWS/Azure and their services.
* Understanding of data warehousing and data modeling concepts.
* Familiarity with data orchestration and workflow management tools such as Airflow.
* Ability to handle data processing tasks and the support the development of scalable data applications.

**Preferred Qualifications** :


* Excellent communication skills, with the ability to interact comfortably with peers and leadership both internally and externally.
* Hands-on experience with data manipulation libraries and frameworks like Polars, Pandas, Spark, or similar tool.
* Familiarity with data warehousing concepts and technologies, such as Google BigQuery, Amazon Redshift, or Snowflake, and basic experience in writing and optimizing SQL queries for these platforms.
* Knowledge of ETL/ELT processes and tools, with basic understanding of how to build and manage data pipelines.
* Exposure to containerized tools like Docker or Kubernetes in a plus.
* Basic knowledge or experience with Infrastructure as Code (IaC) tools like Terraform or Pulumi.
* Some experience with data visualization tools such as Tableau, Power BI or Looker.
* Proven ability to manage and complete projects within deadlines, even in an ambiguous or rapidly changing environment.

**ABOUT US**


Acosta and Mosaic are the sales and marketing powerhouses behind the most recognized and proven brands with top retailers in the United States and Canada. We offer flexible services that maximize efficiency. Acosta has the talent and technology to build data-, reach- and relationship-driven strategies to execute those strategies, and the tools to monitor, track and optimize metrics-based results for customers and retailers.


Acosta and its subsidiaries, in good faith, believes that this posted range of compensation is the accurate range for this role at the time of this posting. Acosta may ultimately pay more or less than the posted range depending on candidate qualifications and locations. This range may be modified in the future.


Acosta and its subsidiaries is an Equal Opportunity Employer


We are committed to providing accommodations for persons with disabilities. If you require accommodation, we will work with you to meet your needs, to the extent required by law.


The above statements are intended to describe the general nature and level of work being performed by people assigned to this classification. They are not intended to be construed as an exhaustive list of all responsibilities, duties, and skills required of personnel so classified. Mosaic reserves the right to modify all or part of any job descriptions at its discretion in order to meet and or exceed the needs of the business.


*By submitting your application you agree with and accept the Acosta Privacy Statement and Terms of Conditions.*


**Acosta et Mosaic** sont les **forces motrices** en matière de **ventes et de marketing** derrière les marques les plus reconnues et éprouvées auprès des principaux détaillants aux États-Unis et au Canada. Nous proposons des services flexibles qui maximisent l’efficacité. Acosta possède le talent et la technologie nécessaires pour élaborer des stratégies axées sur les données, la portée et les relations, afin de mettre en œuvre ces stratégies, ainsi que les outils pour surveiller, suivre et optimiser les résultats basés sur les indicateurs pour les clients et les détaillants.


**Acosta et ses filiales** , de bonne foi, estiment que cette fourchette de rémunération affichée est la fourchette précise pour ce poste au moment de cette publication. Acosta pourrait finalement payer plus ou moins que la fourchette affichée en fonction des qualifications des candidats et des lieux. Cette fourchette peut être modifiée à l’avenir.


**Acosta et ses filiales** sont des employeurs offrant **l’égalité des chances** .


Nous nous engageons à fournir des **aménagements pour les personnes handicapées** . Si vous avez besoin d’un aménagement, nous travaillerons avec vous pour répondre à vos besoins, dans la mesure requise par la loi.


Les déclarations ci-dessus ont pour but de décrire la nature générale et le niveau de travail effectué par les personnes affectées à cette classification. Elles ne doivent pas être interprétées comme une liste exhaustive de toutes les responsabilités, tâches et compétences requises du personnel ainsi classé. Mosaic se réserve le droit de modifier tout ou partie des descriptions de poste à sa discrétion afin de répondre aux besoins de l’entreprise, voire de les dépasser.


En soumettant votre candidature, vous acceptez et acceptez la **Déclaration de confidentialité d’Acosta et les Conditions d’utilisation** .


Acosta, and its subsidiaries, is an Equal Opportunity Employer


**Job Category:** Administration


**Position Type:** Full time


**Business Unit:** Marketing


**Salary Range:** $61,500.00 - $76,900.00


**Company:** Mosaic Sales Solutions US Operating Co, LLC


**Req ID:** 2623","https://www.indeed.com/cmp/Mosaic-North-America-2","","","","","","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/e7695ce9368106bc94a8d147c2b5e7dd","","",""
"b50093d2076e974d","indeed","https://www.indeed.com/viewjob?jk=b50093d2076e974d","http://www.indeed.com/job/data-engineer-dallas-tx-local-only-f2f-interview-required-b50093d2076e974d","Data Engineer || Dallas, TX (Local only) || F2F interview required.","ANB Sourcing LLC","Dallas, TX, US","fulltime, contract","2024-10-01","direct_data","hourly",60.0,65.0,"USD",True,"","","","","","**Data Engineer** 

**Dallas, TX (Local only)- F2F interview required.**

12+ months

***Visa: USC, GC or EAD-GC Only.***

* **8+** **years of experience in Data Engineering.**
* Analyze existing programs or formulates logic for new systems, devises logic procedures, prepares flowcharting, performs coding, and tests/debugs programs.
* Develops conversion and system implementation plans.
* Prepares and obtains approval of system and programming documentation. Recommends changes in development, maintenance, and system standards.
* Trains users in conversion and implementation of system.

Job Types: Full-time, Contract

Pay: $60.00 - $65.00 per hour

Schedule:

* 8 hour shift

Application Question(s):

* Current Location & Visa Status:
* Open for F2F interview in Dallas, TX?

Experience:

* Data Engineer: 8 years (Required)

Work Location: Hybrid remote in Dallas, TX 75201","https://www.indeed.com/cmp/Anb-Sourcing-LLC-2","","","","","","","","",""
"f290ce073ac2cfaa","indeed","https://www.indeed.com/viewjob?jk=f290ce073ac2cfaa","http://www.indeed.com/job/data-architect-f290ce073ac2cfaa","Data Architect","Ariana Solutions","Dallas, TX, US","fulltime, contract","2024-09-30","direct_data","yearly",114342.0,160000.0,"USD",False,"","","","","","**Title - Data Architect(Azure, Databricks)**  
**Location - Dallas, TX, Day one onsite**  
**Salary Range - $180k Per Annum**

**Required Skills/Qualifications:**

* 10-14 years of relevant experience
* Bachelor's and/or master’s degree in computer science or equivalent experience.
* Strong communication, analytical and problem-solving skills with a high attention to detail.

**Desired Experience:**

* At least two years of experience building and leading highly complex, technical engineering teams.
* Strong hands-on experience in Databricks
* Implement scalable and sustainable data engineering solutions using tools such as Databricks, Azure, Apache Spark, and Python. The data pipelines must be created, maintained, and optimized as workloads move from development to production for specific use cases.
* Experience managing distributed teams preferred.
* Comfortable working with ambiguity and multiple stakeholders.
* Comfortable working cross functionality with product management and directly with customers; ability to deeply understand product and customer personas.
* Expertise on Azure Cloud platform
* Good SQL knowledge
* Knowledge on orchestrating workloads on cloud
* Ability to set and lead the technical vision while balancing business drivers
* Strong experience with PySpark, Python programming
* Proficiency with APIs, containerization and orchestration is a plus
* Experience handling large and complex sets of data from various sources and databases
* Solid grasp of database engineering and design principles.
* Experience with Unity Catalog.
* Familiarity with CI/CD methods desired
* Good to have Teradata Experience (not Mandatory)

Job Types: Full-time, Contract

Pay: $114,342.00 - $160,000.00 per year

Benefits:

* Health insurance

Schedule:

* 8 hour shift

Education:

* Bachelor's (Required)

Experience:

* Leadership: 10 years (Required)
* Computer science: 10 years (Required)
* Data Engineer: 10 years (Preferred)
* Data Bricks: 5 years (Preferred)
* Azure: 5 years (Preferred)

Work Location: In person","https://www.indeed.com/cmp/Ariana-Solutions","","","","","","","","",""
"ccc516c3b5782be7","indeed","https://www.indeed.com/viewjob?jk=ccc516c3b5782be7","https://bbinsurance.wd1.myworkdayjobs.com/en-US/Careers/job/Plano-TX-USA/Data-Platform-Engineer_R24_0000003603-1","Data Platform Engineer","Brown & Brown Insurance","Plano, TX, US","fulltime","2024-09-27","direct_data","yearly",90000.0,100000.0,"USD",False,"","","Insurance","","","Built on meritocracy, our unique company culture rewards self-starters and those who are committed to doing what is best for our customers.
Brown & Brown is an independent insurance intermediary that through its licensed subsidiaries provides a variety of insurance and reinsurance products and services to corporate, public entity, institutional, trade, professional, association, and individual clients. Headquartered in Daytona Beach, Florida, offices are located across the United States, with products and services offered through four major business divisions. We are listed on the NYSE at BRO. Our drive to be the best has made Brown & Brown one of the largest and most respected independent insurance intermediaries in the nation, with over 75 years of continuous service. The Company is ranked as the sixth largest such organization in the United States and seventh in the World by Business Insurance magazine.
The Data Platform Engineer is a member of the Enterprise Data Platform team reporting to the Head of Data Engineering. This experienced individual will develop, automate and manage cloud-based data capabilities and technologies in support of both the overall data strategy, architecture and roadmap and the delivery of divisional, corporate and enterprise data assets and insights. Partnering with the operations and delivery teams, they will ensure the availability, stability, performance and scalability of data capabilities and technologies.
Responsibilities:* Engineer, deliver and support automated, Azure cloud-based data capabilities and technologies in support of the Modern Data Platform (MDP) strategy and roadmap.
* Develop, deliver and support Infrastructure As Code templates for MDP capability deployments.
* Monitor, measure and report on the utilization, performance, and cost of MDP capabilities.
* Identify and implement enhancements to further automate and scale the MDP capabilities.
* Provide implementation, production and consulting support to delivery teams leveraging the MDP.
* Collaborate with the Enterprise Data Architecture and Enterprise Data Enablement teams on data solutions and roadmaps.
* Define and automate data platform controls in support of Software Development Lifecycle (SDLC) requirements.
* Mentor and provide guidance to Data Engineers with respect to MDP capabilities.
* Work well with co-located and distributed team members and partners.
* Demonstrate a high degree of creativity and problem-solving skills.
* Other duties as assigned.


Required:* Bachelor’s degree in computer science or related field or equivalent work experience.
* Experience implementing data capabilities and technologies supporting data pipelines, data integration, data transformation, analytics, reporting and modeling (e.g. AI/ML).
* Strong understanding of engineering, implementing, and supporting data platforms and solutions in a cloud environment.
* Hands on experience implementing and using cloud-based storage, data lake, analytics, visualization, SQL, container, dev ops and security services.
* Hands on experience developing and supporting Infrastructure As Code templates.
* Hands on experience working with Python, Java, SQL and JSON.
* Deep understanding of data management and data governance principles.
* Passion for learning new technologies and enhancing existing skills.
* Experience developing, implementing and supporting integrated frameworks across data capabilities and technologies.
* Experience implementing and using CI/CD pipelines and automation.
* Experience in end-to-end Software Development Life Cycle (SDLC) projects.
* Experience working with key stakeholders and technology peers.
* Excellent verbal and written communication skills.
* Self-starter with the ability to build strong relationships and work collaboratively.
* Ability to adapt and respond in a rapidly evolving business environment.
* 5+ years of related work experience.


Preferred:* Experience in the insurance industry and/or basic knowledge of insurance.
* Experience engineering, implementing, and supporting solutions covering multiple geographies.
* Microsoft Azure Solutions Architect Expert, Azure Data Engineer Associate or equivalent certification(s).
* Experience with Azure Data Factory, Azure Synapse Analytics, Azure Databricks, Snowflake and/or equivalent cloud data technologies and platforms.
* Experience with data platforms supporting Data as a Product, Data as a Service, Data Mesh, Data Virtualization, Delta Lake, Lakehouse and/or Data Fabric.


What we offer:* Excellent growth and advancement opportunities
* Competitive pay based on experience.
* Discretionary Time Off (DTO)
* Generous benefits package: health, dental, vision, 401(k), etc.
* Employee Stock Purchase Plan
* Tuition Reimbursement and Student Loan Repayment Assistance
* Mental Health Resources


Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $90,000/year in our lowest geographic market up to $100,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience.
We are an Equal Opportunity Employer. We take pride in the diversity of our team and seek diversity in our applicants.","https://www.indeed.com/cmp/Brown-&-Brown-Insurance","https://www.bbinsurance.com","300 N Beach St
Daytona Beach FL, United States 32114","10,000+","$1B to $5B (USD)","Our culture is built on integrity, innovation, superior capabilities, and discipline. We craft insurance differently by using our experience","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/3faf929bef39f71e04191893d66eecc2","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/ab1ce14b66c5aa1fe32106e46d8f28af","J. Powell Brown","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/34ddad9b59cf9613a0b1feb8e41fd986"
"ad2fdf7f2ecbb413","indeed","https://www.indeed.com/viewjob?jk=ad2fdf7f2ecbb413","https://grnh.se/f76c107b7us","Field Engineer","Striim","Dallas, TX, US","","2024-09-27","direct_data","yearly",130000.0,150000.0,"USD",True,"","","","","","Striim, (pronounced ""stream"" with two i's for integration and intelligence), is a unified data integration and streaming platform that connects clouds, data, and applications with unprecedented speed and simplicity to deliver the right data at the right time. Striim is used by enterprise companies to monitor events across any environment, build applications that drive digital transformation, and leverage true real-time analytics to provide a superior experience to their customers. At our company, we believe and expect all of our employees to operate as one with unlimited potential and dignity.

**Description**



Striim is hiring a field engineer to be a technical leader who will engage with our customers throughout the life cycle of the Striim Platform. A Field Engineer will partner with a Customer Success Manager to create a guided customer journey through all implementation phases, including new customer onboarding, solution architecture strategy, and technical enablement. This is a highly customer-focused role, driving toward operational excellence, continuous learning, and mission-critical innovation. This is a fully technical and hands-on position.


**Responsibilities**


* Onboard new Striim customers, delivering learning, solution strategy, technical enablement, and implementation guidance during the deployment process.
* Lead customer technical teams during development phases to implement best practices and innovate enterprise adoption challenges.
* Support the seamless transition from pre-sales prototypes to post-sales production scale experiences.
* Collaborate with customer success and account management teams to conduct periodic health checks with customers, ensuring operational excellence with Striim.
* Be the Striim product expert, coach, and trusted technical advisor during deployment.
* Be the in-house customer champion, coordinating with Striim customer support and stakeholders to drive technical advocacy, product evolution, and technical innovation.
* Proactively engage existing Striim customers to realize technology value with further adoption of the Striim platform, demonstrating new applications and use cases for Striim.
* Increase internal knowledge base by developing and/or maintaining documentation related to Striim implementations, best practices, and troubleshooting.
* Track customer issues, collaborate with support on customer-training-related matters, and work with customer to develop and track product feature requests (PFRs).
* Report on the status of key accounts, including escalations, to the manager and Customer Success Manager (if applicable).


**Requirements**


* A successful candidate must be based 100% remote somewhere in the Continental United States
* 3+ years of experience in customer-facing technical roles, e.g., Sales Engineer/Pre-sales Engineer, Solutions Architect, Data Engineer, Customer Success Engineer
* 3+ years of experience with database management systems software such as Oracle, MySQL, Microsoft SQL Server, and SQL Programming Language
* 3+ years of experience programming languages such as Java, Python, Shell scripting
* 3+ years of experience or deep core knowledge of Cloud infrastructure and Data Services such as Amazon AWS, Microsoft Azure and Google Cloud
* Principle knowledge in working with, configuring, and troubleshooting Operating Systems based on Unix/Linux and Windows
* Experience working with Message Systems such as Kafka and JMS
* Experience in working with Enterprise data environments and Mission Critical IT systems is desirable
* Knowledge of Snowflake, Google BigQuery or Databricks is a plus
* Excellent written, verbal, and presentation communication skills
* Bachelor's degree in Information Systems, Computer Science, Computer Engineering, Information Systems or equivalent experience


**Benefits**


* We offer
* Competitive salary and pre-IPO stock options
* Private Medical Insurance
* Life Insurance
* Pension Plan
* Income Protection
* Paid Time Off (Discretionary Time Off & Public Holidays)
* The chance to contribute to and shape an upbeat, fully engaged culture


**Compensation**



$130,000 - $150,000 USD on an annualized basis


Our company culture fosters entrepreneurship and nurtures our team members to grow with the company. Come join a Silicon Valley startup focused on delivering a product that's loved by its customers and primed to be a core part of the cloud data stack.



We are an equal opportunity employer, and we value diversity at our company.It is in our best interest to continue to foster an environment of diversity, equity, and inclusion to bring the most value to our workforce, customers, and partners. All applicants are considered for employment without attention to race, color, religion, sex, age, marital status, sexual orientation, gender identity, national origin, veteran status, or disability status.



For more information on Striim's Privacy Policy, click here.","https://www.indeed.com/cmp/Striim","https://www.striim.com","Palo Alto","51 to 200","","","","","",""
"cd5deb2fe188d4f0","indeed","https://www.indeed.com/viewjob?jk=cd5deb2fe188d4f0","https://FMRLLC.contacthr.com/142954853","Principal Data Engineer","Fidelity Investments","Westlake, TX, US","","2024-09-27","direct_data","yearly",120627.0,152741.0,"USD",False,"","","","","accommodations@fmr.com","**Job Description:**
--------------------


We are looking for an experience Data Engineer with a passion for crafting and delivering Data solutions, collaborating in a team environment, with a deep interest in building products that make it easier for our customers to service their client!

**The Team**


This is an exciting role within the Workplace Investing (WI) Solutions Office team. Our team delivers innovative digital solutions to engage and service our customers, while growing the business with reduced risk. Our dynamic and timely solutions provide full-scale experiences that simplify business for associates, clients, and advisors.


One product in which the Principal Data Engineer will play an active lead role is with a digital email assistant tool called Argus. Argus is designed to generate emails and reduce time spent creating repetitive communications. It allows users to send servicing related emails to an entire book of business with as little as two clicks.

**The Expertise You Have**

* BS or MS Degree in Computer Science, Information Technology, or equivalent.
* 10+ years’ experience in Data Engineering
* Experience in ETL/ELT tools: Informatica or SnapLogic
* Experience in Data Virtualization tools: TDV or Denodo
* Experience using relational databases (PostgreSQL, Oracle)
* Experience in database languages: SQL, PSQL, PL/SQL, T-SQL
* Experience in ML and Python is preferred.
* Experience with EDL/Snowflake (Alation)
* Experience with GIT
* Good experience in Agile/Scrum methodologies.
* Solid understanding/experience of Cloud technologies and deployments in AWS using EKS, EC2, RDS and Docker is an advantage.
* Demonstrate strategic thinking and ability to analyze business direction and problems, understand long term vision and risk in developing strategic technical solutions.
* Demonstrate expertise in performance optimization techniques and tools, ensuring efficient and effective system operations
* Experience designing complex data solutions to solve key technical challenges.
* An innovative mindset committed to automating and streamlining manual processes.
* Ability to communicate software engineering and/or development concepts and principles.
* Ability to take up new challenges and explore new technology/tools
* Can collaborate well with the Business, your team members, work independently, and influence your technology peers.

**The Value You Deliver**

* Deliver high quality, innovative and maintainable software solutions in an agile environment.
* Participate in Architecture and Application design.
* Actively contribute to test automation and practices.
* Demonstrate strong leadership, communication, and presentation skills.
* Experience working with distributed teams.
* Understanding of fundamental data design principles.
* Ability to quickly learn, adapt and thrive to meet the needs of a fast paced, changing environment.
* Strong troubleshooting and problem-solving skills.

**Certifications:**
-------------------

**Company Overview**


Fidelity Investments is a privately held company with a mission *to strengthen the financial well-being of our clients.* We help people invest and plan for their future. We assist companies and non-profit organizations in delivering benefits to their employees. And we provide institutions and independent advisors with investment and technology solutions to help invest their own clients’ money.


**Join Us**


At Fidelity, you’ll find endless opportunities to build a meaningful career that positively impacts peoples’ lives, including yours. You can take advantage of flexible benefits that support you through every stage of your career, empowering you to thrive at work and at home. Honored with a Glassdoor Employees’ Choice Award, we have been recognized by our employees as a top 10 Best Place to Work in 2024. And you don’t need a finance background to succeed at Fidelity—we offer a range of opportunities for learning so you can build the career you’ve always imagined.


Fidelity’s hybrid working model blends the best of both onsite and offsite work experiences. Working onsite is important for our business strategy and our culture. We also value the benefits that working offsite offers associates. Most hybrid roles require associates to work onsite all business days of every other week in a Fidelity office.


**At Fidelity, we value honesty, integrity, and the safety of our associates and customers within a heavily regulated industry**. Certain roles may require candidates to go through a preliminary credit check during the screening process. Candidates who are presented with a Fidelity offer will need to go through a background investigation, detailed in this document, and may be asked to provide additional documentation as requested. This investigation includes but is not limited to a criminal, civil litigations and regulatory review, employment, education, and credit review (role dependent). These investigations will account for 7 years or more of history, depending on the role. Where permitted by federal or state law, Fidelity will also conduct a pre-employment drug screen, which will review for the following substances: Amphetamines, THC (marijuana), cocaine, opiates, phencyclidine.


We invite you to **Find Your Fidelity** at fidelitycareers.com.


Fidelity Investments is an equal opportunity employer. We believe that the most effective way to attract, develop and retain a diverse workforce is to build an enduring culture of inclusion and belonging.


Fidelity will reasonably accommodate applicants with disabilities who need adjustments to participate in the application or interview process. To initiate a request for an accommodation, contact the HR Accommodation Team by sending an email to accommodations@fmr.com.","https://www.indeed.com/cmp/Fidelity-Investments","http://www.fidelitycareers.com","Boston, MA","10,000+","more than $10B (USD)","At Fidelity Investments, you’ll find endless opportunities to build a meaningful career that positively impacts peoples’ lives, including yours.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/3b13ae266f49b8b36d02ac0247b514ae","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/91411f9cb266e793f021c34e33a211a6","Abigail P. Johnson, Chairman and CEO","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/89e26e1d327e17504633e7416bbb1768"
"e47360604d9cfd2a","indeed","https://www.indeed.com/viewjob?jk=e47360604d9cfd2a","https://www.paycomonline.net/v4/ats/web.php/jobs/ViewJobDetails?job=242291&clientkey=EE40FAE51728662F692B57A2A934584C&source=Indeed","Senior Data Engineer","FFF Enterprises","Flower Mound, TX, US","","2024-09-26","direct_data","yearly",125000.0,165000.0,"USD",False,"","","","","","**Position Summary**

The Senior Data Engineer will work in a highly motivated team environment and with all the best practices, worth ethics, and processes followed to execute various projects. The Senior Data Engineer will be responsible for collecting, managing, and converting raw data into information that can be interpreted by data scientists, business intelligence developers, and business analysts. The goal of the senior data engineer is to help the organization to utilize data for performance evaluation and optimization.

**Essential Functions and Duties**
==================================

**General Responsibilities:**
=============================

* Provide project and overall day to day support to the organization.
* Supporting a high performing agile delivery team consisting of onsite and offshore members
* Use effective communication and presentation skills to communicate concepts, facilitate conflict resolution and recommended solutions.
* Monitors and organizes the efforts of technical and business support staff.
* Manages projects according to milestones and completes tasks assigned by more experienced analysts and managers. Guides the efforts of less experienced team members.
* Developing data warehousing applications, familiarity with ETL architectures, leveraging multiple sources, (including SAP S4HANA Database and Non-SAP Databases)
* Demonstrate strong knowledge of technology developments within healthcare domain.
* Champion continual quality improvement consistent with companys core values.
* Adheres specifically to all company policies and procedures, Federal and State regulations and laws.
* Display dedication to position responsibilities and achieve assigned goals and objectives.
* Represent the Company in a professional manner and appearance at all times.
* Understand and internalize the Companys purpose; Display loyalty to the Company and its organizational values.
* Display enthusiasm and dedication to learning how to be more effective on the job and share knowledge with others.
* Work effectively with co-workers, internal and external customers and others by sharing ideas in a constructive and positive manner; listen to and objectively consider ideas and suggestions from others; keep commitments; keep others informed of work progress, timetables, and issues; address problems and issues constructively to find mutually acceptable and practical business solutions; address others by name, title, or other respectful identifier, and; respect the diversity of our work force in actions, words, and deeds.
* Comply with the policies and procedures stated in the Injury and Illness Prevention Program by always working in a safe manner and immediately reporting any injury, safety hazard, or program violation.
* Ensure conduct is consistent with all Compliance Program Policies and procedures when engaging in any activity on behalf of the company. Immediately report any concerns or violations.
* Other duties as assigned.
**Education, Knowledge, Skills, and Experience**
================================================

**Required Education:**

* Bachelors Degree in or a related field of study or four (4) years of related experience in lieu of degree.

**Required Knowledge:**
=======================

* Experience working in Healthcare Life Sciences
* Informatica IICS experience
* Excellent SQL skills
* Google Cloud Platform Foundation (BigQuery/SQL experience)

**Required Experience:**
========================

* Must have at least three (3) years experience [seven (7) years for non-degreed candidates] as an Informatica Intelligent Cloud Services (IICS) Developer
* Data warehouse experience (At least 5 years)
* SQL experience (At least 5 years)
* Google BigQuery (Preferred)

**Required Skills:**
====================

* Forward thinking, independent, creative, and self-sufficient who can work with less documentation, has exposure working in complex multi-tiered integrated applications.
* Strong SQL experience with the ability to develop, tune and debug complex SQL applications.
* Experience with Google Cloud Platform, BigQuery and Informatica Intelligent Cloud Services (IICS).
* Ability to interact well with user base, development teams and other technical team members.
* Experience with database design, querying, stored procedures, views, joins, performance tuning etc.
* Experience with load optimization for Informatica batch processes
* Ability to diagnose and resolve issues/problems in aggressive timeframes.
* Strong analytical, problem-identification/solving skills, as well as strong written and oral communication skills.
* Experience in querying and analyzing data coming from multiple sources and determine logic for transformations.
* Ability to interact well with user base, development teams and other technical teams.
* Providing production support for daily, weekly, and monthly production processes.
* Provides data modeling where needed to enable data movement or improve data architecture.
* Demonstrates advanced analytical and problem-solving skills in resolving complex discrepancies, by actively suggesting and assisting in implementing process improvements and procedures.
* Excellent verbal and written communication skills and the ability to interact effectively with end users, co-workers, and management.
* Ability to exercise discretion and maintain confidentiality to the level of required HIPAA standards.
* Intermediate to advanced Microsoft Office skills
**Physical requirements**

Vision, hearing, speech, movements requiring the use of wrists, hands and/or fingers. Must have the ability to view a computer screen for long periods and the ability to sit for extended periods. Must have the ability to work the hours and days required to complete the essential functions of the position, as scheduled. Must be able to travel occasionally. The employee occasionally lifts up to 20 lbs. and occasionally kneels and bends. Working condition include normal office setting.

**Mental Demands**

Learning, thinking, concentration and the ability to work under pressure, particularly during busy times. Must be able to pay close attention to detail and be able to work as a member of a team to ensure excellent customer service. Must have the ability to interact effectively with co-workers and customers, and exercise self-control and diplomacy in customer and employee relations situations. Must have the ability to exercise discretion as well as appropriate judgments when necessary. Must be proactive in finding solutions.

**Direct Reports**
==================

Project resources (in-house)

**EEO/AAP Statement**

FFF Enterprises/ NuFactor is an equal opportunity employer to all and prohibits discrimination and harassment based on the following characteristics: race, color, caste, religion, religious creed (including religious dress and grooming practices), national origin, ancestry, citizenship, physical or mental disability, medical condition (including cancer and genetic conditions), genetic information, marital status, sex (including pregnancy, childbirth, breastfeeding, or related medical conditions), gender, gender identity, gender expression, age (40 years and over), sexual orientation, veteran or military status, medical leave or other types of protected leave (requesting or approved for leave under the Family and Medical Leave Act or any state protected leaves), domestic violence victim status, political affiliation, reproductive health decision-making, and any other characteristic protected by state or federal anti-discrimination law covering employment. These categories are defined according to Government Code section 12920. The Company prohibits unlawful discrimination based on the perception that anyone has any of those characteristics or is associated with a person who has or is perceived as having any of those characteristics.","https://www.indeed.com/cmp/Fff-Enterprises","http://www.fffenterprises.com","Temecula, CA","201 to 500","$1B to $5B (USD)","","","","",""
"177761b3a347dabd","indeed","https://www.indeed.com/viewjob?jk=177761b3a347dabd","http://www.indeed.com/job/data-engineer-177761b3a347dabd","Data Engineer","Rapideagle ","Dallas, TX, US","temporary, contract","2024-09-26","direct_data","hourly",62.0,66.0,"USD",True,"","","","","","**Data Engineer**

**W2 Onsite** 

**Dallas TX**

***Certifications like Snowpro Advanced Data Analyst OR Snowpro Advanced Data Science Required***

**Responsibilities**  
- Design and implement scalable data pipelines for ETL processes to support analytics initiatives.  
- Collaborate with cross-functional teams to gather requirements and understand data needs.  
- Develop and maintain database designs that optimize performance and reliability.  
- Utilize AWS or Azure Data Lake services to manage cloud-based data storage solutions.  
- Perform data analysis and vaticinate trends that can inform business decisions.  
- Write efficient Shell scripts for automation of repetitive tasks.  
- Ensure data quality and integrity through rigorous testing and validation processes.  
- Participate in Agile development processes, contributing to sprint planning and retrospectives.  
- Stay updated on emerging technologies in big data analytics to continuously improve our systems.

**Qualifications**  
- Proven experience as a Data Engineer or in a similar role with a focus on big data technologies.  
- Strong proficiency in database design principles and ETL methodologies.  
- Experience with cloud platforms such as AWS or Azure Data Lake is highly desirable.  
- Familiarity with programming languages such as Java for developing data processing applications.  
- Knowledge of analytics tools and frameworks to support business intelligence efforts.  
- Excellent problem-solving skills with the ability to vaticinate potential issues before they arise.  
- Strong communication skills with the ability to work collaboratively in a team environment.  
- Experience working in an Agile development setting is preferred.

Join us in leveraging the power of data to drive impactful decisions within our organization!

Job Types: Temporary, Contract

Pay: $62.70 - $66.38 per hour

Work Location: Hybrid remote in Dallas, TX 75241","https://www.indeed.com/cmp/Rapideagle","","","","","","","","",""
"f5934cd01884a60f","indeed","https://www.indeed.com/viewjob?jk=f5934cd01884a60f","http://www.indeed.com/job/data-engineer-f5934cd01884a60f","Data Engineer","Creed Infotech","Plano, TX, US","contract","2024-09-25","direct_data","hourly",62.0,65.0,"USD",False,"","","","","","Development and implementation of data integration solutions involving Informatica and Hadoop.  
Should be able to lead multiple projects concurrently each with competing deadlines.  
Should be knowledgeable in Treasury Payments and Deposits domains.  
Serves as a fully seasoned/proficient technical resource; provides technical knowledge and capabilities as team member and individual contributor.  
Typically 5-7 or more years of data delivery/integration experience  
Works under minimal supervision  
Has the knowledge of Hadoop Spark/Spark Streaming best practices and standards as well as standard software development lifecycle experience.  
Must have an understanding of our ability to quickly grasp technology concepts  
Solid quantitative, analytical, process development, facilitation skills, and organizational skills required  
Strong communication, presentation, interpersonal, software development and work management skills are essential  
Coordinate with deployment and support teams and ensure projects are successfully deployed into testing and Production environments.  
Development experience using Agile process  
Experience in designing, developing and deploying Real time and Near real time batch data integration solutions  
Work with people in different time zones teams

**Primary Skills:**  
Informatica  
Oracle Exadata  
SQL  
Hadoop

Job Type: Contract

Pay: $62.00 - $65.00 per hour

Benefits:

* 401(k)
* Dental insurance
* Health insurance

Schedule:

* 8 hour shift

Experience:

* Informatica: 5 years (Required)
* SQL: 6 years (Preferred)
* Data warehouse: 5 years (Preferred)

Ability to Relocate:

* Plano, TX 75023: Relocate before starting work (Required)

Work Location: In person","https://www.indeed.com/cmp/Creed-Infotech","","","","","","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/b09ffc7ce8847ba2908d685c46060209","","",""
"d7349db04ac9ad11","indeed","https://www.indeed.com/viewjob?jk=d7349db04ac9ad11","https://searchjobs.libertymutualgroup.com/careers/job/618500456608?microsite=libertymutual.com&domain=libertymutual.com","Principal Data Engineer","Liberty Mutual Insurance","Plano, TX, US","fulltime","2024-09-19","direct_data","yearly",116700.0,218300.0,"USD",False,"","","","","","**Pay Philosophy**
The typical starting salary range for this role is determined by a number of factors including skills, experience, education, certifications and location. The full salary range for this role reflects the competitive labor market value for all employees in these positions across the national market and provides an opportunity to progress as employees grow and develop within the role. Some roles at Liberty Mutual have a corresponding compensation plan which may include commission and/or bonus earnings at rates that vary based on multiple factors set forth in the compensation plan for the role.

 **Description**Under general direction, acts as a technical expert who consults on highly complex projects. Responsible for the analysis, development and execution of complex data solutions, in order to manage the information lifecycle needs of an organization. Collects, integrates and analyzes organizational data with the purpose of drawing conclusions about that information. Develops, constructs, tests and maintains data architectures for data platform, database, analytical/reporting, or data science systems. Establishes and builds data systems including providing standards, policies, practice, procedures, governance and quality assurance for data deliverables. Recommends methods to improve data reliability, quality, and efficiency. Devises or modifies procedures to solve technical problems. Leads and directs the work of team members. May mentor junior team members.

 **Responsibilities**

  

Builds and designs complex data models and data architecture that improve accessibility, efficiency, governance and quality of data. Makes recommendations for how to improve data and drives those recommendations forward. Identifies business process improvements that address highly complex technology gaps within a single business process. Builds in-depth knowledge of technology enablers. Consult on highly complex technology enabled recommendations to address gaps within a single business process. Proactively identifies potential impact on business strategy. Documents existing processes, organizational structures, architectures and external systems. Consults on designing and developing of complex programs and tools to support ingestion, curation and provisioning of complex enterprise data to achieve analytics, reporting, and data science. Involved in and contributes to development and enhancement of solutions for gaps. Supports the Solutions Engineer in implementation. Support can include but is not limited to; cutover plans, post-implementation support, any issues/defects, transition planning, and knowledge sharing efforts.

**Qualifications*** Bachelor or Master`s degree in technical or business discipline or equivalent experience, technical degree preferred
* Generally 8+ years of professional experience
* In-depth knowledge of IT concepts, strategies and methodologies
* In-depth knowledge of diverse and emerging technologies and new architectural concepts and principles
* Knowledgeable in data engineering languages and tools; proficient in new and emerging technologies
* In-depth understanding of layered solutions and designs; in-depth understanding of shared data engineering concepts and product features, as well as security minded
* In-depth knowledge of business operations, objectives and strategies; in-depth understanding of global business and technology trends and the financial services industry
* Highly developed negotiation, consensus building & influencing skills, facilitation and the adaptability to respond to change quickly
* Highly developed oral and written communication skills; strong presentation skills
* Ability to effectively collaborate with all levels of the organization


Essential Skills:

* Expert knowledge of the ACORD XML canonical model.
* Experience with ACORD.org.
* Experience participating on XML governance.
* Expert in commercial insurance policy applications and their data uses.
* Expert understanding of data mapping methodologies, frameworks, and documentation.
* Experience with data mapping.

**About Us**
\\*\\*This position may have in-office requirements depending on candidate location.\\*\\*  

  

At Liberty Mutual, our purpose is to help people embrace today and confidently pursue tomorrow. That's why we provide an environment focused on openness, inclusion, trust and respect. Here, you'll discover our expansive range of roles, and a workplace where we aim to help turn your passion into a rewarding profession.  

  

Liberty Mutual has proudly been recognized as a ""Great Place to Work"" by Great Place to Work® US for the past several years. We were also selected as one of the ""100 Best Places to Work in IT"" on IDG's Insider Pro and Computerworld's 2020 list. For many years running, we have been named by Forbes as one of America's Best Employers for Women and one of America's Best Employers for New Graduates as well as one of America's Best Employers for Diversity. To learn more about our commitment to diversity and inclusion please visit: https://jobs.libertymutualgroup.com/diversity-inclusion  

  

We value your hard work, integrity and commitment to make things better, and we put people first by offering you benefits that support your life and well-being. To learn more about our benefit offerings please visit: https://LMI.co/Benefits  

  

Liberty Mutual is an equal opportunity employer. We will not tolerate discrimination on the basis of race, color, national origin, sex, sexual orientation, gender identity, religion, age, disability, veteran's status, pregnancy, genetic information or on any basis prohibited by federal, state or local law.  

  

**Fair Chance Notices**

* California
* San Francisco
* Los Angeles
* Philadelphia","https://www.indeed.com/cmp/Liberty-Mutual-Insurance","http://www.libertymutualgroup.com","Boston, MA","10,000+","more than $10B (USD)","Liberty Mutual Insurance is a diversified global insurer with over 50,000 employees located in more than 900 offices throughout the world.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/bf1eb916777af10bec37abe480366b5c","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/5037aab342ca36a4903ca2eb66a448b3","Tim Sweeney","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/cac32de8c853f4f5dba4ec82f9eda463"
"1009480274538","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009480274538","","Partner Data Engineer, YouTube Measurement Infrastructure","Google","San Bruno, CA","","2024-10-10","description","yearly",118000.0,174000.0,"USD",False,"","","","organic","","**Note:** By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; New York, NY, USA; San Bruno, CA, USA.
  
  

**Minimum qualifications:**  

* Bachelor's degree or equivalent practical experience.
* 3 years of experience working with data infrastructure and data models by performing exploratory queries and scripts.
* 3 years of experience with ETL and SQL.
* 3 years of experience working with Python and coding in one or more programming languages: C/C++, Java, Go, Unix/Linux systems.
* 2 years of experience in a client-facing role.


**Preferred qualifications:**  

* 2 years of experience in data visualization.
* Experience working with Google’s data processing stack (e.g., PLX, SQL Pipelines, GoogleSQL).
* Experience working with Google’s technical infrastructure (e.g., Borg, Rapid, Boq).
* Advanced root cause analysis, statistical, time-series and predictive modeling skills.


About the job
  
  

The YouTube Infrastructure Measurement Partner Engineering is responsible for developing and managing production-grade infrastructure to ensure that YouTube is represented fairly in third-party reporting tools, the internal data feeding those tools is accurate and consistent, and supporting data needs for various verticals such as YouTube Shopping, YouTube TV, to Integrated Billing. We provide infrastructure support, data mining, and thought leadership to several initiatives shaping the long-term direction of YouTube.
  
As a Partner Data Engineer on the YouTube Measurement Infrastructure Partner Engineering team, you will be responsible for managing infrastructure solutions that will power YouTube's various strategic initiatives such as public claims and Ads partner integrations.
  
In this role, you will have the opportunity to design and implement large-scale data pipeline solutions combining data from multiple internal and external data sources. This data will serve as the foundation for various analytical and data science initiatives, providing our cross-functional stakeholders with unique insights and values not found elsewhere.
  
At YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.
  
The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more aboutbenefits at Google.
  
  

Responsibilities
  
  

* Manage YouTube data feeds and provide ongoing technical support to internal partners for a wide range of YouTube’s viewership metrics initiatives.
* Provide infrastructure solutions for external audience measurement partner integrations.
* Guarantee the technical aspects of YouTube viewership data integrations (both new and ongoing) by providing technical guidance and documentation.
* Identify, drive, and optimize new third-party reporting opportunities by leveraging YouTube technologies.
* Write and maintain lines of code (Python, C++, etc.) to support your own medium to large-scale Extract, Transform, Load (ETL) pipelines.


Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See alsoGoogle's EEO Policy andEEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing ourAccommodations for Applicants form.","https://www.glassdoor.com/Overview/W-EI_IE9079.htm","","","","","","https://media.glassdoor.com/sql/9079/google-squarelogo-1441130773284.png","","",""
"1009480824678","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009480824678","","Lead Data Engineer","Nuna","San Francisco, CA","","2024-10-10","direct_data","yearly",188000.0,273500.0,"USD",False,"","","","organic","","*At Nuna, our mission is to make high-quality healthcare affordable and accessible for everyone. We are dedicated to tackling one of our nation's biggest problems with ingenuity, creativity, and a keen moral compass.*  

  

*Nuna is committed to simple principles: a rigorous understanding of data, modern technology, and most importantly, compassion and care for our fellow human. We want to know what really works, what doesn't—and why.*

**YOUR TEAM**
-------------



You will join an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and data engineering. You will be part of the larger team building Nuna's Patient and Provider products, which reward patients for healthy behaviors as they manage chronic disease.



The team is responsible for evaluating impact and developing critical algorithmic and quantitative features across these products. This involves bringing analytical rigor to product definition, monitoring, and evaluation; design, development, and evaluation of predictive algorithms; and the maintenance and expansion of a flexible Data Platform. The team takes an ownership attitude and has a strong culture of internal review and collaboration. We work closely with engineering, product, design, and account management teams.


**YOUR OPPORTUNITIES**
----------------------



We are looking for someone who is excited to use their expertise in building scalable data engineering solutions to make a difference in healthcare. You will have the opportunity to play a foundational role in the success of a burgeoning product at Nuna and the ability to shape the data engineering function. The Data Platform supports multiple data products across analytics, experimentation, model serving, and more.


* Contribute to and expand upon the architecture of a growing Data Platform
* Establish data engineering and software best practices in the team
* Hands-on development of Data Platform capabilities - e.g. write code to ingest and transform complex data sources, maintain deployment process, etc.
* Articulate pros and cons of competing tools to inform choices and build vs buy decisions
* Serve as a mentor for team members in code quality and review
* Work closely with data scientists, analysts, and actuaries to identify opportunities to improve workflows and increase overall efficiency

**QUALIFICATIONS**
------------------


#### **Required Qualifications**


* BS/MS in a quantitative field (e.g. Computer Science, Engineering) + 10 years of engineering/equivalent experience
* 7+ years of experience building systems that manage the ingest, transformation, and management of multimodal data types
* Deep knowledge of modern data infrastructure best practices
* Proficiency with tools spanning the range of the following: AWS S3, Terraform, Airflow, Glue / Unity catalog, pytest, spark/pyspark, python, SQL (or analogous)
* Experience with data governance, traceability, etc.
* Proficiency with cloud platforms (AWS preferred)
* Experience in a zero-to-one setting
* Interest in improving healthcare and working with interdisciplinary project teams
* Clear communication and presentation skills

#### **Preferred Qualifications**


* Experience with Databricks product suite, especially Unity catalog
* Experience in a HIPAA-compliant environment
* MLOps experience


We take into account an individual's qualifications, skillset, and experience in determining final salary. This role is eligible for health insurance, life insurance, retirement benefits, participation in the company's equity program, paid time off, including vacation and sick leave. The expected salary range for this position is $188,000 to $273,500. The actual offer will be at the company's sole discretion and determined by relevant business considerations, including the final candidate's qualifications, years of experience, and skillset.

*Nuna is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics and/or veteran status.*","https://www.glassdoor.com/Overview/W-EI_IE1830313.htm","","","","","","https://media.glassdoor.com/sql/1830313/nuna-squareLogo-1636763720319.png","","",""
"1009479469322","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009479469322","","Senior Data Engineer (I,II,III)","Cellares","South San Francisco, CA","","2024-10-09","direct_data","yearly",90000.0,210000.0,"USD",False,"","","","organic","","We are seeking an experienced Senior Data Engineer who will contribute to developing our advanced cell therapy manufacturing platform. This role will lead the design, development, and management of scalable data pipelines and architecture.  

The ideal candidate has extensive experience in data engineering, a strong understanding of modern data architectures, and a deep knowledge of big data technologies. This role involves working with large datasets, ensuring data quality, and collaborating with cross-functional stakeholders across the organization to provide data-driven business outcomes for our cell therapy business.  

We're looking for someone who thrives in a fast-paced, mission-driven environment, is comfortable wearing multiple hats, and is ready to tackle diverse challenges as our company grows.### **Responsibilities**

+ Architect, design, and implement data pipelines and infrastructure to support the implementation of data analytics and AI solutions, leveraging Azure Cloud Platform and Databricks technologies
+ Collaborate with cross-functional teams to understand project requirements, translate them into technical specifications, and develop scalable and efficient data solutions
+ Build and maintain data ingestion, transformation, and storage systems using Azure services such as Azure Database for PostgreSQL, Azure Blob storage, and Azure Databricks, ensuring data quality, reliability, and security
+ Work closely with cell therapy process developers, manufacturing operators, and scientists to preprocess and prepare data for machine learning models, performing feature engineering, data augmentation, and exploratory data analysis as needed
+ Implement monitoring, logging, and alerting mechanisms to track data pipeline performance and ensure timely identification and resolution of issues
+ Document data engineering processes, workflows, and best practices and provide guidance and support to project team members as needed
### **Requirements**

+ Bachelor's or Master's degree in Computer Science, Engineering, or a related technical field with at least 6 years of related industry experience
+ Proven experience in data engineering, with a focus on building data pipelines and infrastructure in cloud environments, preferably on Microsoft Azure
+ Strong proficiency in Azure services such as Azure Databricks, Azure Database for PostgreSQL, Azure Table Storage, Azure Cosmos DB
+ Proficiency in managing, optimizing, and data integration with Elasticsearch clusters
+ Experience with data preprocessing, feature engineering, and data modeling techniques, particularly in the context of data analytics, machine learning, and AI applications
+ Proficiency in programming languages such as Python or C#, with experience in developing scalable and efficient data processing code
+ Expertise with data visualization tools such as Microsoft Power BI and Tableau
+ Familiarity with data governance, compliance, and security best practices, especially in regulated industries such as medical devices, cell therapy, bioprocessing, or instrumentation
+ Excellent problem-solving and analytical skills, with the ability to troubleshoot complex data engineering issues and optimize performance
+ Effective communication and collaboration skills, with the ability to work in cross-functional teams and interact with stakeholders at all levels
+ Comfortable working in a fast-paced start-up company environment with minimal direction and changing priorities
+ Ability to be a strong problem solver and team player
+ Self-awareness, integrity, authenticity, and a growth mindset
+ This will be a full-time onsite position in South San Francisco or Chicago

$90,000 - $210,000 a year  

Cellares total compensation package contains competitive base salaries, highly subsidized Medical, Dental, and Vision Plans, 401(k) Matching, Free EV Charging, Onsite lunches, and Stock options. All displayed pay ranges are approximate, negotiable, and location dependent.","https://www.glassdoor.com/Overview/W-EI_IE2995617.htm","","","","","","https://media.glassdoor.com/sql/2995617/cellares-squarelogo-1634638789882.png","","",""
"1009479542950","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009479542950","","Senior Data Engineer","DocuSign","San Francisco, CA","","2024-10-09","direct_data","yearly",134900.0,216975.0,"USD",False,"","","","organic","accommodations@docusign.com, taops@docusign.com","**Company Overview**
--------------------

  

Docusign brings agreements to life. Over 1.5 million customers and more than a billion people in over 180 countries use Docusign solutions to accelerate the process of doing business and simplify people’s lives. With intelligent agreement management, Docusign unleashes business-critical data that is trapped inside of documents. Until now, these were disconnected from business systems of record, costing businesses time, money, and opportunity. Using Docusign’s Intelligent Agreement Management platform, companies can create, commit, and manage agreements with solutions created by the #1 company in e-signature and contract lifecycle management (CLM).  

  

**What You'll Do**
------------------

  

Docusign is seeking a talented and results oriented Data Engineer to focus on delivering trusted data to the business. As a member of the Global Data Analytics (GDA) Team, the Data Engineer leverages a variety of technologies to design, develop and deliver new features in addition to loading, transforming and preparing data sets of all shapes and sizes for teams around the world. During a typical day, the Engineer will spend time developing new features to analyze data, develop solutions and load tested data sets into the Snowflake Enterprise Data Warehouse. The ideal candidate will demonstrate a positive “can do” attitude, a passion for learning and growing, and the drive to work hard and get the job done in a timely fashion. This individual contributor position provides plenty of room to grow - a mix of challenging assignments, a chance to work with a world-class team, and the opportunity to use innovative technologies such as AWS, Snowflake, dbt, Airflow and Matillion.  

This position is an individual contributor role reporting to the Manager, Data & Analytics. **Responsibility**

* Design, develop and maintain scalable and efficient data pipelines
* Analyze and develop data quality and validation procedures
* Work with stakeholders to understand the data requirements and provide solutions
* Troubleshoot and resolve data issues in a timely manner
* Collaborate with cross-functional teams to ingest data from various sources
* Evaluate and improve data architecture and processes continuously
* Own, monitor, and improve solutions to ensure SLAs are met
* Develop and maintain documentation for Data infrastructure and processes
* Execute projects using Agile Scrum methodologies

  

  

**Job Designation**
-------------------

 **Hybrid:**


Employee divides their time between in-office and remote work. Access to an office location is required. (Frequency: Minimum 2 days per week; may vary by team but will be weekly in-office expectation)

  

Positions at Docusign are assigned a job designation of either In Office, Hybrid or Remote and are specific to the role/job. Preferred job designations are not guaranteed when changing positions within Docusign. Docusign reserves the right to change a position's job designation depending on business needs and as permitted by local law.

  

  

**What You Bring**
------------------

 **Basic**

* Bachelor’s Degree in Computer Science, Data Analytics, Information Systems, etc.
* Experience developing data pipelines in one of the following languages: Python or Java
* 8+ years dimensional and relational data modeling experience
* Experience with SQL and database management

**Preferred**

* 8+ years in data warehouse engineering (OLAP) Snowflake, BigQuery, Teradata, Redshift
* 8+ years with transactional databases (OLTP) Oracle, SQL Server, MySQL
* 8+ years with big data, Hadoop, Data Lake, Spark in a cloud environment(AWS)
* 8+ years with commercial ETL tools – dbt, Matillion, and SSIS/ADF
* 8+ years delivering ETL solutions from source systems, databases, APIs, flat-files, JSON
* Experience developing Entity Relationship Diagrams with Erwin, SQLDBM, or equivalent
* Experience working with job scheduling and monitoring systems (Airflow, Datadog, AWS SNS)
* Experience building BI Dashboards with tools like Tableau
* Experience in any of the financial, Marketing, Sales, accounts payable, accounts receivable, invoicing etc domains
* Experience managing work assignments using tools like Jira and Confluence
* Experience with Scrum/Agile methodologies is a plus.
* Ability to work independently and as part of a team
* Excellent analytical and problem solving skills

  

  

**Wage Transparency**
---------------------

  

Pay for this position is based on a number of factors including geographic location and may vary depending on job-related knowledge, skills, and experience.  

Based on applicable legislation, the below details pay ranges in the following locations:  

California: $134,900.00 - $216,975.00 base salary  

This role is also eligible for bonus, equity and
benefits.

  

Global benefits provide options for the following:  

* Paid Time Off: earned time off, as well as paid company holidays based on region
* Paid Parental Leave: take up to six months off with your child after birth, adoption or foster care placement
* Full Health Benefits Plans: options for 100% employer paid and minimum employee contribution health plans from day one of employment
* Retirement Plans: select retirement and pension programs with potential for employer contributions
* Learning and Development: options for coaching, online courses and education reimbursements
* Compassionate Care Leave: paid time off following the loss of a loved one and other life-changing events

  

  

**Life At Docusign**
--------------------

 **Working here**


Docusign is committed to building trust and making the world more agreeable for our employees, customers and the communities in which we live and work. You can count on us to listen, be honest, and try our best to do what’s right, every day. At Docusign, everything is equal.  

We each have a responsibility to ensure every team member has an equal opportunity to succeed, to be heard, to exchange ideas openly, to build lasting relationships, and to do the work of their life. Best of all, you will be able to feel deep pride in the work you do, because your contribution helps us make the world better than we found it. And for that, you’ll be loved by us, our customers, and the world in which we live. **Accommodation**


Docusign is committed to providing reasonable accommodations for qualified individuals with disabilities in our job application procedures. If you need such an accommodation, or a religious accommodation, during the application process, please contact us at accommodations@docusign.com.  

If you experience any issues, concerns, or technical difficulties during the application process please get in touch with our Talent organization at taops@docusign.com for assistance.
  
### **Our global benefits**


#### **Paid time off**


Take time to unwind with earned days off, plus paid company holidays based on your region.
#### **Paid parental leave**


Take up to six months off with your child after birth, adoption or foster care placement.
#### **Full health benefits**


Options for 100% employer-paid health plans from day one of employment.
#### **Retirement plans**


Select retirement and pension programs with potential for employer contributions.
#### **Learning & development**


Grow your career with coaching, online courses and education reimbursements.
#### **Compassionate care leave**


Paid time off following the loss of a loved one and other life-changing events.","https://www.glassdoor.com/Overview/W-EI_IE307604.htm","","","","","","https://media.glassdoor.com/sql/307604/docusign-squareLogo-1712840936863.png","","",""
"1009479094860","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009479094860","","Data engineer","Writer","San Francisco, CA","","2024-10-09","direct_data","yearly",103322.0,157510.0,"USD",False,"","","","organic","","**About Writer**


Writer is the full-stack generative AI platform delivering transformative ROI for the world’s leading enterprises. Named one of the top 50 companies in AI by Forbes, Writer empowers hundreds of customers like Accenture, Intuit, L’Oreal, and Vanguard to transform the way they work.


Our all-in-one solution makes it easy to deploy customized AI apps and workflows that accelerate growth, increase productivity, and ensure compliance. Designed to provide enterprise-grade accuracy, security, and efficiency, Writer’s suite of development tools is supported by Palmyra – Writer’s state-of-the-art family of LLMs – alongside our industry-leading graph-based RAG and customizable AI guardrails.


Founded in 2020 with offices in San Francisco, New York City, and London, Writer is backed by strategic investors, including ICONIQ Growth, Insight Partners, WndrCo, Balderton Capital, and Aspect Ventures.


Our team of over 200 employees thinks big and moves fast, and we’re looking for smart, hardworking builders and scalers to join us on our journey to create a better future of work.

**About this role**


We are looking for our first ever Data Engineer to join our team. This role presents an extremely rare and unique opportunity to influence the architecture and tools that power our data analytics and reporting capabilities. You’ll be at the intersection of engineering, product and data, leading the integration of our product, financial, and business systems. If you are passionate about data modeling and solving complex data problems, we want to hear from you!

 **Tech stack**


Core tools: BigQuery, dbt, Fivetran, Hightouch, Segment, Amplitude, Omni


Periphery tools: Salesforce, Hubspot, Gong, Vitally

 **Your responsibilities**

* **Data Workflows**: Own, build, and maintain data pipelines, ETL/reverse-ETL processes and BigQuery environment.
* **Data Quality**: Implement an orchestration tool. Design a suite of tests and validations to ensure data consistency, accuracy and integrity.
* **Data Modeling**: Develop reliable and lasting data models, while optimizing for scale.
* **Documentation**: Catalog and document all aspects of our data pipelines. Create the foundation for a data governance program.
* **Collaboration**: Partner with product and engineering teams to deliver data solutions that align with downstream use cases.
* **Data Leadership**: Establish data engineering best practices and serve as a subject matter expert on our data architecture, models and systems.

**️ Is this you?**

* 5+ years of hands-on experience in a data engineering role, ideally in a SaaS environment
* Expert in SQL, dbt and Python
* Advanced knowledge of data engineering tools, frameworks and languages (eg. Airflow, Airbyte, Kafka, github workflows)
* Experience working with services in cloud environment (eg. AWS or GCP)
* Care deeply about data quality, integrity and security
* Thrive in ambiguity and can create paved roads from dirt paths
* Bonus points if you have experience with product event/attribute tracking design and implementation


AND

* High intellectual curiosity and a proclivity to lean into a new subject matter
* A trusted advisor and partner for all levels of the organization
* Intrinsically motivated: you set the highest possible bar for what you build and ship
* An eye for spotting an opportunity, intuition for determining which ones to prioritize, and courage to follow through
* Possesses humility — no work is too trivial if it’s impactful
* Resilient and open to honest (and kind) feedback; tough skin
* Self-aware and committed to learning the why for both successes and failures
* Proactive communication skills, both sync and async
* Experience managing and building relationships across multiple departments and stakeholder levels
* A natural affinity to our values of connect, challenge, own


Curious to learn more about who we are and how we operate? Visit us here

**Benefits & perks**

* Generous PTO, plus company holidays
* Medical, dental, and vision coverage for you and your family
* Paid parental leave for all parents (12 weeks)
* Fertility and family planning support
* Early-detection cancer testing through Galleri
* Flexible spending account and dependent FSA options
* Health savings account for eligible plans with company contribution
* Annual work-life stipends for:


	+ Home office setup, cell phone, internet
	+ Wellness stipend for gym, massage/chiropractor, personal training, etc.
	+ Learning and development stipend
* Company-wide off-sites and team off-sites
* Competitive compensation, company stock options and 401k

*Writer is an equal-opportunity employer and is committed to diversity. We don't make hiring or employment decisions based on race, color, religion, creed, gender, national origin, age, disability, veteran status, marital status, pregnancy, sex, gender expression or identity, sexual orientation, citizenship, or any other basis protected by applicable local, state or federal law. Under the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.*


By submitting your application on the application page, you acknowledge and agree to Writer's Global Candidate Privacy Notice.","https://www.glassdoor.com/Overview/W-EI_IE533133.htm","","","","","","https://media.glassdoor.com/sql/533133/writer-corporation-squarelogo-1509364586410.png","","",""
"1009477514871","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009477514871","","Data Engineer","Abbott Laboratories","Alameda, CA","","2024-10-08","direct_data","yearly",95500.0,190900.0,"USD",False,"","","","organic","","Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 114,000 colleagues serve people in more than 160 countries.

**Working at Abbott**


At Abbott, you can do work that matters, grow, and learn, care for yourself and family, be your true self and live a full life. You’ll also have access to:

* Career development with an international company where you can grow the career you dream of.
* Free medical coverage for employees\\* via the Health Investment Plan (HIP) PPO
* An excellent retirement savings plan with high employer contribution
* Tuition reimbursement, the Freedom 2 Save student debt program and FreeU education benefit - an affordable and convenient path to getting a bachelor’s degree.
* A company recognized as a great place to work in dozens of countries around the world and named one of the most admired companies in the world by Fortune.
* A company that is recognized as one of the best big companies to work for as well as a best place to work for diversity, working mothers, female executives, and scientists.

**The Opportunity**

Research is fueled by data. Our research scientists need data to continue building innovative algorithms and they need an inventive data engineer to build the pipeline that will feed them.

**What You’ll Work On**

* Design, develop, optimize, and maintain data architecture and pipelines for analyzing large data sets and identify patterns and relationships.
* Solve complex data problems to deliver insights that help the organization achieve its goals
* Manage data sources, organize data and create data assets using identified open source or proprietary tools
* Design and implement cloud security and access control mechanisms to protect the data from unauthorized use
* Interact with other technology teams to define, prioritize, and ensure smooth deployments for other operational components.
* Advise, consult, mentor, and coach other data and analytics professionals on data standards and practices.
* Foster a culture of sharing, reuse, design for scale stability, and operational efficiency of data and analytical solutions.
* Codify best practices for future reuse in the form of accessible, reusable patterns, templates, and code bases to facilitate data capturing and management.
* Code in SQL to create curated data products.

**Required Qualifications**

* Bachelor’s degree in any of the following – Engineering, Computer Science or other technical field
* Minimum 6 years of relevant experience in data engineering/analytics space
* Experience developing solutions for cloud computing services, cloud security and infrastructure on AWS and/or Azure

**Preferred Qualifications**

* Experience developing solutions on cloud services like SageMaker, EC2, S3, EMR, Redshift, IAM, etc.
* Experience developing and maintaining data warehouses in big data solutions
* Expertise in SQL and data analysis and strong hands-on expertise with at least one programming language: Python and/or Scala
* Strong knowledge in one or more of the following big data tools: Spark, Hive
* Strong expertise in ETL, reporting tools, data governance, data warehousing, and hands-on experience
* Up-to-date on industry trends within the analytics space from a data acquisition processing, engineering, and management perspective
* Strong people skills, specifically in collaboration and teamwork
* High level of curiosity, creativity, and problem-solving capabilities

**Apply Now**

* Participants who complete a short wellness assessment qualify for FREE coverage in our HIP PPO medical plan. Free coverage applies in the next calendar year.

**Learn more about our health and wellness benefits, which provide the security to help you and your family live full lives:** www.abbottbenefits.com


Follow your career aspirations to Abbott for diverse opportunities with a company that can help you build your future and live your best life. Abbott is an Equal Opportunity Employer, committed to employee diversity.


Connect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal.

  

The base pay for this position is $95,500.00 – $190,900.00. In specific locations, the pay range may vary from the range posted.","https://www.glassdoor.com/Overview/W-EI_IE12.htm","","","","","","https://media.glassdoor.com/sql/12/abbott-squareLogo-1657555841059.png","","",""
"1009474985527","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009474985527","","Senior Data Engineer","SS&C","San Francisco, CA","","2024-10-05","direct_data","yearly",186846.0,200000.0,"USD",False,"","","","organic","tratliff@sscinc.com","SS&C is a global provider of investment and financial services and software for the financial services and healthcare industries. Named to Fortune 1000 list as top U.S. company based on revenue, SS&C is headquartered in Windsor, Connecticut and has 20,000+ employees in over 90 offices in 35 countries. Some 18,000 financial services and healthcare organizations, from the world's largest institutions to local firms, manage and account for their investments using SS&C's products and services.
Job Description
Senior Data Engineer (San Francisco, CA; SS&C Technologies, Inc.): The Senior Data Engineer is based at SS&C’s office in San Francisco, California with a hybrid telecommuting benefit. The incumbent must reside within commuting distance from SS&C’s San Francisco office. The Senior Data Engineer is a member of a team responsible for creating a leading cloud platform with the latest big data, cloud native and machine learning technologies; building and implementing models in a production environment for a revenue-driving products; creating and maintaining overall optimal data pipeline architecture, assembling large, complex data sets that meet functional/non-functional business requirements; managing data migrations/conversions and troubleshooting data processing issues; creating the pipeline for optimal extraction, transformation, and loading (ETL) of data from a wide variety of data sources; building machine learning functions to help with data automation, data preparation; working closely with our analytics engineer and data warehouse engineers to build analytics tools and dashboards that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics; creating data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader; working with data and analytics experts to strive for greater functionality in our data system; and discovering more innovative machine learning solutions that can drive business values. Salary: $186,846 - $200,000 per year.
Minimum requirements: Master’s degree or equivalent in Computer Science, Information Systems, Information Technology Management, or related field.
Alternate Education and Experience: Bachelor’s degree or equivalent in Computer Science, Information Systems, Information Technology Management, or related field plus 5 years of experience in any occupation in which the required experience is gained.
Must have: Proven ability getting data through API with one of the following: Python, Node.js, Java, C#, Scala, etc. Proven ability with big data platform. Proficient coding skills and strong algorithm and data structure basis. Knowledge of at least one of the tools: Hadoop, Spark, Presto, Hive, or Airflow. Proven ability in transforming data, developing data structures, building a metadata store, setting up data pipelines or data workflows. Proven ability in software engineering best practices with git and version control systems. Solid communication skills in explaining complex data pipelines to both technical and non-technical audiences. Excellent writing and documenting skills.
Apply online at https://www.ssctech.com/about-us/careers or send resume to: Tiffany Ratliff, Talent Acquisition, SS&C Technologies, Inc., tratliff@sscinc.com. Ref: 00057576. An EOE.
#LI-DNI
#IND123
Unless explicitly requested or approached by SS&C Technologies, Inc. or any of its affiliated companies, the company will not accept unsolicited resumes from headhunters, recruitment agencies, or fee-based recruitment services. SS&C offers excellent benefits including health, dental, 401k plan, tuition and professional development reimbursement plan. SS&C Technologies is an Equal Employment Opportunity employer and does not discriminate against any applicant for employment or employee on the basis of race, color, religious creed, gender, age, marital status, sexual orientation, national origin, disability, veteran status or any other classification protected by applicable discrimination laws.
Salary is determined by various factors including, but not limited to, relevant work experience, job related knowledge, skills, abilities, business needs, and geographic regions.
California: Salary range for the position: 186,846.00 USD to 200,000.00 USD.","https://www.glassdoor.com/Overview/W-EI_IE6022.htm","","","","","","https://media.glassdoor.com/sql/6022/ss-and-c-squarelogo-1563463575606.png","","",""
"1009460212706","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009460212706","","Senior Data Engineer - Platform Engineering","Crunchyroll, LLC","San Francisco, CA","","2024-09-26","direct_data","yearly",185440.0,231800.0,"USD",False,"","","","organic","","**About Crunchyroll**
---------------------



WE HELP EVERYONE BELONG. IT'S OUR PURPOSE.



Founded by fans, Crunchyroll delivers the art and culture of anime to a passionate community. We super-serve over 100 million anime and manga fans across 200+ countries and territories, and help them connect with the stories and characters they crave. Whether that experience is online or in-person, streaming video, theatrical, games, merchandise, events and more, it's powered by the anime content we all love.



Join our team, and help us shape the future of anime!

### **Who We Are**



We're a cast of characters working to shine a spotlight on anime. Crunchyroll is an international business focused on creating both online and offline experiences for fans through content (licensed, co-produced, originals, distribution), merchandise, events, gaming, news, and more. Visit our About Us pages for more information about our collection of brands.


**About the Team**



The Data Services team is focused on building robust, scalable, and efficient data services, pipelines, lakes, tools, libraries, and software components that drive best practices and empower service teams to succeed. We design and implement data services, pipelines and data lakes for operational analysis, ensuring they are production-ready with automation and standardized access controls.



We lead and evangelize the principle of 100% automation. Additionally, we establish best practices, provide training, and document data architectures to ensure our systems are reliable, future-ready, and capable of continuous evolution and process improvement across the organization.


### **About The Role**



Crunchyroll is growing and changing, presenting unique challenges and opportunities to support millions of anime fans around the world. The Data Engineering team provides seamless help to our internal stakeholders, ensuring an exceptional experience for all Crunchyroll fans.



As a Senior Data Engineer, you will play a pivotal role in designing, implementing, and optimizing data services and pipelines, ensuring that our data services support the needs of the business. You will collaborate with cross-functional teams to enable operational data analysis, enhance eventing systems, and develop tools that empower our data and services teams. Your expertise will also be critical in driving 100% automation, best practices, creating scalable architectures, and optimizing our data environments.This role is eligible for fully remote and will report into our Director of Data Engineering - Platform Engineering.


### **About You**



* Bachelor's degree in Computer Science, Information Technology, or a related field.
* 8+ years of experience in data engineering, with a focus on building and optimizing data pipelines, data architecture, and eventing systems.
* Extensive experience with AWS cloud platform and their data-related services.
* Proficiency in automation frameworks (e.g., Terraform, Cloud Formation).
* Proficiency in data lake and pipeline tools and frameworks (e.g., Databricks, Apache Kafka/Kinesis, AWS Glue).
* Proficiency in one or more programming languages (e.g. Python, Java)
* Strong understanding of SQL (e.g. Redshift, Snowflake, RDS) and NoSQL databases (e.g., DynamoDB) and experience in enabling analytical queries on these platforms.
* Experience with search optimization, including schema design and query tuning.
* Experience in building CI/CD pipelines, testing frameworks (e.g. dbt), and best practices in data engineering.
* Strong problem-solving skills and a proactive approach to identifying and addressing issues.
* Ability to independently own and execute projects while effectively collaborating with the team to influence and shape the vision of the data engineering organization.
* Strong communication skills and the ability to mentor and guide junior engineers.
**Why you will love working at Crunchyroll**
--------------------------------------------



Not only will you get to work with fun, passionate and inspired colleagues, you will also...



* Receive a great compensation package including salary plus performance bonus earning potential, paid annually.
* Enjoy flexible PTO and time off policies allowing you to take the time you need to be your whole self.
* Appreciate the generous medical, dental, vision, STD, LTD, and life insurance options for you and your family.
* Take advantage of our health saving account HSA program plus health care and dependent care FSA programs.
* Love that we offer an employer match on our 401(k) plan.
* Receive employer paid commuter benefit (for eligible employees)
* Appreciate the generous support program for new parents
* Obtain pet insurance and some of our offices are pet friendly!
#LifeAtCrunchyroll #LI-Remote

### **About our Values**



We want to be everything for someone rather than something for everyone and we do this by living and modeling our values in all that we do. We value


* Courage. We believe that when we overcome fear, we enable our best selves.
* Curiosity. We are curious, which is the gateway to empathy, inclusion, and understanding.
* Service. We serve our community with humility, enabling joy and belonging for others.
* Kaizen. We have a growth mindset committed to constant forward progress.

### **Our commitment to diversity and inclusion**



Our mission of helping people belong reflects our commitment to diversity & inclusion. It's just the way we do business.



We are an equal opportunity employer and value diversity at Crunchyroll. Pursuant to applicable law, we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.



Crunchyroll, LLC is an independently operated joint venture between US-based Sony Pictures Entertainment, and Japan's Aniplex, a subsidiary of Sony Music Entertainment (Japan) Inc., both subsidiaries of Tokyo-based Sony Group Corporation.


*Questions about Crunchyroll's hiring process? Please check out our Hiring FAQs:* *https://help.crunchyroll.com/hc/en-us/articles/360040471712-Crunchyroll-Hiring-FAQs*



Please beware of recent scams to online job seekers. Those applying to our job openings will only be contacted directly from @crunchyroll.com email account.","https://www.glassdoor.com/Overview/W-EI_IE282440.htm","","","","","","https://media.glassdoor.com/sql/282440/crunchyroll-squareLogo-1721927757878.png","","",""
"1009454813054","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009454813054","","Staff Data Analyst","Aurora Innovation","San Francisco, CA","","2024-09-21","direct_data","yearly",135000.0,216000.0,"USD",False,"","","","organic","careersiteaccommodations@aurora.tech, careersiteaccommodations@aurora.tech","**Who We Are**



Aurora (Nasdaq: AUR) is delivering the benefits of self-driving technology safely, quickly, and broadly to make transportation safer, increasingly accessible, and more reliable and efficient than ever before. The Aurora Driver is a self-driving system designed to operate multiple vehicle types, from freight-hauling semi-trucks to ride-hailing passenger vehicles, and underpins Aurora Horizon and Aurora Connect, its driver-as-a-service products for trucking and ride-hailing. Aurora is working with industry leaders across the transportation ecosystem, including Toyota, FedEx, Volvo Trucks, PACCAR, Uber, Uber Freight, U.S. Xpress, Werner, Covenant, Schneider, and Ryder. For Aurora's latest news, visit aurora.tech and @aurora\\_inno on Twitter.


On the Aurora Data Science team, you will join a world-class group whose mission is generating insights and intelligence to improve the Aurora Driver and help accelerate our path towards safe and broad commercialization of Autonomous Vehicle technology. We are looking for an exceptional Data Analyst that can play a key role in accelerating the development of the Aurora Driver by contributing towards the automation, monitoring, and analysis of our development and operational processes. This is an opportunity to leverage vast amounts of data from both online (on-road) and offline (simulation) test modalities to help Aurora achieve its product and commercialization goals.



The ideal candidate will be someone who thrives working cross-functionally, getting things done, and has an ability to navigate complex and exciting projects with our partner Software, Hardware, and Operations teams. If your passions align with working on cutting edge Data Science projects to deliver impactful analysis, tools, and workflows that will transform the Transportation space, then joining Aurora Data Science is the perfect opportunity for you.


**In this role, you will**


* Work with our Engineering teams to inform the development of the Aurora Driver and streamline critical validation activities
* Partner closely with those stakeholders to design and implement metrics and dashboards to accelerate their development processes and help them measure, understand, and improve their performance
* Influence Aurora's tooling ecosystem to support data analytics work streams.
* Collaborate with a team of world-class Data Scientist and Analysts on Data Science & Analytics problems spanning multiple subsystems (eg. Motion Planning, Perception, Controls, etc.)
* Work closely with engineering leads to support their decisions with data-driven input
* Collaborate with our Data Science and Engineering communities to ensure the adoption of best practices and suggest improvements


**Required Qualifications**


* 6+ years of experience as a Data Analyst, Data Scientist, Data Engineer or similar technical role
* Experience technically leading and mentoring in the data and analytics space
* Experience taking Data Analytics projects end-to-end: synthesizing business needs, building required data pipelines, analyzing data, and clearly presenting insights.
* Expert knowledge and experience using relational databases (SQL, PostgreSQL, etc.) and familiarity with best practices for Data Engineering
* Advanced knowledge of data analytics infrastructure, including data transformation tools such as DBT and visualization frameworks and tools
* Competent in Python, able to write readable code that others can easily interpret
* Able to work effectively in a highly cross-functional, fast-moving and high-stakes environment.
* Proven ability to communicate technical, data-driven analysis to both technical and non-technical audiences across stakeholders, including translating and cascading Executive input into their work


**Desirable Qualifications**


* Advanced degree (MS or PhD) in Statistics, Computer Science, Operations Research, Economics, or a related quantitative field
* Experience using Amazon Web Services (AWS) tools
* Experience in the Autonomous Vehicle, Robotics, or Advanced Transportation spaces


The base salary range for this position is $135K - $216K per year. Aurora's pay ranges are determined by role, level, and location. Within the range, the successful candidate's starting base pay will be determined based on factors including job-related skills, experience, qualifications, relevant education or training, and market conditions. These ranges may be modified in the future. The successful candidate will also be eligible for an annual bonus, equity compensation, and benefits.



#LI-SP1



#Mid-Senior

**Working at Aurora**



At Aurora, we bring together extraordinarily talented and experienced people united by the strength of our values. We operate with integrity, set outrageous goals, and build a culture where we win together — all without any jerks.



We have offices in several locations across the United States, where we encourage team and cross-functional collaboration. Aurora offers competitive medical, dental, and vision benefits, and additional healthcare support including medical transportation reimbursement, fertility, adoption, and surrogacy benefits. We empower our employees and their families with options to further their unique physical, mental, and financial well-being.



Our Learning and Development offerings include Aurora Academy, where our people learn, develop, and practice the essential skills that drive Aurora's mission, continually up-leveling our team along the way. Our Careers page provides insight into career opportunities at Aurora, and you can find all the latest news on our Blog.



Safety is central to everything we do. Every employee at Aurora has a role in contributing to safety, every step of the way. We seek candidates who take active responsibility, can contribute to building an atmosphere of trust, and invest in the organization's long-term success by working safely — no matter what.



We believe that self-driving technology has broad benefits – including increased access to transportation. To realize those benefits, we need a workforce with diverse experiences, insights, and perspectives — a workforce that reflects the communities our technology will serve.



Aurora is committed to providing access to anyone who seeks information from our website. We invite anyone using assistive technologies, such as a screen reader or Braille reader, to email us at careersiteaccommodations@aurora.tech if they experience difficulty using our website. Please describe the accessibility problem and include a URL (if available).


*Aurora considers candidates without regard to their race, color, religion, national origin, age, sex, gender, gender identity, gender expression, sexual orientation, marital status, pregnancy status, parent or caregiver status, ancestry, political affiliation, veteran and/or military status, physical or mental disability, or any other status protected by federal or state law. Aurora considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at* *careersiteaccommodations@aurora.tech**.*


*For California applicants, information collected and processed as part of your application and any job applications you choose to submit is subject to**Aurora's California Employment Privacy Policy**.*


**Diversity, Equity and Inclusion**



At Aurora, every employee is empowered to take an active role in building an inclusive, collaborative, and unified culture that leverages our diverse strengths, perspectives, and backgrounds.



Transforming how the world moves people and goods involves seeking to understand backgrounds, insights, and lived experiences that differ from our own. One way we accomplish that is with our 15 employee-led Aurora Unified Groups, which support diverse voices and drive inclusive collaboration. We believe that teamwork, belonging, and trust motivate and support our employees to do their best work. As our team grows, we strive to attract and retain exceptional talent that adds new perspectives and experiences and continues to drive innovation. Learn more on our Culture Page.



We are committed to helping qualified military community members leverage their talents in service of our mission. To understand how your military experience aligns with career opportunities at Aurora, review your military job classification at MyNextMove.org and consider applying for open positions corresponding to your identified skills and experiences!","https://www.glassdoor.com/Overview/W-EI_IE1834014.htm","","","","","","https://media.glassdoor.com/sql/1834014/aurora-innovation-squareLogo-1625154850255.png","","",""
"1009453258998","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009453258998","","Data Engineer II, Amazon Health Science & Analytics","Amazon.com Services LLC","San Francisco, CA","","2024-09-20","direct_data","yearly",118900.0,205600.0,"USD",False,"","","","organic","","* 3+ years of data engineering experience
* Experience with data modeling, warehousing and building ETL pipelines
* - Knowledge of modern data warehouse (Snowflake, Big Query)
* - Proficiency in SQL
* - Ability to communicate technical concepts to diverse audiences


Want to channel the power of data to be a part of something big, having an impact our customers' and members' health and well being? Come join a dynamic, data-centric organization as we chart a course to greater self-service and empowerment of business, clinical, and technology leaders at One Medical!
  
  

You will be responsible for designing and building reliable & performant data
  
models and pipelines to provide actionable insights and accommodate needs from our
  
cross-functional partners and distributed analysts across the organization.
  
  

You are someone that enjoys exploring data to identify large areas of opportunity to drive
  
business impact, are able to ask the right questions to accurately analyze situations and can
  
acquire data from multiple and diverse sources when solving problems. Not only that, you are
  
also able to make sense of complex, high-quantity, and sometimes contradictory information to
  
solve these problems through structured thinking and have shown the ability to drive results in
  
accomplishing objectives despite obstacles and setbacks. You thrive at effective communication
  
in a variety of settings, whether it’s one-on-one, small and large groups, or among diverse styles
  
and position levels.
  
  

#everydaybetter
  
  

Key job responsibilities
  
* Partner with folks across the company on developing flexible and scalable analytics to


drive insights and decision making by internal customers
  
* Design and build reliable, performant and high quality data models and pipelines to


provide actionable insights and accommodate needs for our cross-functional teams
  
* Build out suites of standard KPIs/metrics
* Work with the team to define how we model and warehouse data that is accessed by


most teams and analysts across the company
  
* Engage in code reviews to ensure code committed is collectively maintainable by the


team
  
* Build proper data quality detection tools to identify data issues in the data transformation


stages and fix the problems to meet pipelines / table health SLAs
  
* Ensure all critical systems within team’s domain have appropriate and up to date


documentation
  
* Participate in our scheduled support rotation, where you’ll be responsible for maintaining


and troubleshooting pipelines and providing assistance to data analysts
  
* Champion the practice of making data-informed decisions by ensuring internal


stakeholders such as the product management, operations, marketing, clinical
  
effectiveness, finance and executive teams are making data driven decisions quickly and
  
with confidence.
  
* Build and improve data tooling in partnership with data engineering and platform teams
* Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
* Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
* - Healthcare industry experience
* - Knowledge of Apache Airflow
* - Proficiency in Python


Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.
  
  

**Los Angeles County applicants:** Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
  
  

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
  
  

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.","https://www.glassdoor.com/Overview/W-EI_IE6036.htm","","","","","","https://media.glassdoor.com/sql/6036/amazon-squarelogo-1552847650117.png","","",""
"1009453258836","glassdoor","https://www.glassdoor.com/job-listing/j?jl=1009453258836","","Senior Data Engineer, Amazon Health Science & Analytics","Amazon.com Services LLC","San Francisco, CA","","2024-09-20","direct_data","yearly",139100.0,240500.0,"USD",False,"","","","organic","","* 5+ years of data engineering experience
* Experience with data modeling, warehousing and building ETL pipelines
* Experience with SQL
* Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS
* Experience mentoring team members on best practices
* Experience working with DBT.
* Experience in dimensional data modelling and schema design.


Want to channel the power of data to be a part of something big, having an impact our customers' and members' health and well being? Come join a dynamic, data-centric organization as we chart a course to greater self-service and empowerment of business, clinical, and technology leaders at One Medical!
  
  

Key job responsibilities
  
* Partner with folks across the company on developing flexible and scalable analytics to drive insights and decision making by internal customers
* Design and build reliable, performant and high quality scalable data architecture, data models, and pipelines to provide actionable insights and accommodate needs for our cross-functional teams
* You will have the opportunity to design the most critical business level aggregated tables at One Medical
* Build out suites of standard KPIs and metrics
* Define the strategy for how we model and warehouse data that is accessed by most teams and analysts across the company
* Build proper data quality detection to identify data issues in the data transformation stages and fix the problems to meet pipelines / table health SLAs
* Champion the practice of making data-informed decisions by ensuring internal stakeholders such as product management, operations, marketing, clinical effectiveness, finance and the executive team are making data driven decisions quickly and with confidence.
* Build and improve data tooling in partnership with data engineering and platform teams
* Mentor junior team members and team members throughout the broader Amazon Health Services organization


#everydaybetter
  
  

* Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
* Experience operating large data warehouses


Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.
  
  

**Los Angeles County applicants:** Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
  
  

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
  
  

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $139,100/year in our lowest geographic market up to $240,500/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.","https://www.glassdoor.com/Overview/W-EI_IE6036.htm","","","","","","https://media.glassdoor.com/sql/6036/amazon-squarelogo-1552847650117.png","","",""
"b4e4dedda049b742","indeed","https://www.indeed.com/viewjob?jk=b4e4dedda049b742","https://www.tesla.com/careers/search/job/internship-data-engineer-cell-manufacturing-software-winter-spring-2025-229209","Internship, Data Engineer, Cell Manufacturing Software (Winter/Spring 2025)","Tesla","Fremont, CA, US","internship","2024-10-09","direct_data","hourly",36.0,50.0,"USD",False,"","","Industrial Manufacturing","","","**Job Category** Engineering & Information Technology  

**Location** Fremont, California  

**Req. ID** 229209  

**Job Type** Intern/Apprentice  




Tesla participates in the E-Verify Program
What to Expect
Tesla is re-thinking how batteries are made from the ground up. We’re designing new factories, new equipment, new processes, and new software to rapidly scale battery manufacturing, globally. The primary bottleneck to Tesla’s future expansion (and the transition to sustainable transport and energy storage) is our ability to produce and procure batteries – that’s why we’re innovating in-house, with our collection of world-class engineers, to redefine the industry. Software, data, and automation all play a huge part in this strategy.  

We’ve built software from scratch to meet the specific needs of Tesla’s rapid battery manufacturing scale up. This software tracks every component of the cell manufacturing process and acts as the brain of the entire cell factory. It’s key to ensuring batteries are made safely end-to-end and for understanding how to improve processes.
We’re looking for a data engineering intern that will help us tackle specific projects within Cell Manufacturing. These projects will involve advanced data analysis, building of detailed reports and working through some of the biggest production, quality, and cost bottlenecks in our Cell Factories. During this internship you will be working alongside world-class software and data engineers, and you’ll be working directly with engineers across multiple disciplines in cell manufacturing.
What You’ll Do* Perform detailed analysis against large data sets of manufacturing data (some data that is streamed at 1000 HZ)
* Root cause issues in cell manufacturing with your understanding of our data set, partnering with engineers from process, quality and controls to execute on their requests
* Build web-based frontend tools and visualizations which show critical factory data to manufacturing engineers
* Support data scientists and software engineers in using a centralized data platform to build interactive visualizations, generate reports, and conduct statistical analyses
* Work closely with manufacturing engineers to integrate new datasets into the data platform and ensure all data reporting needs can be met
  


What You’ll Bring* Currently pursuing a degree in Computer Science or a related field of study with a graduation date between 2025-2026
* Ability to relocate and work on site in Fremont, CA
* Strong programming experience with at least one of Python, Go, Java, or Scala.
* Experience working with databases, data warehouses, or distributed data systems
* Experience with Git or other source control software
* Experience with Kafka, ClickHouse, or Spark is a nice-to-have
* Experience with frontend development using Javascript, Typescript, or React is a nice-to-have
* Strong verbal and written communication skills to quickly translate needs into data analysis problems and effectively communicate learnings
  

Compensation and Benefits
Benefits  

As a full-time Tesla Intern, you will be eligible for:
* Aetna PPO and HSA plans > 2 medical plan options with $0 payroll deduction
* Family-building, fertility, adoption and surrogacy benefits
* Dental (including orthodontic coverage) and vision plans. Both have an option with a $0 payroll contribution
* Company Paid (Health Savings Account) HSA Contribution when enrolled in the High Deductible Medical Plan with HSA
* Healthcare and Dependent Care Flexible Spending Accounts (FSA)
* LGBTQ+ care concierge services
* 401(k), Employee Stock Purchase Plans, and other financial benefits
* Company Paid Basic Life, AD&D, and short-term disability insurance
* Employee Assistance Program
* Sick time after 90 days of employment and Paid Holidays
* Back-up childcare and parenting support resources
* Voluntary benefits to include: critical illness, hospital indemnity, accident insurance, theft & legal services, and pet insurance
* Commuter benefits
* Employee discounts and perks program
  
  

Expected Compensation  

$36.00 - $50.00 + benefits  

  

Pay offered may vary depending on multiple individualized factors, including market location, job-related knowledge, skills, and experience. The total compensation package for this position may also include other elements dependent on the position offered. Details of participation in these benefit plans will be provided if an employee receives an offer of employment.  

Tesla is an Equal Opportunity / Affirmative Action employer committed to diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, age, national origin, disability, protected veteran status, gender identity or any other factor protected by applicable federal, state or local laws.
Tesla is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.","https://www.indeed.com/cmp/Tesla","https://www.tesla.com","1 Tesla Road Austin, TX 78725","10,000+","$5B to $10B (USD)","Tesla is accelerating the world’s transition to sustainable energy.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/5e42be6c7dd264b60310b59afb8a3c48","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/0dd52e4838b7fbaad47cb480680a00d3","Elon Musk","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/0fc450600a0b471e811e0d08de5cbe98"
"ae8c202069c5ac7f","indeed","https://www.indeed.com/viewjob?jk=ae8c202069c5ac7f","https://grnh.se/61405e2f1us","Lead Data Engineer","Nuna","San Francisco Bay Area, CA, US","","2024-10-09","direct_data","yearly",188000.0,273500.0,"USD",False,"","","","","","*At Nuna, our mission is to make high-quality healthcare affordable and accessible for everyone. We are dedicated to tackling one of our nation's biggest problems with ingenuity, creativity, and a keen moral compass.*  

  

*Nuna is committed to simple principles: a rigorous understanding of data, modern technology, and most importantly, compassion and care for our fellow human. We want to know what really works, what doesn't—and why.*

**YOUR TEAM**
-------------



You will join an interdisciplinary group spanning data science, machine learning, data analytics, actuarial science, and data engineering. You will be part of the larger team building Nuna's Patient and Provider products, which reward patients for healthy behaviors as they manage chronic disease.



The team is responsible for evaluating impact and developing critical algorithmic and quantitative features across these products. This involves bringing analytical rigor to product definition, monitoring, and evaluation; design, development, and evaluation of predictive algorithms; and the maintenance and expansion of a flexible Data Platform. The team takes an ownership attitude and has a strong culture of internal review and collaboration. We work closely with engineering, product, design, and account management teams.


**YOUR OPPORTUNITIES**
----------------------



We are looking for someone who is excited to use their expertise in building scalable data engineering solutions to make a difference in healthcare. You will have the opportunity to play a foundational role in the success of a burgeoning product at Nuna and the ability to shape the data engineering function. The Data Platform supports multiple data products across analytics, experimentation, model serving, and more.


* Contribute to and expand upon the architecture of a growing Data Platform
* Establish data engineering and software best practices in the team
* Hands-on development of Data Platform capabilities - e.g. write code to ingest and transform complex data sources, maintain deployment process, etc.
* Articulate pros and cons of competing tools to inform choices and build vs buy decisions
* Serve as a mentor for team members in code quality and review
* Work closely with data scientists, analysts, and actuaries to identify opportunities to improve workflows and increase overall efficiency

**QUALIFICATIONS**
------------------


#### **Required Qualifications**


* BS/MS in a quantitative field (e.g. Computer Science, Engineering) + 10 years of engineering/equivalent experience
* 7+ years of experience building systems that manage the ingest, transformation, and management of multimodal data types
* Deep knowledge of modern data infrastructure best practices
* Proficiency with tools spanning the range of the following: AWS S3, Terraform, Airflow, Glue / Unity catalog, pytest, spark/pyspark, python, SQL (or analogous)
* Experience with data governance, traceability, etc.
* Proficiency with cloud platforms (AWS preferred)
* Experience in a zero-to-one setting
* Interest in improving healthcare and working with interdisciplinary project teams
* Clear communication and presentation skills

#### **Preferred Qualifications**


* Experience with Databricks product suite, especially Unity catalog
* Experience in a HIPAA-compliant environment
* MLOps experience


We take into account an individual's qualifications, skillset, and experience in determining final salary. This role is eligible for health insurance, life insurance, retirement benefits, participation in the company's equity program, paid time off, including vacation and sick leave. The expected salary range for this position is $188,000 to $273,500. The actual offer will be at the company's sole discretion and determined by relevant business considerations, including the final candidate's qualifications, years of experience, and skillset.

*Nuna is an Equal Employment Opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, disability, genetics and/or veteran status.*","https://www.indeed.com/cmp/Nuna-3","http://www.nuna.com","San Francisco, CA","51 to 200","","","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/d3f7ddd30e2068d842c336aa6ce9c75f","","",""
"5730c9f7bbab0b75","indeed","https://www.indeed.com/viewjob?jk=5730c9f7bbab0b75","https://analogdevices.wd1.myworkdayjobs.com/en-US/External/job/US-CA-San-Jose-Rio-Robles/Associate-Data-Engineer_R243721-1","Associate Data Engineer","Analog Devices","San Jose, CA, US","","2024-10-09","direct_data","yearly",78200.0,107525.0,"USD",True,"","","","","","Come join Analog Devices (ADI) – a place where Innovation meets Impact. For more than 55 years, Analog Devices has been inventing new breakthrough technologies that transform lives. At ADI you will work alongside the brightest minds to collaborate on solving complex problems that matter from autonomous vehicles, drones and factories to augmented reality and remote healthcare.
ADI fosters a culture that focuses on employees through beneficial programs, aligned goals, continuous learning opportunities, and practices that create a more sustainable future.
ADI At A Glance
Analog Devices, Inc. (NASDAQ: ADI) is a global semiconductor leader that bridges the physical and digital worlds to enable breakthroughs at the Intelligent Edge. ADI combines analog, digital, and software technologies into solutions that help drive advancements in digitized factories, mobility, and digital healthcare, combat climate change, and reliably connect humans and the world. With revenue of more than $12 billion in FY23 and approximately 26,000 people globally working alongside 125,000 global customers, ADI ensures today’s innovators stay Ahead of What’s Possible. Learn more at www.analog.com and on LinkedIn and Twitter (X)  

Job Description:  

As an Associate Data Engineer, you will play a crucial role in designing, building, and maintaining data pipelines and databases. You will collaborate with data scientists, analysts, and other stakeholders to ensure that data infrastructure is reliable, scalable, and optimized for performance. This position will allow you to gain experience in managing data extraction, transformation, and loading (ETL) processes while ensuring data integrity across the organization.
Key Responsibilities:* Design and implement data pipelines for the efficient extraction, transformation, and loading (ETL) of data.
* Support the development and maintenance of relational and non-relational databases, ensuring data accessibility and performance.
* Work with data warehousing solutions such as Redshift or Snowflake to support large-scale data storage.
* Write and maintain scripts in Python or R for data manipulation and processing.
* Ensure the accuracy, consistency, and integrity of data across its lifecycle.
* Collaborate with cross-functional teams to understand and meet data infrastructure needs.

Skills You Will Need to Be Successful:* Proficiency in SQL and knowledge of relational and non-relational databases.
* Understanding of ETL processes and experience in designing scalable data pipelines.
* Familiarity with data warehousing solutions like Redshift or Snowflake.
* Experience with scripting languages such as Python or R for data manipulation.
* Strong attention to detail with a focus on maintaining data accuracy and integrity.

Minimum Qualifications:* Bachelor’s Degree in Computer Science, Data Engineering, or a related field.
* 0-2 years of experience in data engineering, database management, or similar roles.
* Understanding of basic data engineering concepts and tools.
*For positions requiring access to technical data, Analog Devices, Inc. may have to obtain export licensing approval from the U.S. Department of Commerce - Bureau of Industry and Security and/or the U.S. Department of State - Directorate of Defense Trade Controls. As such, applicants for this position – except US Citizens, US Permanent Residents, and protected individuals as defined by 8 U.S.C. 1324b(a)(3) – may have to go through an export licensing review process.**Analog Devices is an equal opportunity employer. We foster a culture where everyone has an opportunity to succeed regardless of their race, color, religion, age, ancestry, national origin, social or ethnic origin, sex, sexual orientation, gender, gender identity, gender expression, marital status, pregnancy, parental status, disability, medical condition, genetic information, military or veteran status, union membership, and political affiliation, or any other legally protected group.**EEO is the Law:* *Notice of Applicant Rights Under the Law**.*
Job Req Type: Graduate Job  


Required Travel: Yes, 10% of the time  


The wage range for a new hire into this position is $78,200 to $107,525.* Actual wage offered may vary depending on geography, experience, education, training, external market data, internal equity, or other bona fide factors.
* This position qualifies for a discretionary performance-based bonus which is based on personal and company factors.
* This position includes medical, vision and dental coverage, 401k, paid vacation, holidays, and sick time, and other benefits.","https://www.indeed.com/cmp/Analog-Devices","http://www.analog.com","Wilmington, MA","10,000+","more than $10B (USD)","For decades, Analog Devices has built bridges between the physical and the digital.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/3b3603ff1ad22757aaea406c001a6798","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/29fa89f99daab6879db5358af5a805e9","Vincent T. Roche","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/66430a936984841efe1ff7ad3dd6f291"
"91f171f8260d5452","indeed","https://www.indeed.com/viewjob?jk=91f171f8260d5452","https://analogdevices.wd1.myworkdayjobs.com/en-US/External/job/US-CA-San-Jose-Rio-Robles/Data-Engineer_R243722","Data Engineer","Analog Devices","San Jose, CA, US","","2024-10-09","direct_data","yearly",97060.0,133458.0,"USD",True,"","","","","","Come join Analog Devices (ADI) – a place where Innovation meets Impact. For more than 55 years, Analog Devices has been inventing new breakthrough technologies that transform lives. At ADI you will work alongside the brightest minds to collaborate on solving complex problems that matter from autonomous vehicles, drones and factories to augmented reality and remote healthcare.
ADI fosters a culture that focuses on employees through beneficial programs, aligned goals, continuous learning opportunities, and practices that create a more sustainable future.
ADI At A Glance
Analog Devices, Inc. (NASDAQ: ADI) is a global semiconductor leader that bridges the physical and digital worlds to enable breakthroughs at the Intelligent Edge. ADI combines analog, digital, and software technologies into solutions that help drive advancements in digitized factories, mobility, and digital healthcare, combat climate change, and reliably connect humans and the world. With revenue of more than $12 billion in FY23 and approximately 26,000 people globally working alongside 125,000 global customers, ADI ensures today’s innovators stay Ahead of What’s Possible. Learn more at www.analog.com and on LinkedIn and Twitter (X)  

Job Description:  

As a Data Engineer, you will be responsible for designing, building, and optimizing the organization’s data architecture. This role involves developing scalable data pipelines, managing large-scale databases, and ensuring efficient data processing. You will collaborate with stakeholders to understand data requirements and ensure that data infrastructure supports the organization's needs while maintaining the integrity and quality of data throughout its lifecycle.
Key Responsibilities:* Design, build, and maintain scalable data pipelines for extracting, transforming, and loading (ETL) data.
* Develop and optimize relational and non-relational databases to ensure efficient data storage and retrieval.
* Implement data warehousing solutions like Redshift or Snowflake to support large-scale data management.
* Utilize scripting languages such as Python or R for data manipulation, automation, and analysis.
* Ensure data integrity, accuracy, and consistency across all processes and systems.
* Collaborate with cross-functional teams, including data scientists and analysts, to support their data needs and projects.

Skills You Will Need to Be Successful:* Strong expertise in SQL and relational/non-relational database management.
* Advanced knowledge of ETL processes and data pipeline design.
* Proficiency in data warehousing solutions (e.g., Redshift, Snowflake) for large-scale data storage.
* Experience with scripting languages such as Python or R for data manipulation and automation.
* Strong problem-solving skills with a focus on data accuracy and system optimization.

Minimum Qualifications:* Master’s Degree in Computer Science, Data Engineering, or a related field preferred
* 2+ years of experience in data engineering, database management, or similar roles.
* Proven experience with building and maintaining scalable data architectures.
*For positions requiring access to technical data, Analog Devices, Inc. may have to obtain export licensing approval from the U.S. Department of Commerce - Bureau of Industry and Security and/or the U.S. Department of State - Directorate of Defense Trade Controls. As such, applicants for this position – except US Citizens, US Permanent Residents, and protected individuals as defined by 8 U.S.C. 1324b(a)(3) – may have to go through an export licensing review process.**Analog Devices is an equal opportunity employer. We foster a culture where everyone has an opportunity to succeed regardless of their race, color, religion, age, ancestry, national origin, social or ethnic origin, sex, sexual orientation, gender, gender identity, gender expression, marital status, pregnancy, parental status, disability, medical condition, genetic information, military or veteran status, union membership, and political affiliation, or any other legally protected group.**EEO is the Law:* *Notice of Applicant Rights Under the Law**.*
Job Req Type: Graduate Job  


Required Travel: Yes, 10% of the time  


The wage range for a new hire into this position is $97,060 to $133,458.* Actual wage offered may vary depending on geography, experience, education, training, external market data, internal equity, or other bona fide factors.
* This position qualifies for a discretionary performance-based bonus which is based on personal and company factors.
* This position includes medical, vision and dental coverage, 401k, paid vacation, holidays, and sick time, and other benefits.","https://www.indeed.com/cmp/Analog-Devices","http://www.analog.com","Wilmington, MA","10,000+","more than $10B (USD)","For decades, Analog Devices has built bridges between the physical and the digital.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/3b3603ff1ad22757aaea406c001a6798","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/29fa89f99daab6879db5358af5a805e9","Vincent T. Roche","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/66430a936984841efe1ff7ad3dd6f291"
"f77f92515ed759a1","indeed","https://www.indeed.com/viewjob?jk=f77f92515ed759a1","https://careers.google.com/jobs/results/139454772787716806-partner-data-engineer/","Partner Data Engineer, YouTube Measurement Infrastructure","Google","San Bruno, CA, US","fulltime","2024-10-09","description","yearly",118000.0,174000.0,"USD",False,"","","","","","**Note:** By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; New York, NY, USA; San Bruno, CA, USA.
  
  

**Minimum qualifications:**  

* Bachelor's degree or equivalent practical experience.
* 3 years of experience working with data infrastructure and data models by performing exploratory queries and scripts.
* 3 years of experience with ETL and SQL.
* 3 years of experience working with Python and coding in one or more programming languages: C/C++, Java, Go, Unix/Linux systems.
* 2 years of experience in a client-facing role.


**Preferred qualifications:**  

* 2 years of experience in data visualization.
* Experience working with Google’s data processing stack (e.g., PLX, SQL Pipelines, GoogleSQL).
* Experience working with Google’s technical infrastructure (e.g., Borg, Rapid, Boq).
* Advanced root cause analysis, statistical, time-series and predictive modeling skills.


About the job
  
  

The YouTube Infrastructure Measurement Partner Engineering is responsible for developing and managing production-grade infrastructure to ensure that YouTube is represented fairly in third-party reporting tools, the internal data feeding those tools is accurate and consistent, and supporting data needs for various verticals such as YouTube Shopping, YouTube TV, to Integrated Billing. We provide infrastructure support, data mining, and thought leadership to several initiatives shaping the long-term direction of YouTube.
  
As a Partner Data Engineer on the YouTube Measurement Infrastructure Partner Engineering team, you will be responsible for managing infrastructure solutions that will power YouTube's various strategic initiatives such as public claims and Ads partner integrations.
  
In this role, you will have the opportunity to design and implement large-scale data pipeline solutions combining data from multiple internal and external data sources. This data will serve as the foundation for various analytical and data science initiatives, providing our cross-functional stakeholders with unique insights and values not found elsewhere.
  
At YouTube, we believe that everyone deserves to have a voice, and that the world is a better place when we listen, share, and build community through our stories. We work together to give everyone the power to share their story, explore what they love, and connect with one another in the process. Working at the intersection of cutting-edge technology and boundless creativity, we move at the speed of culture with a shared goal to show people the world. We explore new ideas, solve real problems, and have fun — and we do it all together.
  
The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more aboutbenefits at Google.
  
  

Responsibilities
  
  

* Manage YouTube data feeds and provide ongoing technical support to internal partners for a wide range of YouTube’s viewership metrics initiatives.
* Provide infrastructure solutions for external audience measurement partner integrations.
* Guarantee the technical aspects of YouTube viewership data integrations (both new and ongoing) by providing technical guidance and documentation.
* Identify, drive, and optimize new third-party reporting opportunities by leveraging YouTube technologies.
* Write and maintain lines of code (Python, C++, etc.) to support your own medium to large-scale Extract, Transform, Load (ETL) pipelines.


Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See alsoGoogle's EEO Policy andEEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing ourAccommodations for Applicants form.","https://www.indeed.com/cmp/Google","http://goo.gle/3ygdkgv","Mountain View, CA","10,000+","more than $10B (USD)","Our mission is to organize the world’s information and make it universally accessible and useful. ","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/fff4be3829cee39e477a518f55475f44","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/56b1f27b69e0e2c02b8e9ad6e5fce05f","Sundar Pichai","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/417a5815642490eb9a47ed7970a26c97"
"7e4d5e47448877f2","indeed","https://www.indeed.com/viewjob?jk=7e4d5e47448877f2","https://careers.google.com/jobs/results/78534069649842886-data-engineer/","Data Engineer, Global Sales Activation, Go-To-Market","Google","Mountain View, CA, US","fulltime","2024-10-09","description","yearly",118000.0,174000.0,"USD",False,"","","","","","This role may also be located in our Playa Vista, CA campus.
  
**Note:** By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; Atlanta, GA, USA; Chicago, IL, USA; New York, NY, USA; Los Angeles, CA, USA; San Francisco, CA, USA; Washington D.C., DC, USA.
  
  

**Minimum qualifications:**  

* Bachelor’s degree in Engineering, Computer Science, a related field, or equivalent practical experience.
* 3 years of experience coding with one or more programming languages (e.g., Python, Java, C/C++).
* 3 years of experience designing and building data pipelines (ETL) and model data, for synch and asynch system integration and implementation.
* 3 years of experience analyzing data, database query (e.g. SQL), and creating dashboards/reports.


**Preferred qualifications:**  

* Master's degree in Engineering, Computer Science, or a related field.
* 3 years of experience partnering with stakeholders (e.g., users, partners, customers).
* 3 years of experience developing project plans and delivering projects on time within budget and scope.
* 3 years of experience designing data models and data warehouses, including data processing automation, data quality, data governance, business intelligence, and data privacy.
* Experience writing and maintaining ETLs which operate on a variety of structured and unstructured sources.
* Structured thinking with the ability to break down complex, ambiguous problems and propose solutions through impactful data modeling designs.


About the job
  
  

The Governance, Infrastructure, and Operations (GIO) team sits within Product Operations in the Global Sales Activation (GSA) organization, and is responsible for leading sales workflow activation strategy across business operations, governance, legal compliance, sales enablement, and measurement and analytics. GSA resides within the Go-To-Market Operations (GTM) team and enables Google’s Business Organization (GBO) to drive customer success. Experts in driving process improvements and consistency, team members are analytical and strategic with a pragmatic sense of getting things done.
  
Data is the fundamental building block for every tool and every insight. We build the data sets that help run the business, piping the relevant data into and out of our tools, and making it useful for analysts across the organization to drive reporting and insights. We are responsible for democratizing GBO and Ads data, helping business leaders make sense of business operations through timely, accurate, and robust business intelligence. We use SQL and ETL systems to produce useful datasets, establish best practices for data sets and reporting, and develop a breadth of expertise in various data domains. Ultimately, Data Engineers scale centralized reporting and automate data processes to ensure the business is operating more effectively and efficiently.
  
The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more aboutbenefits at Google.
  
Responsibilities
  
  

* Centralize ads and customer data to enable discovery and analysis for users.
* Recommend and adopt best practices in developing and modifying existing data models and ETL pipelines. Be responsible for data governance, data integrity, test design, validation.
* Create Extract, Transform, and Load (ETLs) and reporting systems for new data using a variety of traditional as well as large-scale distributed data systems.
* Work closely with analysts to productionize various statistical and machine learning models using data processing pipelines.
* Write and review technical documents including design, development, and revision documents.


Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See alsoGoogle's EEO Policy andEEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing ourAccommodations for Applicants form.","https://www.indeed.com/cmp/Google","http://goo.gle/3ygdkgv","Mountain View, CA","10,000+","more than $10B (USD)","Our mission is to organize the world’s information and make it universally accessible and useful. ","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/fff4be3829cee39e477a518f55475f44","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/56b1f27b69e0e2c02b8e9ad6e5fce05f","Sundar Pichai","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/417a5815642490eb9a47ed7970a26c97"
"75dbf6bb245b4109","indeed","https://www.indeed.com/viewjob?jk=75dbf6bb245b4109","https://careers.docusign.com/jobs/25564?lang=en-us","Senior Data Engineer","DocuSign","San Francisco, CA, US","","2024-10-08","direct_data","yearly",134900.0,216975.0,"USD",True,"","","","","accommodations@docusign.com, taops@docusign.com","**Company Overview**
--------------------

  

Docusign brings agreements to life. Over 1.5 million customers and more than a billion people in over 180 countries use Docusign solutions to accelerate the process of doing business and simplify people’s lives. With intelligent agreement management, Docusign unleashes business-critical data that is trapped inside of documents. Until now, these were disconnected from business systems of record, costing businesses time, money, and opportunity. Using Docusign’s Intelligent Agreement Management platform, companies can create, commit, and manage agreements with solutions created by the #1 company in e-signature and contract lifecycle management (CLM).  

  

**What You'll Do**
------------------

  

Docusign is seeking a talented and results oriented Data Engineer to focus on delivering trusted data to the business. As a member of the Global Data Analytics (GDA) Team, the Data Engineer leverages a variety of technologies to design, develop and deliver new features in addition to loading, transforming and preparing data sets of all shapes and sizes for teams around the world. During a typical day, the Engineer will spend time developing new features to analyze data, develop solutions and load tested data sets into the Snowflake Enterprise Data Warehouse. The ideal candidate will demonstrate a positive “can do” attitude, a passion for learning and growing, and the drive to work hard and get the job done in a timely fashion. This individual contributor position provides plenty of room to grow - a mix of challenging assignments, a chance to work with a world-class team, and the opportunity to use innovative technologies such as AWS, Snowflake, dbt, Airflow and Matillion.  

This position is an individual contributor role reporting to the Manager, Data & Analytics. **Responsibility**

* Design, develop and maintain scalable and efficient data pipelines
* Analyze and develop data quality and validation procedures
* Work with stakeholders to understand the data requirements and provide solutions
* Troubleshoot and resolve data issues in a timely manner
* Collaborate with cross-functional teams to ingest data from various sources
* Evaluate and improve data architecture and processes continuously
* Own, monitor, and improve solutions to ensure SLAs are met
* Develop and maintain documentation for Data infrastructure and processes
* Execute projects using Agile Scrum methodologies

  

  

**Job Designation**
-------------------

 **Hybrid:**


Employee divides their time between in-office and remote work. Access to an office location is required. (Frequency: Minimum 2 days per week; may vary by team but will be weekly in-office expectation)

  

Positions at Docusign are assigned a job designation of either In Office, Hybrid or Remote and are specific to the role/job. Preferred job designations are not guaranteed when changing positions within Docusign. Docusign reserves the right to change a position's job designation depending on business needs and as permitted by local law.

  

  

**What You Bring**
------------------

 **Basic**

* Bachelor’s Degree in Computer Science, Data Analytics, Information Systems, etc.
* Experience developing data pipelines in one of the following languages: Python or Java
* 8+ years dimensional and relational data modeling experience
* Experience with SQL and database management

**Preferred**

* 8+ years in data warehouse engineering (OLAP) Snowflake, BigQuery, Teradata, Redshift
* 8+ years with transactional databases (OLTP) Oracle, SQL Server, MySQL
* 8+ years with big data, Hadoop, Data Lake, Spark in a cloud environment(AWS)
* 8+ years with commercial ETL tools – dbt, Matillion, and SSIS/ADF
* 8+ years delivering ETL solutions from source systems, databases, APIs, flat-files, JSON
* Experience developing Entity Relationship Diagrams with Erwin, SQLDBM, or equivalent
* Experience working with job scheduling and monitoring systems (Airflow, Datadog, AWS SNS)
* Experience building BI Dashboards with tools like Tableau
* Experience in any of the financial, Marketing, Sales, accounts payable, accounts receivable, invoicing etc domains
* Experience managing work assignments using tools like Jira and Confluence
* Experience with Scrum/Agile methodologies is a plus.
* Ability to work independently and as part of a team
* Excellent analytical and problem solving skills

  

  

**Wage Transparency**
---------------------

  

Pay for this position is based on a number of factors including geographic location and may vary depending on job-related knowledge, skills, and experience.  

Based on applicable legislation, the below details pay ranges in the following locations:  

California: $134,900.00 - $216,975.00 base salary  

This role is also eligible for bonus, equity and
benefits.

  

Global benefits provide options for the following:  

* Paid Time Off: earned time off, as well as paid company holidays based on region
* Paid Parental Leave: take up to six months off with your child after birth, adoption or foster care placement
* Full Health Benefits Plans: options for 100% employer paid and minimum employee contribution health plans from day one of employment
* Retirement Plans: select retirement and pension programs with potential for employer contributions
* Learning and Development: options for coaching, online courses and education reimbursements
* Compassionate Care Leave: paid time off following the loss of a loved one and other life-changing events

  

  

**Life At Docusign**
--------------------

 **Working here**


Docusign is committed to building trust and making the world more agreeable for our employees, customers and the communities in which we live and work. You can count on us to listen, be honest, and try our best to do what’s right, every day. At Docusign, everything is equal.  

We each have a responsibility to ensure every team member has an equal opportunity to succeed, to be heard, to exchange ideas openly, to build lasting relationships, and to do the work of their life. Best of all, you will be able to feel deep pride in the work you do, because your contribution helps us make the world better than we found it. And for that, you’ll be loved by us, our customers, and the world in which we live. **Accommodation**


Docusign is committed to providing reasonable accommodations for qualified individuals with disabilities in our job application procedures. If you need such an accommodation, or a religious accommodation, during the application process, please contact us at accommodations@docusign.com.  

If you experience any issues, concerns, or technical difficulties during the application process please get in touch with our Talent organization at taops@docusign.com for assistance.
  
### **Our global benefits**


#### **Paid time off**


Take time to unwind with earned days off, plus paid company holidays based on your region.
#### **Paid parental leave**


Take up to six months off with your child after birth, adoption or foster care placement.
#### **Full health benefits**


Options for 100% employer-paid health plans from day one of employment.
#### **Retirement plans**


Select retirement and pension programs with potential for employer contributions.
#### **Learning & development**


Grow your career with coaching, online courses and education reimbursements.
#### **Compassionate care leave**


Paid time off following the loss of a loved one and other life-changing events.","https://www.indeed.com/cmp/Docusign","http://www.docusign.com","San Francisco, CA","5,001 to 10,000","$1B to $5B (USD)","Bringing agreements to life.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/912d0311d0fb686951f819bd9ac676a9","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/d09974d32ff1a5a0e7de071499cff969","Allan Thygesen","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/7c814b7d6517392345099b4b03ee9cd7"
"5f83e9212c859a82","indeed","https://www.indeed.com/viewjob?jk=5f83e9212c859a82","https://jobs.lever.co/cellares/d4bc82a2-dffa-4e4a-b25a-1c1237534188","Senior Data Engineer (I,II,III)","Cellares","South San Francisco, CA, US","fulltime","2024-10-08","direct_data","yearly",90000.0,210000.0,"USD",False,"","","","","","We are seeking an experienced Senior Data Engineer who will contribute to developing our advanced cell therapy manufacturing platform. This role will lead the design, development, and management of scalable data pipelines and architecture.  

The ideal candidate has extensive experience in data engineering, a strong understanding of modern data architectures, and a deep knowledge of big data technologies. This role involves working with large datasets, ensuring data quality, and collaborating with cross-functional stakeholders across the organization to provide data-driven business outcomes for our cell therapy business.  

We're looking for someone who thrives in a fast-paced, mission-driven environment, is comfortable wearing multiple hats, and is ready to tackle diverse challenges as our company grows.### **Responsibilities**

+ Architect, design, and implement data pipelines and infrastructure to support the implementation of data analytics and AI solutions, leveraging Azure Cloud Platform and Databricks technologies
+ Collaborate with cross-functional teams to understand project requirements, translate them into technical specifications, and develop scalable and efficient data solutions
+ Build and maintain data ingestion, transformation, and storage systems using Azure services such as Azure Database for PostgreSQL, Azure Blob storage, and Azure Databricks, ensuring data quality, reliability, and security
+ Work closely with cell therapy process developers, manufacturing operators, and scientists to preprocess and prepare data for machine learning models, performing feature engineering, data augmentation, and exploratory data analysis as needed
+ Implement monitoring, logging, and alerting mechanisms to track data pipeline performance and ensure timely identification and resolution of issues
+ Document data engineering processes, workflows, and best practices and provide guidance and support to project team members as needed
### **Requirements**

+ Bachelor's or Master's degree in Computer Science, Engineering, or a related technical field with at least 6 years of related industry experience
+ Proven experience in data engineering, with a focus on building data pipelines and infrastructure in cloud environments, preferably on Microsoft Azure
+ Strong proficiency in Azure services such as Azure Databricks, Azure Database for PostgreSQL, Azure Table Storage, Azure Cosmos DB
+ Proficiency in managing, optimizing, and data integration with Elasticsearch clusters
+ Experience with data preprocessing, feature engineering, and data modeling techniques, particularly in the context of data analytics, machine learning, and AI applications
+ Proficiency in programming languages such as Python or C#, with experience in developing scalable and efficient data processing code
+ Expertise with data visualization tools such as Microsoft Power BI and Tableau
+ Familiarity with data governance, compliance, and security best practices, especially in regulated industries such as medical devices, cell therapy, bioprocessing, or instrumentation
+ Excellent problem-solving and analytical skills, with the ability to troubleshoot complex data engineering issues and optimize performance
+ Effective communication and collaboration skills, with the ability to work in cross-functional teams and interact with stakeholders at all levels
+ Comfortable working in a fast-paced start-up company environment with minimal direction and changing priorities
+ Ability to be a strong problem solver and team player
+ Self-awareness, integrity, authenticity, and a growth mindset
+ This will be a full-time onsite position in South San Francisco or Chicago

$90,000 - $210,000 a year  

Cellares total compensation package contains competitive base salaries, highly subsidized Medical, Dental, and Vision Plans, 401(k) Matching, Free EV Charging, Onsite lunches, and Stock options. All displayed pay ranges are approximate, negotiable, and location dependent.","https://www.indeed.com/cmp/Cellares","","","","","","","","",""
"153a2edf80f7e6dd","indeed","https://www.indeed.com/viewjob?jk=153a2edf80f7e6dd","https://ats.rippling.com/rippling/jobs/6289eed4-7025-43a1-94bb-57ad580509a6","Senior Data Engineer, Growth Marketing","Rippling","San Francisco, CA, US","","2024-10-08","direct_data","yearly",135000.0,236250.0,"USD",False,"","","","","accomodations@rippling.com","**About Rippling**
Rippling is the first way for businesses to manage all of their HR & IT—payroll, benefits, computers, apps, and more—in one unified workforce platform.  

By connecting every business system to one source of truth for employee data, businesses can automate all of the manual work they normally need to do to make employee changes. Take onboarding, for example. With Rippling, you can just click a button and set up a new employees’ payroll, health insurance, work computer, and third-party apps—like Slack, Zoom, and Office 365—all within 90 seconds.  

Based in San Francisco, CA, Rippling has raised $1.2B from the world’s top investors—including Kleiner Perkins, Founders Fund, Sequoia, Greenoaks, and Bedrock—and was named one of America's best startup employers by Forbes.  

We prioritize candidate safety. Please be aware that all official communication will only be sent from @Rippling.com addresses. **About The Role**
We are looking for an experienced data engineer to join our engineering team in our Revenue Operations org. As a senior member of the team, you will be leading the design and development of data pipelines and services to enable data-driven decision-making, as well as power BI, ML, experimentation, and user-facing features. You'd be expected to work closely with stakeholders across a variety of orgs, such as Data Science, Marketing, Bizops, Revops, Finance, and adjacent data teams to drive projects forward while supporting the professional development of junior team members.  

Here’s an idea of some of the initiatives you could be working on:* Build custom data pipelines to ingest data from third party data sources for our marketing and data science teams using Airflow and AWS resources
* Build custom transformations and derived datasets to power audience segmentation, analytics, and data science
* Own our marketing and sales data platform and the responsibility for defining the key datasets, schema, and building of tools to enable easy use of this data

**What You'll Do*** Architect, build, and scale our data pipelines for ingesting data from internal databases and systems, and third party tools into our warehouse
* Help build out Marketing and Revenue Ops data platform and tooling
* Support analytics, data science, machine learning, and business operations functions
* Monitor and maintain pipelines and infrastructure to upholds internal SLAs

**Qualifications*** 5+ years of experience in data and software engineering
* Expertise in writing complex data transforms in SQL and Python
* Knowledge of data warehousing concepts around building custom ETL integrations and building data infrastructure (SCD, CDC, Snapshots, indexing, partitioning)
* Experience in analytics, dimensional modeling, and ETL optimization preferred
* BS/BA in a technical field such as Computer Science or Mathematics preferred

 *Rippling is an equal opportunity employer. We are committed to building a diverse and inclusive workforce and do not discriminate based on race, religion, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, age, sexual orientation, veteran or military status, or any other legally protected characteristics, Rippling is committed to providing reasonable accommodations for candidates with disabilities who need assistance during the hiring process. To request a reasonable accommodation, please email accomodations@rippling.com.*","https://www.indeed.com/cmp/Rippling","http://www.rippling.com","San Francisco","51 to 200","","","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/d621ada17bcc71d13a5817834303263d","","",""
"f08c3b2070d091dc","indeed","https://www.indeed.com/viewjob?jk=f08c3b2070d091dc","https://www.bill.com/about-us/jobs?gh_jid=5340428004","Data Engineer II","BILL","San Jose, CA, US","","2024-10-08","direct_data","yearly",110200.0,132100.0,"USD",True,"","","","","interviewaccommodations@hq.bill.com","**Do the best work of your career as a champion for small and mid-size businesses.**



BILL is a leader in financial automation software for small and midsize businesses (SMBs). As a champion of SMBs, we are dedicated to automating the future of finance so businesses can thrive. Hundreds of thousands of businesses trust BILL solutions to manage financial workflows, including payables, receivables, and spend and expense management. With BILL, businesses are connected to a network of millions of members, so they can pay or get paid faster. Through our automated solutions, we help SMBs simplify and control their finances, so they can confidently manage their businesses, and succeed on their terms.



BILL is a trusted partner of leading U.S. financial institutions, accounting firms, and accounting software providers. We have operations in San Jose, CA, Draper, UT, Houston, TX and are continuing to expand into other geographic locations. If you’re looking for a place that helps you do the best work of your career, look no further than BILL.


**Make your impact within a rapidly growing Fintech Company**



Our team’s mission is to build a world-class data platform to fuel data products for BILL’s customers and to enable business critical initiatives for our data teams. As a member of our team you would be designing and scaling our platform, tackling big data challenges and working closely with other teams in their data initiatives. Come and join our team to take our company’s data architecture to the next level.


**Responsibilities:**


* Collaborate with architects, engineers, analysts and product owners to understand their data requirements and translate them into design
* Build scalable data solutions required to support data products, data science, machine learning and AI applications
* Own the quality, efficiency and automation of data pipelines
* Partner with different teams within the company to drive data driven projects
* Partner with core infrastructure and engineering teams to build, maintain and operate data platform frameworks in the Cloud
* Use agile software development processes to make iterative improvements to our cloud data platform
* Perform peer reviews of the code and contribute to the team’s wiki


**We’d love to chat if you have:**


* Bachelor’s degree in Computer Science, Engineering or related discipline
* 3+ years of professional experience in data and cloud platforms
* Demonstrated experience in the Agile environment with developing, testing and implementing solutions utilizing cloud big data tech stack
* Demonstrated experience with one or more big data frameworks such as **Kafka, Flink,** **Kinesis**, **Spark, Airflow** etc.
* Strong coding skills in one high-level programming language such as **Python**, **Java** or similar
* Strong experience in data frameworks such as **SQL, PySpark** and experience with Cloud services**(e.g., AWS, GCP)**
* Knowledge of one or more open table formats (**Iceberg, Hudi, Delta Lake etc.)** and experience withone or moredatabases such as **Redshift, Snowflake, Dynamodb, Graph or OLAP dbs** etc.
* Knowledge of CI/CD, Data Operations, infrastructure-as-code such as **Terraform or similar**


The estimated salary range for this role is noted below for our San Jose based role. Our ranges for each role and job level are based on a variety of factors including candidate experience, expertise, and geographic location and may vary from the amounts listed above. The role is also eligible for a competitive benefits package that includes: medical, dental, vision, life and disability insurance, 401(k) retirement plan, flexible spending & health savings account, paid holidays, paid time off, and other company benefits.


San Jose pay range
$110,200—$132,100 USD
**Let’s talk about benefits**


* 100% paid employee health, dental, and vision plans (choose HMO, PPO, or HDHP)
* HSA & FSA accounts
* Life Insurance, Long & Short-term disability coverage
* Employee Assistance Program (EAP)
* 11+ Observed holidays and wellness days and flexible time off
* Employee Stock Purchase Program with employee discounts
* Wellness & Fitness initiatives
* Employee recognition and referral programs
* And much more


**For positions that are in office we support a hybrid work environment with on-site and remote work days. Check out our** **LinkedIn Life Page** **for each location and discover BILL.**


**We live our culture and values every day**



At BILL, we’re different by design—it's our culture. Our CEO is a trusted entrepreneur who lives our cultural values: Humble, Authentic, Passionate, Accountable, and Fun. People here love being their authentic selves, contributing unique experiences, sharing ideas, perspectives, and intellectual curiosity. We celebrate our diversity as the heart and soul of how we work, grow, and succeed together. Inspiring people with meaningful career experiences they love really does make the dream work and our successes just keep getting better. There’s no limit to what we can build and where we can go from here. We’d love you to join us.  

  

BILL is proudly an Equal Opportunity Employer where everyone is welcome. Our innovation and technology are inspired by an inclusive culture unlike any other. Everyone brings a different personal story and perspective and this diverse mix of minds, backgrounds, and experiences is where our greatest ideas come from. We welcome people of all races, ethnicities, ages, religions, abilities, genders, and sexual orientations to make us an even more vibrant company. We want everyone to bring their authentic selves here, to share our values, shape our vision, drive innovation, and become part of a culture we celebrate every day.



Our promise to our candidates is to be transparent, diligent, and engaging while guiding individuals through each step of our hiring process. At BILL we strive to achieve an inclusive and positive candidate experience that aligns with our core values and focuses on diversity.



If you require a reasonable accommodation for your application, interviews, or another aspect of the hiring process, please contact interviewaccommodations@hq.bill.com.


**BILL Culture:**


* **Humble** - We check our egos at the door. We are curious. We listen, accept feedback.
* **Authentic** - We earn and show trust by being real—embracing our authentic selves.
* **Passionate** - We care deeply about each other and our customers.
* **Accountable** - We are duty-bound to each other, our customers, and society.
* **Fun** - We wrap it all together by building connections and enjoying time spent together.","https://www.indeed.com/cmp/Bill-4650b035","http://www.bill.com","San Jose, California","","","","","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/189e67e093f1d83239d37c0428c3b6a7","",""
"110f07f456e1b799","indeed","https://www.indeed.com/viewjob?jk=110f07f456e1b799","https://jobs.ashbyhq.com/writer/2599ac0c-762b-40ad-88d1-1ad5931e6fe9?utm_source=2zJJ0mDmlj","Data engineer","Writer","San Francisco, CA, US","fulltime","2024-10-08","direct_data","yearly",140013.0,177287.0,"USD",False,"","","","","","**About Writer**


Writer is the full-stack generative AI platform delivering transformative ROI for the world’s leading enterprises. Named one of the top 50 companies in AI by Forbes, Writer empowers hundreds of customers like Accenture, Intuit, L’Oreal, and Vanguard to transform the way they work.


Our all-in-one solution makes it easy to deploy customized AI apps and workflows that accelerate growth, increase productivity, and ensure compliance. Designed to provide enterprise-grade accuracy, security, and efficiency, Writer’s suite of development tools is supported by Palmyra – Writer’s state-of-the-art family of LLMs – alongside our industry-leading graph-based RAG and customizable AI guardrails.


Founded in 2020 with offices in San Francisco, New York City, and London, Writer is backed by strategic investors, including ICONIQ Growth, Insight Partners, WndrCo, Balderton Capital, and Aspect Ventures.


Our team of over 200 employees thinks big and moves fast, and we’re looking for smart, hardworking builders and scalers to join us on our journey to create a better future of work.

**About this role**


We are looking for our first ever Data Engineer to join our team. This role presents an extremely rare and unique opportunity to influence the architecture and tools that power our data analytics and reporting capabilities. You’ll be at the intersection of engineering, product and data, leading the integration of our product, financial, and business systems. If you are passionate about data modeling and solving complex data problems, we want to hear from you!

 **Tech stack**


Core tools: BigQuery, dbt, Fivetran, Hightouch, Segment, Amplitude, Omni


Periphery tools: Salesforce, Hubspot, Gong, Vitally

 **Your responsibilities**

* **Data Workflows**: Own, build, and maintain data pipelines, ETL/reverse-ETL processes and BigQuery environment.
* **Data Quality**: Implement an orchestration tool. Design a suite of tests and validations to ensure data consistency, accuracy and integrity.
* **Data Modeling**: Develop reliable and lasting data models, while optimizing for scale.
* **Documentation**: Catalog and document all aspects of our data pipelines. Create the foundation for a data governance program.
* **Collaboration**: Partner with product and engineering teams to deliver data solutions that align with downstream use cases.
* **Data Leadership**: Establish data engineering best practices and serve as a subject matter expert on our data architecture, models and systems.

**️ Is this you?**

* 5+ years of hands-on experience in a data engineering role, ideally in a SaaS environment
* Expert in SQL, dbt and Python
* Advanced knowledge of data engineering tools, frameworks and languages (eg. Airflow, Airbyte, Kafka, github workflows)
* Experience working with services in cloud environment (eg. AWS or GCP)
* Care deeply about data quality, integrity and security
* Thrive in ambiguity and can create paved roads from dirt paths
* Bonus points if you have experience with product event/attribute tracking design and implementation


AND

* High intellectual curiosity and a proclivity to lean into a new subject matter
* A trusted advisor and partner for all levels of the organization
* Intrinsically motivated: you set the highest possible bar for what you build and ship
* An eye for spotting an opportunity, intuition for determining which ones to prioritize, and courage to follow through
* Possesses humility — no work is too trivial if it’s impactful
* Resilient and open to honest (and kind) feedback; tough skin
* Self-aware and committed to learning the why for both successes and failures
* Proactive communication skills, both sync and async
* Experience managing and building relationships across multiple departments and stakeholder levels
* A natural affinity to our values of connect, challenge, own


Curious to learn more about who we are and how we operate? Visit us here

**Benefits & perks**

* Generous PTO, plus company holidays
* Medical, dental, and vision coverage for you and your family
* Paid parental leave for all parents (12 weeks)
* Fertility and family planning support
* Early-detection cancer testing through Galleri
* Flexible spending account and dependent FSA options
* Health savings account for eligible plans with company contribution
* Annual work-life stipends for:


	+ Home office setup, cell phone, internet
	+ Wellness stipend for gym, massage/chiropractor, personal training, etc.
	+ Learning and development stipend
* Company-wide off-sites and team off-sites
* Competitive compensation, company stock options and 401k

*Writer is an equal-opportunity employer and is committed to diversity. We don't make hiring or employment decisions based on race, color, religion, creed, gender, national origin, age, disability, veteran status, marital status, pregnancy, sex, gender expression or identity, sexual orientation, citizenship, or any other basis protected by applicable local, state or federal law. Under the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.*


By submitting your application on the application page, you acknowledge and agree to Writer's Global Candidate Privacy Notice.","https://www.indeed.com/cmp/Writer-1","","","","","","","","",""
"ec5f75d425b75a77","indeed","https://www.indeed.com/viewjob?jk=ec5f75d425b75a77","https://click.appcast.io/track/kt7r2po-org?cs=5c","Staff, Data Engineer | Sunnyvale | Marketplace","Walmart","Sunnyvale, CA, US","","2024-10-08","direct_data","yearly",143000.0,286000.0,"USD",False,"","","","","","Position Summary...  

  

What you'll do...
  

**\\*\\* Immigration Sponsorship is not available in this role & location . \\*\\***  

  

**About Team :**  

  

**Marketplace Engineering team** is at the forefront of building core platforms and services to enable Walmart to deliver vast selection at competitive prices and with best-in-class customer experience by enabling third-party sellers to the marketplace platform, sell and manage their products to our customers on walmart.com. We do this by managing the entire seller lifecycle, monitoring customer experience, and deliver high- value insights to our sellers to help them plan their assortment, price, inventory. The team also actively collaborates with partner platform teams to ensure we continue to deliver the best experience to our sellers and our customers.  

  

**What you'll do :**  

  

We are looking for an experienced **Staff Data Engineer** to join Global Marketplace Engineering team. This **hands-on role** requires exceptional coding skills, a passion for technology and engineering excellence, and the ability to guide and mentor a team of engineers. You will play a key role in defining and maintaining our technical architecture with lead architect, ensuring alignment with business goals and scalability requirements.  

  

As a **Staff Data Engineer**, you'll have the opportunity to  

* Guide and mentor, a team of engineers, conducting code reviews and leading design discussions to ensure engineering best practices.
* Drive the adoption of coding standards, design patterns, and development best practices.
* Lead the creation and maintenance of our technical architecture, aligning it with business goals and scalability requirements.
* Architect complex software systems (data/backend), ensuring performance, security, and scalability needs are met.

  

**Software Craftsmanship:**  

* Consistently produce high-quality software with a focus on unit testing, regular code reviews, and continuous integration.
* Uphold high standards in quality and operational excellence.

  

**Technical Documentation:**  

* Develop comprehensive technical documentation and presentations to clearly communicate architectural decisions and design options.
* Ensure documentation aligns with project scopes, milestones, and deliverables.

  

**Engineering Advocacy:**  

* Promote and enforce technical standards across the organization to achieve concrete outcomes and drive engineering excellence.
* Foster a culture of learning and innovation through hands-on technical guidance and mentorship.

  

**Project Leadership:**  

* Lead the discovery phase of major projects, ensuring the design aligns with business goals and technical requirements.
* Collaborate with cross-functional teams to define project scopes and milestones.

  

**Cross-functional Collaboration:**  

* Collaborate closely with Product Management, UX/UI, Quality Assurance, and DevOps teams.
* Communicate complex technical concepts effectively to both technical and non-technical stakeholders.

  

**Innovation and Research:**  

Stay at the forefront of technological advancements, conducting research to identify emerging tools and methodologies.  

* 

  

  

**What you'll Bring :**  

* **10+ years of experience in software development, focusing on building large scale distributed systems.**
* Experience in multiple stack technologies **Java, Python, Scala**
* Proficiency in **API development, GQL, Node.js**
* Well versed with **Hadoop, Hive, Spark using Scala, Kubernetes, Vertex AI, Presto/Trino, Cloud, Automic, Airflow and Data Lake** concepts.
* Advanced knowledge of complex software design, distributed system design, design patterns, data structures, and algorithms.
* Skilled in data modelling & data migration protocols.
* Familiarity with public cloud technologies such as **Azure or Google Cloud Platform**.
* Experience with **Kafka connect, Druid, Big Query and Looker** is added advantage.
* Excellent technical debugging and production support skills.
* Extensive experience in the design, development, and delivery of software products with a large user base.
* Track record in an architect role with **large-scale software development** data-backed services and applications.
* **Excellent decision-making** skills with the ability to balance conflicting interests in a complex and fast-paced environment.

  

  

**About Walmart Global Tech :**  

Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That's what we do at Walmart Global Tech. We're a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world's leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.  

  

**Flexible, hybrid work :**  

We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.  

  

**Benefits :**  

Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.  

  

**Equal Opportunity Employer :**  

Walmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.  

  

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.  

  

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.  

‎
  

  

‎
  

  

‎
  

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.  

‎
  

  

For information about PTO, see https://one.walmart.com/notices .
  

  

‎
  

  

‎
  

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.  

‎
  

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.  

‎
  

  

For information about benefits and eligibility, see One.Walmart .
  

  

‎
  

The annual salary range for this position is $143,000.00-$286,000.00  

‎
  

Additional compensation includes annual or quarterly performance bonuses.  

‎
  

Additional compensation for certain positions may also include:  

‎
  

  

‎
  

* Stock


‎
  

  

‎  

  

**Minimum Qualifications...**  

  

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.  

  

Option 1: Bachelor's degree in Computer Science and 4 years' experience in software engineering or related field. Option 2: 6 years' experience in software engineering or related field. Option 3: Master's degree in Computer Science and 2 years' experience in software engineering or related field.  

3 years' experience in data engineering, database engineering, business intelligence, or business analytics.  

  

**Preferred Qualifications...**  

  

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.  

  

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Master's degree in Computer Science or related field and 4 years' experience in software engineering or related field, We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart's accessibility standards and guidelines for supporting an inclusive culture.  

  

**Primary Location...**  

  

840 W California Ave, Sunnyvale, CA 94086-4828, United States of America","https://www.indeed.com/cmp/Walmart","https://careers.walmart.com","Bentonville, AR","10,000+","more than $10B (USD)","Headquartered in Bentonville, Arkansas, Walmart is a multinational corporation that operates the largest chain of department stores globally.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/81872361234125a30d818f132d5fa3f8","","Doug McMillon","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/a8dbfb0b8ee0396d8cf2ad044da40a5e"
"26c458d317b385d5","indeed","https://www.indeed.com/viewjob?jk=26c458d317b385d5","https://apply.workable.com/j/17F41D6B0D","Data Engineer","","Oakland, CA, US","fulltime","2024-10-08","direct_data","yearly",150000.0,180000.0,"USD",True,"","","","","","Our client is a venture-backed SaaS startup that recently secured Series A funding. They're solving a multi-billion dollar problem of data quality for the entire marketing industry. Their platform enables major brands and publishers to optimize consumer data quality, improving marketing ROI. In a fast-paced and collaborative environment, they are committed to excellence and innovation.

### **Key Responsibilities:**

* Design and maintain scalable data pipelines using Spark and AWS EMR for processing terabytes of consumer data
* Write, test, and optimize custom Scala code for ETL workflows
* Deploy and manage ETL processes in AWS cloud environments using Airflow
* Automate delivery of structured data to enterprise clients via Snowflake and Databricks
* Collaborate with the Data Science team to optimize data infrastructure
* Contribute to data modeling efforts using SQL for efficient large-scale data management
* Create monitoring tools and KPIs using Tableau to ensure data pipeline health
* Maintain comprehensive documentation for internal teams and external clients

**Tech Stack:** AWS (EMR, EC2, S3, Athena, Sagemaker), Spark, DBT, Snowflake, Databricks, Airflow, Terraform, Github, Tableau

**Programming Languages:** Scala, Python, SQL, and Bash

**Requirements**

* 5-7 years of relevant work experience (3-5 years considered)
* Strong SQL and Scala skills
* Experience with cloud computing tools (e.g., Spark, AWS EMR, Snowflake, Databricks)
* Proficiency in data modeling and distributed data processing
* Excellent communication skills, including explaining complex concepts to non-technical stakeholders

### **An ideal candidate will:**

* Thrives in a fast-paced startup, embracing high-impact responsibilities with minimal oversight
* Strong communicator, adept at explaining complex data concepts to diverse stakeholders
* Passionate about solving data quality challenges in marketing, with relevant industry experience
* Committed to long-term growth, excited by potential for ownership and future team leadership

**Benefits**

### **Compensation:**

* Salary range: $150,000 - $180,000
* Stock options package
* Full health benefits and 401k

### **Work Environment:**

* Hybrid model: 3 days in office, 2 days remote, on average
* Small, high-impact team with plans for growth
* Report directly to the Head of Data Science","","","","","","","","","",""
"ee03e3a2227d949f","indeed","https://www.indeed.com/viewjob?jk=ee03e3a2227d949f","https://www.jobs.abbott/us/en/job/ABLAUS31099788ENUSEXTERNAL/Data-Engineer?utm_source=indeed&utm_medium=phenom-feeds","Data Engineer","Abbott","Alameda, CA, US","fulltime","2024-10-07","direct_data","yearly",83600.0,167200.0,"USD",False,"","","","","","Abbott is a global healthcare leader that helps people live more fully at all stages of life. Our portfolio of life-changing technologies spans the spectrum of healthcare, with leading businesses and products in diagnostics, medical devices, nutritionals and branded generic medicines. Our 114,000 colleagues serve people in more than 160 countries.


Meet Lingo, a new biosensing technology that provides users a window into their body. Lingo tracks key biomarkers – such as glucose, ketones, and lactate – to help people make better decisions about their health and nutrition. Biowearable technology will digitize, decentralize and democratize healthcare, enabling consumers to take control of their own health.

**WORKING AT ABBOTT**


At Abbott, you can do work that matters, grow, and learn, care for yourself and family, be your true self and live a full life. You’ll also have access to:

* Career development with an international company where you can grow the career you dream of .
* Free medical coverage for employees\\* via the Health Investment Plan (HIP) PPO
* An excellent retirement savings plan with high employer contribution
* Tuition reimbursement, the Freedom 2 Save student debt program and FreeU education benefit - an affordable and convenient path to getting a bachelor’s degree.
* A company recognized as a great place to work in dozens of countries around the world and named one of the most admired companies in the world by Fortune.
* A company that is recognized as one of the best big companies to work for as well as a best place to work for diversity, working mothers, female executives, and scientists.

**The opportunity**

This **Data Engineer** position works out of our **Alameda, CA** location in Lingo.


This Data Engineer role is part of the Data Science & Analytics team where you will work alongside Product, Data Science & Analytics teams build high-quality data pipelines for high-end analytics solutions. These solutions will generate insights from the organization's connected data and enable data-driven decision-making capabilities for the organization.

**What you’ll do**

* Create, deploy and optimize large scale data
* Use extensive data engineering expertise to design and build solutions/ products for analyzing large data sets and identify patterns and relationships
* Manage data sources, organize data and create data assets using identified open source or proprietary tools
* Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals.
* Solve complex data problems to deliver insights that help the organization achieve its goals.
* Code in Python and Scala with tools like Apache Spark/Kafka to build a multi-cluster data warehouse.
* Interact with other technology teams to define, prioritize, and ensure smooth deployments for other operational components.
* Advise, consult, mentor, and coach other data and analytics professionals on data standards and practices.
* Foster a culture of sharing, reuse, design for scale stability, and operational efficiency of data and analytical solutions.
* Codify best practices for future reuse in the form of accessible, reusable patterns, templates, and code bases to facilitate data capturing and management.
* Code in SQL to create curated data products.
 **Qualifications**

* Bachelors Degree in any of the following: Math, Physics, Computer Science, Statistics, Economics, Quantitative Sciences
* **Minimum 3 years** in data engineering/analytics space
* Strong problem-solving skills
* Experience in any from MS Azure, AWS, Python, Spark, hive, HBase, Hadoop, Kafka, YARN etc.
* Attention to detail and organization/ documentation skills
* Ability to prioritize and triage deadline-driven tasks in a high-pressure environment
* Basic knowledge of distributed computing, parallel processing and large scale data management
* Experience manipulating and analyzing complex, high-volume data from varying sources
* Ability to communicate complex quantitative analysis in a clear, precise, actionable manner
**Apply Now**

* Participants who complete a short wellness assessment qualify for FREE coverage in our HIP PPO medical plan. Free coverage applies in the next calendar year.

**Learn more about our health and wellness benefits, which provide the security to help you and your family live full lives:** www.abbottbenefits.com


Follow your career aspirations to Abbott for diverse opportunities with a company that can help you build your future and live your best life. Abbott is an Equal Opportunity Employer, committed to employee diversity.


Connect with us at www.abbott.com, on Facebook at www.facebook.com/Abbott and on Twitter @AbbottNews and @AbbottGlobal.

  

The base pay for this position is $83,600.00 – $167,200.00. In specific locations, the pay range may vary from the range posted.","https://www.indeed.com/cmp/Abbott","http://www.abbott.com","Abbott Park, IL","10,000+","more than $10B (USD)","Abbott employees do work that matters as part of a global community dedicated to helping people live better and healthier with our life-changing technologies.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/30e9c7297f17d9cce810b6efcc34d602","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/ef2def0162120b08f0e3f39d7ca6a3f3","Robert Ford",""
"6ef2ee53bffb97bc","indeed","https://www.indeed.com/viewjob?jk=6ef2ee53bffb97bc","https://jsv3.recruitics.com/redirect?rx_cid=3239&rx_jobId=a1KDp00000E2JMSMA3&rx_url=https%3A%2F%2Fwww.metacareers.com%2Fjobs%2F1668648587034930%2F%3Frx_campaign%3Dindeed0%26rx_ch%3Dvp%26rx_group%3D187943%26rx_job%3Da1KDp00000E2JMSMA3%26rx_medium%3Dcpc%26rx_r%3Dnone%26rx_source%3Dindeed%26rx_ts%3D20241010T061201Z%26rx_vp%3Dcpc%26utm_campaign%3DJob%252Bboard%26utm_medium%3Djobs%26utm_source%3Dindeedorganic","Data Engineer Intern","Meta","Sunnyvale, CA, US","internship","2024-10-07","direct_data","monthly",6120.0,11000.0,"USD",False,"","","","","accommodations-ext@fb.com","Every month, billions of people leverage Meta products to connect with friends and loved ones from across the world. On the Data Engineering Team, our mission is to support these products both internally and externally by delivering the best data foundation that drives impact through informed decision making. As a highly collaborative organization, our data engineers work cross-functionally with software engineering, data science, and product management to optimize growth, strategy, and experience for over three billion users, as well as our internal employee community. In this role, you will see a direct correlation between your work, company growth, and user satisfaction. Beyond this, you will work with some of the brightest minds in the industry, and you'll have a unique opportunity to solve some of the most interesting data challenges with efficiency and integrity, at a scale few companies can match. As we continue to expand and create, we have a lot of exciting work ahead of us!  

  

  

### **Data Engineer Intern Responsibilities:**

* Architect, implement and deploy new data models and data processes in production
* Perform data analysis to generate business insights
* Interface with Engineers, Product Managers and Data Scientists to understand product goals and data needs
* Build data expertise and own data quality for allocated areas of ownership
* Manage data warehouse plans for a product or a group of products
* Support critical data processes running in production

  

  

  

### **Minimum Qualifications:**

* Currently has, or is in the process of obtaining, a Bachelors, or Masters degree in Computer Science, Information Science, Mathematics, or related technical field
* Knowledge of SQL, data modeling and at least one programming language(e.g., Python, C++, C#, Scala)
* Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment

  

  

  

### **Preferred Qualifications:**

* Intent to return to degree-program after the completion of the internship
* Curious, self-driven, analytical and excited to play with data
* Ability to thrive in a fast paced work environment
* Experience in collaborating with individuals and organizations

  

  

  

### **About Meta:**


Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.  

  

  

Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.
  

  

Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.  

  

$6,120/month to $11,000/month + benefits  

  

Individual compensation is determined by skills, qualifications, experience, and location. Compensation details listed in this posting reflect the base hourly rate, monthly rate, or annual salary only, and do not include bonus, equity or sales incentives, if applicable. In addition to base compensation, Meta offers benefits. Learn more about benefits at Meta.","https://www.indeed.com/cmp/Meta-dd1502f2","http://www.metacareers.com","Menlo Park, CA","10,000+","more than $10B (USD)","Meta builds technologies that help people connect, find communities, and grow businesses.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/bd68b445614f6698f5772db72d9e8f01","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/f44d91ed6b6b4d1b968feaab0ef5f6de","Mark Zuckerberg","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/6899719874009ac6d16d2083a3774add"
"488e19b2b7c7339e","indeed","https://www.indeed.com/viewjob?jk=488e19b2b7c7339e","https://click.appcast.io/track/ksr0sih-org?cs=5c","Senior, Data Engineer","Walmart","Sunnyvale, CA, US","","2024-10-07","direct_data","yearly",117000.0,234000.0,"USD",False,"","","","","","Position Summary...  

  

What you'll do...  

  

About Team:
  

Data Ventures exists to unlock the full value of Walmart's data by developing
  

and productizing B2B data initiatives that empower merchants and suppliers to
  

make better, faster decisions for the business. As part of this transformation, we're
  

seeking entrepreneurial individuals to help drive data productization from concept
  

to deployment.  

  

What you'll do:
  

Demonstrates up-to-date expertise and applies this to the development,
  

execution, and improvement of action plans by providing expert advice and
  

guidance to others. Supporting and aligning efforts to meet customer, business
  

needs and building commitment for perspectives and rationales.
  

Create software design and architecture for next software solution. This will be
  

your channel to communicate your ideas with rest of the team. Not just one but
  

evaluate multiple solutions
  

Analyze competing requirements and articulate tradeoffs and lead discussions
  

with business and development team, leading white board sessions with team.
  

Drives the execution of multiple business plans and projects by identifying
  

customer and operational needs. Developing and communicating business
  

plans and priorities, removing barriers and obstacles that impact performance.
  

Demonstrating adaptability and supporting continuous learning.
  

Creates training documentation. Oversees the tasks of less experienced
  

programmers and stipulates system troubleshooting supports.  

  

What you'll bring:
  

Experience with
  

* Hadoop, Spark, Cloud, Scala, Streaming, Kafka
* SQL / Data warehousing
* BI and Looker Views, Models, Explores, Looks/Charts
* DS and Algorithm
* CI/CD
* Data Modeling
* Airflow
* Knowledge of
* Cloud (GCP/Azure)
* Backend, Spring
* Python

  

About Walmart Global Tech
  

Imagine working in an environment where one line of code can make life easier for
  

hundreds of millions of people. That's what we do at Walmart Global Tech. We're a
  

team of software engineers, data scientists, cybersecurity expert's and service
  

professionals within the world's leading retailer who make an epic impact and are at  

  

the forefront of the next retail disruption. People are why we innovate, and people
  

power our innovations. We are people-led and tech-empowered.
  

  

We train our team in the skillsets of the future and bring in experts like you to help
  

us grow. We have roles for those chasing their first opportunity as well as those
  

looking for the opportunity that will define their career. Here, you can kickstart a
  

great career in tech, gain new skills and experience for virtually every industry, or
  

leverage your expertise to innovate at scale, impact millions and reimagine the
  

future of retail.
  

Flexible, hybrid work
  

We use a hybrid way of working with primary in office presence coupled with an
  

optimal mix of virtual presence. We use our campuses to collaborate and be
  

together in person, as business needs require and for development and networking
  

opportunities. This approach helps us make quicker decisions, remove location
  

barriers across our global team, be more flexible in our personal lives.
  

Benefits
  

Beyond our great compensation package, you can receive incentive awards for your
  

performance. Other great perks include a host of best-in-class benefits maternity
  

and parental leave, PTO, health benefits, and much more.
  

Equal Opportunity Employer:
  

Walmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best
  

equipped to help our associates, customers and the communities we serve live
  

better when we really know them. That means understanding, respecting and
  

valuing diversity- unique styles, experiences, identities, ideas and opinions - while
  

being inclusive of all people.
  

The above information has been designed to indicate the general nature and level
  

of work performed in the role. It is not designed to contain or be interpreted as a
  

comprehensive inventory of all responsibilities and qualifications required of
  

employees assigned to this job. The full Job Description can be made available as
  

part of the hiring process  

  

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.  

‎
  

  

‎
  

  

‎
  

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.  

‎
  

  

For information about PTO, see https://one.walmart.com/notices .
  

  

‎
  

  

‎
  

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.  

‎
  

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.  

‎
  

  

For information about benefits and eligibility, see One.Walmart .
  

  

‎
  

The annual salary range for this position is $117,000.00-$234,000.00  

‎
  

Additional compensation includes annual or quarterly performance bonuses.  

‎
  

Additional compensation for certain positions may also include:  

‎
  

  

‎
  

* Stock


‎
  

  

‎  

  

**Minimum Qualifications...**  

  

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.  

  

Option 1: Bachelor's degree in Computer Science and 3 years' experience in software engineering or related field. Option 2: 5 years' experience in  

software engineering or related field. Option 3: Master's degree in Computer Science and 1 year's experience in software engineering or related  

field.  

2 years' experience in data engineering, database engineering, business intelligence, or business analytics.  

  

**Preferred Qualifications...**  

  

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.  

  

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Master's degree in Computer Science or related field and 3 years' experience in software engineering, We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart's accessibility standards and guidelines for supporting an inclusive culture.  

  

**Primary Location...**  

  

640 W California Avenue, Sunnyvale, CA 94086-4828, United States of America","https://www.indeed.com/cmp/Walmart","https://careers.walmart.com","Bentonville, AR","10,000+","more than $10B (USD)","Headquartered in Bentonville, Arkansas, Walmart is a multinational corporation that operates the largest chain of department stores globally.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/81872361234125a30d818f132d5fa3f8","","Doug McMillon","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/a8dbfb0b8ee0396d8cf2ad044da40a5e"
"dc097aad78e4eb05","indeed","https://www.indeed.com/viewjob?jk=dc097aad78e4eb05","https://click.appcast.io/track/ksr0sig-org?cs=5c","Principal, Data Engineer | Marketplace | Sunnyvale","Walmart","Sunnyvale, CA, US","","2024-10-07","direct_data","yearly",143000.0,286000.0,"USD",False,"","","","","","Position Summary...  

  

What you'll do...
  

**\\*\\* Immigration Sponsorship is not available in this role & location . \\*\\***  

  

**About Team :**  

  

Marketplace Engineering team is at the forefront of building core platforms and services to enable Walmart to deliver vast selection at competitive prices and with best-in-class customer experience by enabling third-party sellers to the marketplace platform, sell and manage their products to our customers on walmart.com. We do this by managing the entire seller lifecycle, monitoring customer experience, and deliver high- value insights to our sellers to help them plan their assortment, price, inventory. The team also actively collaborates with partner platform teams to ensure we continue to deliver the best experience to our sellers and our customers.  

  

**What you'll do :** We are looking for an experienced **Principal Data Engineer** to join Global Marketplace Engineering team. This **hands-on role** requires exceptional coding skills, a passion for technology and engineering excellence, and the ability to guide and mentor a team of engineers. You will play a pivotal role in defining and maintaining our technical architecture, ensuring alignment with business goals and scalability requirements.  

  

As a **Principal Data Engineer**, you'll have the opportunity to  

* Guide and mentor, a team of engineers, conducting code reviews and leading design discussions to ensure engineering best practices.
* Act as a technical authority, providing direction and expertise to the team.
* Drive the adoption of coding standards, design patterns, and development best practices.

  

**Architectural Leadership:**  

* Lead the creation and maintenance of our technical architecture, aligning it with business goals and scalability requirements.
* Architect complex software systems (data/backend), ensuring performance, security, and scalability needs are met.

  

**Software Craftsmanship:**  

* Consistently produce high-quality software with a focus on unit testing, regular code reviews, and continuous integration.
* Uphold high standards in quality and operational excellence.

  

**Technical Documentation:**  

* Develop comprehensive technical documentation and presentations to clearly communicate architectural decisions and design options.
* Ensure documentation aligns with project scopes, milestones, and deliverables.

  

**Engineering Advocacy:**  

* Promote and enforce technical standards across the organization to achieve concrete outcomes and drive engineering excellence.
* Foster a culture of learning and innovation through hands-on technical guidance and mentorship.

  

**Project Leadership:**  

* Lead the discovery phase of major projects, ensuring the design aligns with business goals and technical requirements.
* Collaborate with cross-functional teams to define project scopes and milestones.

  

**Cross-functional Collaboration:**  

* Collaborate closely with Product Management, UX/UI, Quality Assurance, and DevOps teams.
* Communicate complex technical concepts effectively to both technical and non-technical stakeholders.

  

**Innovation and Research:**  

Stay at the forefront of technological advancements, conducting research to identify emerging tools and methodologies.  

* 

  

  

**What you'll Bring** **:**  

* 15+ years of experience in software development, focusing on building large scale distributed systems.
* Experience in multiple stack technologies **Java, Python, Scala**
* Proficiency in **API development, GQL, Node.js**
* Well versed with **Hadoop, Hive, Spark using Scala, Vertex AI, Presto/Trino, Kubernetes, Cloud, Automic, Airflow and Data Lake** concepts.
* Advanced knowledge of complex software design, distributed system design, design patterns, data structures, and algorithms.
* Skilled in data modelling & data migration protocols.
* Familiarity with public cloud technologies such as **Azure or Google Cloud Platform**.
* Experience with **Kafka connect, Druid, Big Query and Looker** is added advantage.
* Excellent technical debugging and production support skills.
* Extensive experience in the design, development, and delivery of software products with a large user base.
* Track record in an architect role with **large-scale software development** data-backed services and applications.
* **Excellent decision-making** skills with the ability to balance conflicting interests in a complex and fast-paced environment.

  

  

**About Walmart Global Tech :**  

Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That's what we do at Walmart Global Tech. We're a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world's leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.  

  

**Flexible, hybrid work :**  

We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.  

  

**Benefits :**  

Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.  

  

**Equal Opportunity Employer :**  

Walmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.  

  

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.  

  

At Walmart, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.  

‎
  

  

‎
  

  

‎
  

You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.  

‎
  

  

For information about PTO, see https://one.walmart.com/notices .
  

  

‎
  

  

‎
  

Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.  

‎
  

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.  

‎
  

  

For information about benefits and eligibility, see One.Walmart .
  

  

‎
  

The annual salary range for this position is $143,000.00-$286,000.00  

‎
  

Additional compensation includes annual or quarterly performance bonuses.  

‎
  

Additional compensation for certain positions may also include:  

‎
  

  

‎
  

* Stock


‎
  

  

‎  

  

**Minimum Qualifications...**  

  

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.  

  

Option 1: Bachelor's degree in Computer Science and 5 years' experience in software engineering or related field. Option 2: 7 years' experience in software engineering or related field. Option 3: Master's degree in Computer Science and 3 years' experience in software engineering or related field.  

4 years' experience in data engineering, database engineering, business intelligence, or business analytics.  

  

**Preferred Qualifications...**  

  

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.  

  

Data engineering, database engineering, business intelligence, or business analytics, ETL tools and working with large data sets in the cloud, Master's degree in Computer Science or related field and 5 years' experience in software engineering or related field, We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart's accessibility standards and guidelines for supporting an inclusive culture.  

  

**Primary Location...**  

  

840 W California Ave, Sunnyvale, CA 94086-4828, United States of America","https://www.indeed.com/cmp/Walmart","https://careers.walmart.com","Bentonville, AR","10,000+","more than $10B (USD)","Headquartered in Bentonville, Arkansas, Walmart is a multinational corporation that operates the largest chain of department stores globally.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/81872361234125a30d818f132d5fa3f8","","Doug McMillon","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/a8dbfb0b8ee0396d8cf2ad044da40a5e"
"35dc7546c9e2698b","indeed","https://www.indeed.com/viewjob?jk=35dc7546c9e2698b","https://careers.blackline.com/jobs/4907/job?utm_source=indeed_integration&iis=Job%20Board&iisn=Indeed&indeed-apply-token=73a2d2b2a8d6d5c0a62696875eaebd669103652d3f0c2cd5445d3e66b1592b0f","Principal Data Engineer","BlackLine","Pleasanton, CA, US","","2024-10-06","direct_data","yearly",201000.0,269000.0,"USD",False,"","","","","","Make Your Mark::

As a Principal Software Engineer, you will play a crucial role in delivering high quality releases to our customers by defining application architecture, designing, developing, troubleshooting, maintaining, optimizing, and scaling BlackLine’s data platform and driving innovation into our product suite.  

In this role, you will work with management to identify strategic directions for system architecture.
You will research, test, benchmark and evaluate new technologies, propose scaling solutions, collaborate with other teams to define, and build new features, optimize existing features while writing elegant code, coaching, and mentoring less experienced data engineers and communicating with people at all levels.  

In this position, every bit of your software design skill be drawn upon to drive towards and implement best of breed features in a rapid iterative environment. Your attention to detail, tenacity, and creative problem-solving and thinking ahead will directly impact the company's success, as well as the success of your peers across the organization.  

If you have a passion for delivering products that make a difference, are driven to make things better in all that you do and are eager to work in a collaborative agile environment where Developers are dedicated to solving customer problems and innovating, you will be a great fit for the team.  

As a member of the Data & BI Engineering team you will primarily focus on advancing our Enterprise Data Platform to allow the organization to make data-driven decisions. The successful candidate will work closely with cross-functional teams to identify business requirements, design, and develop data models, data warehouses, and data visualization solutions that help support the organization's strategic goals.

  

  

The principal Data Engineer will work in a dynamic environment and will be required to stay current with the latest trends and technologies in the business intelligence field. The ideal candidate will be able to pick up business domain and internal process knowledge and leverage that knowledge to think strategically, communicate effectively, and manage multiple projects simultaneously.

  

  

The team is also responsible for administering tools and platforms around reporting, analytics, and data visualization while promoting best practices. The role requires a strong combination of technical expertise, leadership skills, and a deep understanding of data engineering principles and best practices. We are looking for a driven, detail-oriented, and passionate engineer to come to join our team.


You'll Get To::
* Provide technical expertise and leadership in technology direction, road-mapping, architecture definition, design, development, and delivery of enterprise-class solutions while adhering to timelines, coding standards, requirements, and quality.
* Architect, design, develop, test, troubleshoot, debug, optimize, scale, perform the capacity planning, deploy, maintain, and improve software applications, driving the delivery of high-quality value and features to Blackline’s customers.
* Work collaboratively across the company to design, communicate and further assist with adoption of best practices in architecture and implementation.
* Deliver robust architectural solutions for complex design problems.
* Implement, refine, and enforce data engineering best practices to ensure that delivered features meet performance, security, and maintainability expectations.
* Research, test, benchmark, and evaluate new tools and technologies, and recommend ways to implement them in data platform. Identify and create solutions that are likely to contribute to the development of new company concepts while keeping in mind the business strategy, short- and long-term roadmap, and architectural considerations to support them in a highly scalable and easy extensible manner.
* Actively participate in research, development, support, management, and other company initiatives designing solutions to optimally address current and future business requirements and infrastructure plans.
* Inspire a forward-thinking team of developers, acting as an agent of change and evangelist for a quality-first culture within the organization. Mentor and coach key technical staff and guide them to solutions on complex design issues.
* Act as a conduit for questions and information flow when those outside of Engineering have ideas for new technology applications.
* Speak in terms relevant to audience, translating technical concepts into non-technical language and vice versa. Facilitate consensus building while striving for win/win scenarios and elicit value-add contributions from all team members in group settings.
* Maintain a strong sense of business value and return on investment in planning, design, and communication.
* Proactively identify issues, bottlenecks, gaps, or other areas of concern or opportunity and work to either directly affect change, or advocate for that change by working with peers and leadership to build consensus and act.
* Perform critical maintenance, deployment, and release support activities, including occasional off-hours support.


What You'll Bring::
* Bachelor’s or master’s degree in computer science, Data Science, or a related field.
* 10+ years as a data engineer designing and architecting complex systems.
* 10+ years of experience using RDBMS, SQL, Python, or other programming languages is a plus.
* 5+ years working experience with SQL and familiarity with Snowflake data warehouse, strong working knowledge in stored procedures, CTEs, and UDFs, RBAC.
* Deep understanding of Data warehouse concepts, star, snowflake and dimensional modeling and ETL/ELT best practices, scalability, complex process management, self-healing approaches, etc.
* Strong working knowledge in at-least one of the big data architectures such as Lambda, Kappa and Hub and Spoke Architectures.
* Excellent proficiency in Stream-processing systems like Storm, Spark-Streaming, kafka streaming and building real time data pipelines.
* Proficiency in Container technologies: Docker, and Kubernetes.
* Experience with at least one modern Data pipeline, Replication and processing tools such as Qlik, Fivetran, airflow, Astronomer etc
* Understanding of data security and privacy regulations, with experience implementing data security best practices.
* Ability to define and manage user roles and permissions in Snowflake to ensure data security and privacy.
* Experience in working in a startup-type environment, good team player, and can work independently with minimal supervision.
* Proficient in managing large volumes of data.
* Strong analytical and interpersonal skills, comfortable presenting complex ideas in simple terms.
* Strong communication and collaboration skills, with the ability to work effectively with cross-functional teams.
* Experience in providing technical support and troubleshooting for data-related issues.
* Expertise with at least one cloud environment and building cloud native data services.
* Prior experience driving data governance, quality, security initiatives.


We’re Even More Excited If You Have::
* 5+ years of building data intensive applications in Java
* Experience with nosql systems such as mongodb, cockroachDb, apache cassandra etc.
* Significant experience with open-source platforms and technologies.
* Experience with data science and machine learning tools and technologies is a plus.


Thrive at BlackLine Because You Are Joining::
* A technology-based company with a sense of adventure and a vision for the future. Every door at BlackLine is open. Just bring your brains, your problem-solving skills, and be part of a winning team at the world's most trusted name in Finance Automation!
* A culture that is kind, open, and accepting. It's a place where people can embrace what makes them unique, and the mix of cultural backgrounds and varying interests cultivates diverse thought and perspectives.
* A culture where BlackLiner's continued growth and learning is empowered. BlackLine offers a wide variety of professional development seminars and inclusive affinity groups to celebrate and support our diversity.


BlackLine is an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to sex, gender identity or expression, race, ethnicity, age, religious creed, national origin, physical or mental disability, ancestry, color, marital status, sexual orientation, military or veteran status, status as a victim of domestic violence, sexual assault or stalking, medical condition, genetic information, or any other protected class or category recognized by applicable equal employment opportunity or other similar laws.  

BlackLine recognizes that the ways we work and the workplace itself has shifted. We innovate in a workplace that optimizes a combination of virtual and in-person interactions to maximize collaboration and nurture our culture. Candidates who live within a reasonable commute to one of our offices will work in the office at least 2 days a week.
Salary Range:: USD $201,000.00 - USD $269,000.00","https://www.indeed.com/cmp/Blackline-7","https://www.blackline.com","Woodland Hills, CA","1,001 to 5,000","$500M to $1B (USD)","BlackLine is a provider of cloud-based solutions that transform Finance and Accounting (F&A)","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/1bd0900874d4c710e4731318eb5fc208","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/3d7092e4bcbdb95f2f862a7bee3e5f99","Therese Tucker & Owen Ryan",""
"94e3c78f35c7cf07","indeed","https://www.indeed.com/viewjob?jk=94e3c78f35c7cf07","http://www.indeed.com/job/big-data-engineer-gcp-w2-94e3c78f35c7cf07","Big Data Engineer with GCP (W2)","Aptivacorp","Sunnyvale, CA, US","fulltime, contract","2024-10-05","direct_data","hourly",60.0,62.0,"USD",False,"","","","","","**Position: Data Engineer**  
**Location: Sunnyvale, CA / Bentonville, AR (onsite)**

**Duration: 12+ Months**

**Must Have Skills:**

* Hadoop
* Spark
* Scala
* GCP
* ETL Process / Data Pipeline experience

**Responsibilities:**

* As a Senior Data Engineer, you will
* Design and develop big data applications using the latest open source technologies.
* Desired working in offshore model and Managed outcome
* Develop logical and physical data models for big data platforms.
* Automate workflows using Apache Airflow.
* Create data pipelines using Apache Hive, Apache Spark, Apache Kafka.
* Provide ongoing maintenanc e and enhancements to existing systems and participate in rotational on-call support.
* Learn our business domain and technology infrastructure quickly and share your knowledge freely and actively with others in the team.
* Mentor junior engineers on the team
* Lead daily standups and design reviews
* Groom and prioritize backlog using JIRA
* Act as the point of contact for your assigned business domain

**Requirements:**

* GCP Experience
* Recent GCP experience
* Experience building data pipelines in GCP
* GCP Dataproc, GCS & BIGQuery experience
* 5+ years of hands-on experience with developing data warehouse solutions and data products.
* 5+ years of hands-on experience developing a distributed data processing platform with Hadoop, Hive or Spark, Airflow or a workflow orchestration solution are required
* 2+ years of hands-on experience in modeling and designing schema for data lakes or for RDBMS platforms.
* Experience with programming languages: Python, Java, Scala, etc.
* Experience with scripting languages: Perl, Shell, etc.
* Practice working with, processing, and managing large data sets (multi TB/PB scale).
* Exposure to test driven development and automated testing frameworks.
* Background in Scrum/Agile development methodologies.
* Capable of delivering on multiple competing priorities with little supervision.
* Excellent verbal and written communication skills.
* Bachelor's Degree in computer science or equivalent experience.

The most successful candidates will also have experience in the following:

* Gitflow
* Atlassian products – BitBucket, JIRA, Confluence etc.
* Continuous Integration tools such as Bamboo, Jenkins, or TFS

**Thanks & Regards…**

**Venugopal**

**Phone: +1 (703) 263-5081 (Please text if not reachable)**

Job Types: Full-time, Contract

Pay: $60.00 - $62.00 per hour

Expected hours: 40 per week

Schedule:

* 8 hour shift
* Day shift

Work Location: In person","https://www.indeed.com/cmp/Aptivacorp-3","","","","","","","","",""
"e2724217e02dd8f8","indeed","https://www.indeed.com/viewjob?jk=e2724217e02dd8f8","https://wd1.myworkdaysite.com/en-US/recruiting/ssctech/SSCTechnologies/job/San-Francisco-CA/Senior-Data-Engineer_R28190","Senior Data Engineer","SS&C","San Francisco, CA, US","fulltime","2024-10-04","direct_data","yearly",186846.0,200000.0,"USD",False,"","","Banks And Financial Services","","tratliff@sscinc.com","SS&C is a global provider of investment and financial services and software for the financial services and healthcare industries. Named to Fortune 1000 list as top U.S. company based on revenue, SS&C is headquartered in Windsor, Connecticut and has 20,000+ employees in over 90 offices in 35 countries. Some 18,000 financial services and healthcare organizations, from the world's largest institutions to local firms, manage and account for their investments using SS&C's products and services.
Job Description
Senior Data Engineer (San Francisco, CA; SS&C Technologies, Inc.): The Senior Data Engineer is based at SS&C’s office in San Francisco, California with a hybrid telecommuting benefit. The incumbent must reside within commuting distance from SS&C’s San Francisco office. The Senior Data Engineer is a member of a team responsible for creating a leading cloud platform with the latest big data, cloud native and machine learning technologies; building and implementing models in a production environment for a revenue-driving products; creating and maintaining overall optimal data pipeline architecture, assembling large, complex data sets that meet functional/non-functional business requirements; managing data migrations/conversions and troubleshooting data processing issues; creating the pipeline for optimal extraction, transformation, and loading (ETL) of data from a wide variety of data sources; building machine learning functions to help with data automation, data preparation; working closely with our analytics engineer and data warehouse engineers to build analytics tools and dashboards that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics; creating data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader; working with data and analytics experts to strive for greater functionality in our data system; and discovering more innovative machine learning solutions that can drive business values. Salary: $186,846 - $200,000 per year.
Minimum requirements: Master’s degree or equivalent in Computer Science, Information Systems, Information Technology Management, or related field.
Alternate Education and Experience: Bachelor’s degree or equivalent in Computer Science, Information Systems, Information Technology Management, or related field plus 5 years of experience in any occupation in which the required experience is gained.
Must have: Proven ability getting data through API with one of the following: Python, Node.js, Java, C#, Scala, etc. Proven ability with big data platform. Proficient coding skills and strong algorithm and data structure basis. Knowledge of at least one of the tools: Hadoop, Spark, Presto, Hive, or Airflow. Proven ability in transforming data, developing data structures, building a metadata store, setting up data pipelines or data workflows. Proven ability in software engineering best practices with git and version control systems. Solid communication skills in explaining complex data pipelines to both technical and non-technical audiences. Excellent writing and documenting skills.
Apply online at https://www.ssctech.com/about-us/careers or send resume to: Tiffany Ratliff, Talent Acquisition, SS&C Technologies, Inc., tratliff@sscinc.com. Ref: 00057576. An EOE.
#LI-DNI
#IND123
Unless explicitly requested or approached by SS&C Technologies, Inc. or any of its affiliated companies, the company will not accept unsolicited resumes from headhunters, recruitment agencies, or fee-based recruitment services. SS&C offers excellent benefits including health, dental, 401k plan, tuition and professional development reimbursement plan. SS&C Technologies is an Equal Employment Opportunity employer and does not discriminate against any applicant for employment or employee on the basis of race, color, religious creed, gender, age, marital status, sexual orientation, national origin, disability, veteran status or any other classification protected by applicable discrimination laws.
Salary is determined by various factors including, but not limited to, relevant work experience, job related knowledge, skills, abilities, business needs, and geographic regions.
California: Salary range for the position: 186,846.00 USD to 200,000.00 USD.","https://www.indeed.com/cmp/Ss&C","https://www.ssctech.com/","Corporate Headquarters
80 Lamberton Road
Windsor, CT 06095
","10,000+","$5B to $10B (USD)","","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/bc920c7689abf01ecfa6a81f5d36d78d","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/5473d198e533d81f58b5221290784678","William Stone","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/2dd540ecbb60c8d61ecb87fff186d2c2"
"b7a9eb4611cd3256","indeed","https://www.indeed.com/viewjob?jk=b7a9eb4611cd3256","http://www.indeed.com/job/data-engineer-b7a9eb4611cd3256","Data Engineer","Rapideagle ","South San Francisco, CA, US","contract","2024-10-02","direct_data","hourly",70.0,80.0,"USD",False,"","","","","","**Job Summary**  
We are seeking a skilled Data Engineer to join our dynamic team. The ideal candidate will be responsible for designing, building, and maintaining data pipelines that facilitate the collection and processing of large datasets. This role requires a strong understanding of data warehousing concepts, analytics, and cloud technologies. The Data Engineer will collaborate with cross-functional teams to ensure data is accessible, reliable, and actionable for business intelligence initiatives.

**Duties**  
- Develop and maintain robust data pipelines using tools such as Informatica and AWS.  
- Design and implement data warehouse solutions to support analytics and reporting needs.  
- Collaborate with data scientists and analysts to understand data requirements and deliver high-quality datasets.  
- Utilize Apache Hive for querying large datasets and optimizing performance.  
- Write efficient Shell Scripts for automation of data processing tasks.  
- Participate in Agile development processes to ensure timely delivery of projects.  
- Monitor data quality and troubleshoot issues as they arise.  
- Stay updated on industry trends and emerging technologies to continuously improve data engineering practices.

**Experience**  
- Proven experience in data engineering or related field with a strong focus on building scalable data solutions.  
- Proficiency in using AWS services for data storage and processing.  
- Familiarity with Agile methodologies and collaborative project management practices.  
- Experience with analytics tools to derive insights from complex datasets.  
- Knowledge of database management systems and data modeling techniques.  
- Strong problem-solving skills with the ability to vaticinate future trends based on current data patterns.  
- Excellent communication skills to effectively collaborate with technical and non-technical stakeholders.

Join our team as a Data Engineer where you can leverage your skills in a fast-paced environment while contributing to impactful projects that drive business success.

Job Type: Contract

Pay: $70.00 - $80.00 per hour

Expected hours: 40 per week

Benefits:

* Dental insurance
* Health insurance
* Paid time off
* Vision insurance

Schedule:

* 8 hour shift

Work Location: In person","https://www.indeed.com/cmp/Rapideagle","","","","","","","","",""
"c0ec4b6f42086214","indeed","https://www.indeed.com/viewjob?jk=c0ec4b6f42086214","https://careers.hingehealth.com/jobs/1688/job?utm_source=indeed_integration&iis=Job%20Board&iisn=Indeed&indeed-apply-token=73a2d2b2a8d6d5c0a62696875eaebd669103652d3f0c2cd5445d3e66b1592b0f","Senior Data Engineer","Hinge Health","San Francisco, CA, US","fulltime","2024-10-01","direct_data","yearly",162800.0,244200.0,"USD",True,"","","","","","Overview:
**About the Role**
Data Engineers at Hinge Health are software engineers with expertise in data pipelines, OLTP & data warehouse schema design, data governance, ETL, RDBMS and NoSQL systems. Data Engineers are hands-on, building self-service tools and automation that enable application engineers and data analysts to manage, maintain, and secure their data systems with autonomy while adhering to best practices in a HIPAA environment. The ideal candidate thrives in a highly collaborative, cross functional environment. **What You'll Accomplish*** Create compliance strategies (HIPAA, GDPR, CCPA), tooling, processes, and coaching that enables service and application teams to take full ownership of their data in a growing organization
* Architect and build data pipelines and data aggregation systems to deliver quality real-time and batch analytical reports
* Participate in hiring and mentoring of team members
* Assist and coach teams to optimize poorly performing data pipelines
* Work with the SRE team to establish best practices around database monitoring, alerting, and availability

**Hinge Health Hybrid Model**
We believe that remote work and in-person work have their own advantages and disadvantages, and we want to be able to leverage the best of both worlds. Employees in hybrid roles are required to be in the office 3 days/week.
Qualificatons:
**Basic Qualifications*** 5+ years of experience in processing and storing large scale data using distributed systems as well as a mastery of database designs and data warehousing
* 4+ years of experience working with broad spectrum of data stores like PostgreSQL, MySQL, MongoDB, Redis, Snowflake and Redshift
* 4+ years of experience building data pipelines using Spark, Kafka, Airflow
* 6+ years of software engineering experience and 4+ in data engineering

**Preferred Qualifications*** Bachelor’s Degree in Computer Science or related technical degree
* Mastery of SQL and Python

**Compensation**
This position will have an annual salary, plus equity and benefits. Please note the annual salary range is a guideline, and individual total compensation will vary based on factors such as qualifications, skill level, competencies, and work location. The annual salary range for this position is $162,800 - $244,200.
Company Information:
**About Hinge Health**
Hinge Health is moving people beyond pain by transforming the way it is treated and prevented. Connecting people digitally and in-person with expert clinical care, we combine advanced technology, AI and a care team of experts to guide people through personalized care directly from their phone. Our approach is proven to reduce pain by 68%, prevent 42% of new opioid prescriptions, and avoid more than half of joint replacement surgeries. Available to 18M people, Hinge Health is trusted by leading health plans and employers, including Land O’Lakes, L.L. Bean, Salesforce, Self-Insured Schools of California, Southern Company, City of Boston, US Foods, and Verizon. Learn more at http://www.hingehealth.com**What You'll Love About Us*** Inclusive healthcare and benefits: On top of comprehensive medical, dental, and vision coverage, we offer employees and their family members help with gender-affirming care, tools for family and fertility planning, and travel reimbursements if healthcare isn’t available where you live.
* Planning for the future: Start saving for the future with our traditional or Roth 401k retirement plan options which include a 2% company match.
* Modern life stipends: Manage your own learning and development

**Diversity and Inclusion**
We’re committed to building diverse teams that reflect the communities we serve. Visit hingehealth.com/diversity-equity-and-inclusion to learn more about what moves us.
Hinge Health is an equal opportunity employer and prohibits discrimination and harassment of any kind. We make employment decisions without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, age, veteran status, disability status, pregnancy, or any other basis protected by federal, state or local law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements.
We provide reasonable accommodations for candidates with disabilities. If you feel you need assistance or an accommodation due to a disability, let us know by reaching out to your recruiter.","https://www.indeed.com/cmp/Hinge-Health","http://www.hingehealth.com","San Francisco, CA","1,001 to 5,000","Decline to state","Hinge Health is the #1 digital clinic for joint and muscle pain.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/3ed529a20b4eb58ec4589ccd16e77097","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/cc706b437520ce5c584e2231952cc958","Daniel Perez","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/4ee9e82683a258d4db4924fa4a5cd58d"
"2be136a1e83ae5fb","indeed","https://www.indeed.com/viewjob?jk=2be136a1e83ae5fb","https://www.tesla.com/careers/search/job/internship-data-engineer-fleet-analytics-winter-spring-2025-225121","Internship, Data Engineer, Fleet Analytics (Winter/Spring 2025)","Tesla","Palo Alto, CA, US","internship","2024-10-01","direct_data","hourly",32.0,45.0,"USD",False,"","","Industrial Manufacturing","","","**Job Category** Vehicle Software  

**Location** PALO ALTO, California  

**Req. ID** 225121  

**Job Type** Intern/Apprentice  




Tesla participates in the E-Verify Program
What to Expect
Consider before applying: This position is expected to start in January and continue through April/May. Internships are in-person for 40 hours a week for a minimum of 12 weeks. Please consider before submitting an application.
International Students: If your work authorization is through CPT, please consult your school before applying. You must be able to work 40 hours per week. Many students will be limited to part-time depending on their academic standing.
The Internship Recruiting Team is driven by the passion to recognize emerging talent. Our year-round program places the best students in positions that they will grow both technically and personally through their experience working closely with their Manager, Mentor, and team. We are dedicated to providing an experience that allows for the intern to experience life at Tesla by giving them ownership over projects that are critical to their team’s success.
About the Team
Data is deeply embedded in the product and engineering culture at Tesla. We rely on data – lots of it – to improve autopilot, to optimize hardware designs, to proactively detect faults, and to optimize load on the electrical grid. We collect data from each of our cars, Superchargers, and energy storage devices to make these products better and our customers safer.  

The Fleet Analytics team is a central team that helps many teams leverage the data we collect. We help engineers through direct support by doing data analysis for them and through applications and tools so they can self-serve those analyses in the future. To do so, we leverage our internal data platform built on top of AWS, S3, Spark, Trino using open source data science tools such as Jupyter notebooks, Pandas, Bokeh, Superset, and Airflow. Our work has a direct impact on Tesla's product, and enables the work of hundreds of engineers across disciplines throughout the company.  

What You’ll Do* Work with stakeholders to take a vague problem statement, refine the scope of the analysis, and use the results to drive informed decisions
* Write reproducible data analysis over petabytes of data using cutting-edge open source technologies
* Summarize and clearly communicate data analysis assumptions and results
* Build data pipelines to promote your ad-hoc data analyses into production dashboards that engineers can rely on
* Design and implement metrics, applications and tools that will enable engineers by allowing them to self-serve their data insights
* Work with engineers to drive usage of your applications and tools
* Write clean and tested code that can be maintained and extended by other software engineers

What You’ll Bring* Strong proficiency in Python, SQL
* Able to understand electrical systems
* Strong foundation in statistics
* Experience building data visualizations
* Experience writing software in a professional environment
* Strong verbal and written communication skills
* Strong problem-solving skills to help refine problem statements and figure out how to solve them with the available data
* Experience with data science tools such as Pandas, Numpy, R, Matlab, Octave is a plus
* Experience building data pipelines and web applications is nice to have

Compensation and Benefits
Benefits  

As a full-time Tesla Intern, you will be eligible for:
* Aetna PPO and HSA plans > 2 medical plan options with $0 payroll deduction
* Family-building, fertility, adoption and surrogacy benefits
* Dental (including orthodontic coverage) and vision plans. Both have an option with a $0 payroll contribution
* Company Paid (Health Savings Account) HSA Contribution when enrolled in the High Deductible Medical Plan with HSA
* Healthcare and Dependent Care Flexible Spending Accounts (FSA)
* LGBTQ+ care concierge services
* 401(k), Employee Stock Purchase Plans, and other financial benefits
* Company Paid Basic Life, AD&D, and short-term disability insurance
* Employee Assistance Program
* Sick time after 90 days of employment and Paid Holidays
* Back-up childcare and parenting support resources
* Voluntary benefits to include: critical illness, hospital indemnity, accident insurance, theft & legal services, and pet insurance
* Commuter benefits
* Employee discounts and perks program
  
  

Expected Compensation  

$32.45 - $45.43 + benefits  

  

Pay offered may vary depending on multiple individualized factors, including market location, job-related knowledge, skills, and experience. The total compensation package for this position may also include other elements dependent on the position offered. Details of participation in these benefit plans will be provided if an employee receives an offer of employment.  

Tesla is an Equal Opportunity / Affirmative Action employer committed to diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, age, national origin, disability, protected veteran status, gender identity or any other factor protected by applicable federal, state or local laws.
Tesla is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.","https://www.indeed.com/cmp/Tesla","https://www.tesla.com","1 Tesla Road Austin, TX 78725","10,000+","$5B to $10B (USD)","Tesla is accelerating the world’s transition to sustainable energy.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/5e42be6c7dd264b60310b59afb8a3c48","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/0dd52e4838b7fbaad47cb480680a00d3","Elon Musk","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/0fc450600a0b471e811e0d08de5cbe98"
"428ef5e51bed3d57","indeed","https://www.indeed.com/viewjob?jk=428ef5e51bed3d57","https://jobs.ashbyhq.com/coastal-carbon/19c4ece2-dc64-4ed4-82a5-cd6b8f226e40?utm_source=n7N06Eaxo3","Data Engineer","Coastal Carbon","San Francisco, CA, US","fulltime","2024-10-01","direct_data","yearly",138527.0,175407.0,"USD",True,"","","","","","**Who are we?**


Coastal Carbon is a seed-funded startup on a mission to create positive impact through earth observation and AI. Founded at the University of Waterloo by a team of PhDs and engineers, we’re backed by some of the best AI and climate tech investors like HF0, Inovia Capital and Propeller Ventures, angels like James Tamplin (cofounder Firebase) and Sid Gorham (cofounder OpenTable, Granular), and partners like Amazon AWS and the United Nations.


**What do we do?**


We’re building multimodal foundation models for the natural world. We believe there’s more to the world than the internet + more to intelligence than memorizing the internet. Our models are trained on satellite remote sensing and real world ground truth data, and are used by our customers in nature conservation, carbon dioxide removal, and government to protect and positively impact our increasingly changing world. Our ultimate goal is to build AGI of the natural world.

**About the role**


We are seeking a Data Engineer to join our team and help us build out a digital twin of the natural world. The successful candidate will be responsible for supporting the design, building, monitoring, and maintenance of the underlying database and related tooling.

**The role will involve:**

* Developing and maintaining AWS infrastructure to support a multi-Petabyte database
* Supporting upstream data pipeline design and implementation
* Heavy focus on scalability and optimization for performance
* Creating downstream applications to support machine learning and visualization

**Requirements**

* Bachelor’s degree in engineering, computer science or a related field, or equivalent
* 5+ years of relevant experience
* Fluency with SQL programming
* Proficiency in Python
* Aptitude in parallel processing
* Demonstrated experience with managing, ingesting, and transforming geospatial data
* Knowledge of Earth observations and methods including satellite remote sensing and weather reanalysis data
* Familiarity with object store databases like Redshift/Snowflake
* Experience building data pipelines and tooling to support downstream applications
* Team player, willing to undertake various tasks to support our collective goals

**Nice to have**

* Proficiency in PyTorch or Tensorflow (with interest in learning PyTorch)
* Knowledge of AWS networking and security protocols
* Experience with containerization and orchestration technologies such as Docker, AirFlow, and/or Kubernetes.
* Location wise, strong preference for in-person in Waterloo, however hybrid work is possible for exceptional candidates.","https://www.indeed.com/cmp/Coastal-Carbon","","","","","","","","",""
"abcf817fe6c6981b","indeed","https://www.indeed.com/viewjob?jk=abcf817fe6c6981b","https://inabia.applytojob.com/apply/hMXqOAqToK/Data-Engineer?source=INDE&~","Data Engineer","Inabia Software & Consulting Inc.","Sunnyvale, CA, US","contract","2024-09-30","direct_data","yearly",122858.0,155565.0,"USD",False,"","","","","","**Client looking for 8+ Years of experience.**  

  

**Title: Data Engineer**  

**Duration: Contract**  

**Location: Sunnyvale, CA (Onsite)**  

**\\*Locals Required\\***  

  

**Job Description :**  

**Mandatory Areas**  

* Hadoop- 8+ Yrs of Exp
* Spark - 8+ Yrs of Exp-
* Scala - 8+ Yrs of Exp
* GCP - 5+ Yrs of Exp
* ETL Process / Data Pipeline experience –8+ Yrs of Exp –

**Responsibilities:**  

**As a Senior Data Engineer, you will**  

* Design and develop big data applications using the latest open source technologies.
* Desired working in offshore model and Managed outcome
* Develop logical and physical data models for big data platforms.
* Automate workflows using Apache Airflow.
* Create data pipelines using Apache Hive, Apache Spark, Apache Kafka.
* Provide ongoing maintenance and enhancements to existing systems and participate in rotational on-call support.
* Learn our business domain and technology infrastructure quickly and share your knowledge freely and actively with others in the team.
* Mentor junior engineers on the team
* Lead daily standups and design reviews
* Groom and prioritize backlog using JIRA
* Act as the point of contact for your assigned business domain

  

**Requirements:**  

**GCP Experience**  

* 2+ years of recent GCP experience
* Experience building data pipelines in GCP
* GCP Dataproc, GCS & BIGQuery experience

  

* 5+ years of hands-on experience with developing data warehouse solutions and data products.
* 5+ years of hands-on experience developing a distributed data processing platform with Hadoop, Hive or Spark, Airflow or a workflow orchestration solution are required
* 2+ years of hands-on experience in modeling and designing schema for data lakes or for RDBMS platforms.
* Experience with programming languages: Python, Java, Scala, etc.
* Experience with scripting languages: Perl, Shell, etc.
* Practice working with, processing, and managing large data sets (multi TB/PB scale).
* Exposure to test driven development and automated testing frameworks.
* Background in Scrum/Agile development methodologies.
* Capable of delivering on multiple competing priorities with little supervision.
* Excellent verbal and written communication skills.
* Bachelor's Degree in computer science or equivalent experience.


The most successful candidates will also have experience in the following:  

* Gitflow
* Atlassian products – BitBucket, JIRA, Confluence etc.
* Continuous Integration tools such as Bamboo, Jenkins, or TFS

  




hMXqOAqToK","https://www.indeed.com/cmp/Inabia-Software-&-Consulting-Inc.","https://www.inabia.com","Redmond","11 to 50","$1M to $5M (USD)","","","","",""
"af27c228504a7bfe","indeed","https://www.indeed.com/viewjob?jk=af27c228504a7bfe","https://click.appcast.io/track/kp736wf-org?cs=hqw","Technical Product Manager","NVIDIA","Santa Clara, CA, US","fulltime","2024-09-27","direct_data","yearly",204000.0,310500.0,"USD",False,"","","","","","NVIDIA has become the platform upon which every new AI-powered application is built. From big, challenging Generative AI applications to autonomous vehicles, or voice-recognition systems, the need for advanced perception and cognitive capabilities is exploding and NVIDIA is right in the center of this revolution. GPU computing is the most productive and pervasive platform for deep learning and AI. It begins with the most advanced GPUs and the systems and software we build on top of them. We integrate and optimize every deep learning framework. We work with the major systems companies and every major cloud service provider to make GPUs available in data centers and in the cloud, and we create computers and software to bring AI to edge devices, such as self-driving cars and autonomous robots.


We are currently seeking a dynamic individual to join our team as an DGX Technical Product Manager who can move and adapt quickly to changing needs.

**What You’ll Be Doing:**
-------------------------

* Translate high level customer and application needs into detailed technical requirements for product capabilities around storage and network acceleration
* Define the go-to-market strategy and contribute to the cross-functional implementation of the plan across Marketing, PR, Sales, etc.
* Collaborate with DGX partner ecosystem to create an integrated solution blueprint.
* Work with engineering and core infrastructure teams on technical architecture, API design, usage dashboards, security and enterprise readiness.
* Work with customers to collect technical feedback and use it to drive future roadmap Partner with Technical Marketing teams on demos and product marketing teams on product positioning and messaging.
* Perform technical competitive analysis of other offerings in the market.

**What We Need To See:**
------------------------

* Bachelor’s Degree in a quantitative field (e.g., Applied Math, Computational Science, Computer Science, Machine Learning, etc.) or equivalent experience
* 12 + years of proven experience as a technical product manager, data scientist, data engineer, machine learning engineer, or similar role
* Hands on work with data science or deep learning with emphasis on data movement, and network interaction
* Analytical approach and ability to synthesize user research, engineering feasibility, and market trends into product strategy
* Outstanding interpersonal skills with a validated ability to articulate a value proposition to technical and non-technical audiences.
* Expertise in deploying enterprise solutions and use of cloud-native technologies on public cloud infrastructure (Docker containers, Kubernetes, service-oriented architecture).
* Ability to manage concurrent projects and priorities in a dynamic environment.

**Ways To Stand Out From The Crowd:**
-------------------------------------

* Hands on experience in system administration, networking and/or storage technologies.
* Experience collaborating with and contributing to open-source projects.
* Strong programming skills and familiarity with CUDA and GPU fundamentals.


NVIDIA is widely considered to be one of the technology world’s most desirable employers. We have some of the most brilliant, forward-thinking and hardworking people in the world working for us. There has never been a more exciting time to join!


The base salary range is 204,000 USD - 310,500 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.
You will also be eligible for equity and benefits. *NVIDIA accepts applications on an ongoing basis.*

NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.","https://www.indeed.com/cmp/Nvidia","http://www.nvidia.com","Santa Clara, CA","10,000+","$5B to $10B (USD)","Bringing superhuman capabilities to some of the world's toughest problems.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/9cda2ebf26905efa812e1a5315c7a53d","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/06eb3cf17b12479594aa62ea9119efa4","Jensen Huang","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/27e1ae2d4916c24beeaf3726c199a564"
"0b001d127a3347f3","indeed","https://www.indeed.com/viewjob?jk=0b001d127a3347f3","https://grnh.se/0c0706a72us","Principal Data Engineer","SmithRx","San Francisco, CA, US","","2024-09-26","direct_data","yearly",197139.0,249621.0,"USD",True,"","","","","","**Who We Are:**



SmithRx is a rapidly growing, venture-backed Health-Tech company. Our mission is to disrupt the expensive and inefficient Pharmacy Benefit Management (PBM) sector by building a next-generation drug acquisition platform driven by cutting edge technology, innovative cost saving tools, and best-in-class customer service. With hundreds of thousands of members onboarded since 2016, SmithRx has a solution that is resonating with clients all across the country.



We pride ourselves for our mission-driven and collaborative culture that inspires our employees to do their best work. We believe that the U.S healthcare system is in need of transformation, and we come to work each day dedicated to making that change a reality. At our core, we are guided by our company values:


* **Integrity:** Always operate with honesty and transparency so we earn the trust of our clients.
* **Courage:** Demonstrate the courage needed to take on a broken industry and continuously improve what we offer to optimize health outcomes.
* **Together:** Foster a collaborative and inclusive environment that values teamwork, respect, and open communication, and encourages creativity and diversity of thought.


**Job Summary:**



SmithRx is leading the transformation of pharmacy benefit management (PBM) with a cutting-edge platform that delivers real-time insights, cost efficiencies, and exceptional customer experiences. As we continue to expand, we are seeking an experienced Principal Data Engineer with expertise in data engineering and AI/ML. In this key role, you will take ownership of driving innovation and leading the technology strategy for modern data platforms across data warehouse, tooling, integrations, and AI/ML. You will collaborate with cross-functional leaders to deliver impactful data solutions that directly influence our business outcomes.


**What you will do:**


* Lead the design and development of robust data architectures that support scalable, secure, and efficient data pipelines.
* Architect, develop an enterprise data warehouse (EDW) and tooling that encompasses design patterns to scale and expand through integrations and automation of ETL/ELT pipelines as well as analytic layer to scale reporting and insights.
* Develop strategies across the entire AI/ML project lifecycle. This includes seamless integration with data platforms, spanning from problem definition and data preparation to model deployment and performance monitoring.
* Drive innovation by evaluating and implementing new technologies and tools that enhance our data platform's capabilities.
* Drive excellence and standardization e.g. Optimize the performance of database systems, ensuring best practices in data security, access control, and compliance.
* Ensure data quality, lineage, and resilience across production environments including monitoring, alerting, and recovery mechanisms to ensure 99% uptime and quick resolution of data pipeline issues.
* Provide technical leadership, mentoring, and guidance to team members, establishing and enforcing best practices in data engineering and data science.
* Influence and Collaborate with cross-functional teams & leadership, including product managers, engineers, data analysts, and business stakeholders
  


**What you will bring to SmithRx:**


* BS, MS, or PhD in Computer Science, Information Systems, or a related field, with 15+ years of experience in data engineering, data science, or a similar role.
* Strong expertise in data architecture, database design, and optimization, with experience in OLTP, OLAP, NoSQL, and cloud-based data warehouses (e.g., AWS Snowflake, PostgresDB, DymanoDB, etc ).
* Proficiency in programming languages such as Python, SQL, and tools like Spark, PySpark, Airflow, DBT, Snowflake, Cortext, OpenAI, and Terraform.
* Proven experience architecting and designing AI/ML initiatives with a deep understanding of AI/ML algorithms and frameworks. Nice to have - experience in developing and deploying ML models in production
* Ability to lead cross-functional teams, influence stakeholders, and manage complex projects in a fast-paced environment.
* Strong analytical and problem-solving skills, with the ability to handle evolving requirements and ambiguous challenges.
* Excellent communication and presentation skills, capable of conveying complex technical concepts to both technical and non-technical audiences.


**What SmithRx Offers You:**


* Highly competitive wellness benefits including Medical, Pharmacy, Dental, Vision, and Life Insurance and AD&D Insurance
* Flexible Spending Benefits
* 401(k) Retirement Savings Program
* Short-term and long-term disability
* Discretionary Paid Time Off
* 12 Paid Holidays
* Wellness Benefits
* Commuter Benefits
* Paid Parental Leave benefits
* Employee Assistance Program (EAP)
* Well-stocked kitchen in office locations
* Professional development and training opportunities","https://www.indeed.com/cmp/Smithrx-1","https://www.smithrx.com","San Francisco, CA, Lehi, UT and Plano, TX","201 to 500","","SmithRx is working to reduce pharmacy costs by reimagining the traditional PBM as a Drug Acquisition Platform built on transparent modern technology that aligns with the needs of our customers.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/5e8e82d7d01537c3838ab10bdd0bde5d","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/e0dfdf804821423432aae7bb49298f4e","Jake Frenz","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/8687beb6eccfda3ebe7892e61032c1ee"
"3c26c8f9185fa7c4","indeed","https://www.indeed.com/viewjob?jk=3c26c8f9185fa7c4","http://www.indeed.com/job/big-data-lead-engineer-3c26c8f9185fa7c4","Big Data Lead Engineer","Laiba Technologies","Santa Clara, CA, US","contract","2024-09-26","direct_data","hourly",65.0,68.0,"USD",False,"","","","","","**Role : Big Data Lead Engineer** 

**Location : Santa Clara, CA (Onsite role)**

1) 6+ years of experience in design and implementation in an environment with hundreds of terabytes of data

2) 6+ years of experience with large data processing tools such as: Dataflow, GKE, BQ, Beam

3) 6+ years of experience with Java

* As a Principal Big Data Engineer, you will be an integral member of our data ingestion and processing platform team responsible for architecture, design and development.
* Having the dynamic ability to adapt to conventional big-data frameworks and tools with the use-cases required by the project
* Ability to communicate with research and development teams and data scientists, finding bottlenecks and resolving them Design and implement different architectural models for our scalable data processing, as well as scalable data storage Build tools for proper data ingestion from multiple heterogeneous sources .

Job Type: Contract

Pay: $65.00 - $68.00 per hour

Experience:

* Big data: 6 years (Required)
* Java: 6 years (Required)

Work Location: In person","https://www.indeed.com/cmp/Laiba-Technologies-2","","","","","","","","",""
"892144b17da4563a","indeed","https://www.indeed.com/viewjob?jk=892144b17da4563a","https://grnh.se/e4798fcc1us","Senior Data Engineer - Platform Engineering","Crunchyroll","San Francisco Bay Area, CA, US","","2024-09-25","direct_data","yearly",185440.0,231800.0,"USD",True,"","","","","","**About Crunchyroll**
---------------------



WE HELP EVERYONE BELONG. IT'S OUR PURPOSE.



Founded by fans, Crunchyroll delivers the art and culture of anime to a passionate community. We super-serve over 100 million anime and manga fans across 200+ countries and territories, and help them connect with the stories and characters they crave. Whether that experience is online or in-person, streaming video, theatrical, games, merchandise, events and more, it's powered by the anime content we all love.



Join our team, and help us shape the future of anime!

### **Who We Are**



We're a cast of characters working to shine a spotlight on anime. Crunchyroll is an international business focused on creating both online and offline experiences for fans through content (licensed, co-produced, originals, distribution), merchandise, events, gaming, news, and more. Visit our About Us pages for more information about our collection of brands.


**About the Team**



The Data Services team is focused on building robust, scalable, and efficient data services, pipelines, lakes, tools, libraries, and software components that drive best practices and empower service teams to succeed. We design and implement data services, pipelines and data lakes for operational analysis, ensuring they are production-ready with automation and standardized access controls.



We lead and evangelize the principle of 100% automation. Additionally, we establish best practices, provide training, and document data architectures to ensure our systems are reliable, future-ready, and capable of continuous evolution and process improvement across the organization.


### **About The Role**



Crunchyroll is growing and changing, presenting unique challenges and opportunities to support millions of anime fans around the world. The Data Engineering team provides seamless help to our internal stakeholders, ensuring an exceptional experience for all Crunchyroll fans.



As a Senior Data Engineer, you will play a pivotal role in designing, implementing, and optimizing data services and pipelines, ensuring that our data services support the needs of the business. You will collaborate with cross-functional teams to enable operational data analysis, enhance eventing systems, and develop tools that empower our data and services teams. Your expertise will also be critical in driving 100% automation, best practices, creating scalable architectures, and optimizing our data environments.This role is eligible for fully remote and will report into our Director of Data Engineering - Platform Engineering.


### **About You**



* Bachelor's degree in Computer Science, Information Technology, or a related field.
* 8+ years of experience in data engineering, with a focus on building and optimizing data pipelines, data architecture, and eventing systems.
* Extensive experience with AWS cloud platform and their data-related services.
* Proficiency in automation frameworks (e.g., Terraform, Cloud Formation).
* Proficiency in data lake and pipeline tools and frameworks (e.g., Databricks, Apache Kafka/Kinesis, AWS Glue).
* Proficiency in one or more programming languages (e.g. Python, Java)
* Strong understanding of SQL (e.g. Redshift, Snowflake, RDS) and NoSQL databases (e.g., DynamoDB) and experience in enabling analytical queries on these platforms.
* Experience with search optimization, including schema design and query tuning.
* Experience in building CI/CD pipelines, testing frameworks (e.g. dbt), and best practices in data engineering.
* Strong problem-solving skills and a proactive approach to identifying and addressing issues.
* Ability to independently own and execute projects while effectively collaborating with the team to influence and shape the vision of the data engineering organization.
* Strong communication skills and the ability to mentor and guide junior engineers.
**Why you will love working at Crunchyroll**
--------------------------------------------



Not only will you get to work with fun, passionate and inspired colleagues, you will also...



* Receive a great compensation package including salary plus performance bonus earning potential, paid annually.
* Enjoy flexible PTO and time off policies allowing you to take the time you need to be your whole self.
* Appreciate the generous medical, dental, vision, STD, LTD, and life insurance options for you and your family.
* Take advantage of our health saving account HSA program plus health care and dependent care FSA programs.
* Love that we offer an employer match on our 401(k) plan.
* Receive employer paid commuter benefit (for eligible employees)
* Appreciate the generous support program for new parents
* Obtain pet insurance and some of our offices are pet friendly!
#LifeAtCrunchyroll #LI-Remote

### **About our Values**



We want to be everything for someone rather than something for everyone and we do this by living and modeling our values in all that we do. We value


* Courage. We believe that when we overcome fear, we enable our best selves.
* Curiosity. We are curious, which is the gateway to empathy, inclusion, and understanding.
* Service. We serve our community with humility, enabling joy and belonging for others.
* Kaizen. We have a growth mindset committed to constant forward progress.

### **Our commitment to diversity and inclusion**



Our mission of helping people belong reflects our commitment to diversity & inclusion. It's just the way we do business.



We are an equal opportunity employer and value diversity at Crunchyroll. Pursuant to applicable law, we do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.



Crunchyroll, LLC is an independently operated joint venture between US-based Sony Pictures Entertainment, and Japan's Aniplex, a subsidiary of Sony Music Entertainment (Japan) Inc., both subsidiaries of Tokyo-based Sony Group Corporation.


*Questions about Crunchyroll's hiring process? Please check out our Hiring FAQs:* *https://help.crunchyroll.com/hc/en-us/articles/360040471712-Crunchyroll-Hiring-FAQs*



Please beware of recent scams to online job seekers. Those applying to our job openings will only be contacted directly from @crunchyroll.com email account.","https://www.indeed.com/cmp/Crunchyroll","https://www.crunchyroll.com","San Francisco, CA","501 to 1,000","$500M to $1B (USD)","Crunchyroll is an international business focused on creating both online and offline experiences for fans through content (licensed, co-produced, originals, distribution), merchandise, events, gaming","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/e43c4b066e9b567782b235978ab484e0","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/fdafd8d07bd8eaef90630dda4296e574","",""
"785057671a880aaf","indeed","https://www.indeed.com/viewjob?jk=785057671a880aaf","https://jsv3.recruitics.com/redirect?rx_cid=3427&rx_jobId=200555800-2&rx_url=https%3A%2F%2Fjobs.apple.com%2Fen-us%2Fdetails%2F200555800%2Fsoftware-data-engineer-analytical-engineering-apple-media-products%3Fboard_id%3DJB001%26rx_campaign%3Dindeed0%26rx_ch%3Djobp4p%26rx_group%3D130780%26rx_job%3D200555800-2%26rx_medium%3Dcpc%26rx_r%3Dnone%26rx_source%3Dindeed%26rx_ts%3D20241010T043802Z%26rx_vp%3Dcpc%26team%3DSFTWR","Software Data Engineer - Analytical Engineering - Apple Media Products","Apple","Cupertino, CA, US","fulltime","2024-09-23","direct_data","yearly",175800.0,312200.0,"USD",False,"","","","","","**Summary**  

  

Posted: Jul 23, 2024  

  

Weekly Hours: **40**  

  

Role Number:**200555800**  

  

Apple's App Store is the world's largest and most innovative app marketplace, home to over 1.5 million apps and serving more than half a billion customers every week across all the Apple devices. Since the App Store launched in 2008, it has changed how we all live; it has enabled countless new companies, spawned new industries, and built millions of jobs. But we believe we are just getting started. We're seeking a software data engineer to join the App Store Data Engineering team. In this role you will help deliver this experience and improve the store every day for both users and developers by generating insights from data in a privacy-friendly manner. We enable data-driven innovation by building solutions, services, and analytical workloads for a variety of internal collaborators and external partners. In a world where apps have become essential in people's daily lives, the App Store team has become essential to Apple's business.  

  

**Description**  

  

As a member of the App Store Data Engineering team, you will have significant responsibility and influence in shaping its strategic direction. This is a software engineering position. We write robust code, not just ad-hoc scripts. Our software process dozens of terabytes of data on daily basis. Our volumes are on a petabytes scale. Our jobs and applications must be efficient, scalable, and stable. Although we write software, data is our main product and first-class citizen. We care about accurate and qualitative data as much as we care about fine, clean, and manageable code. The data we produce power Apple leadership and partners about new innovations and the next big things. To succeed here you'll need to be a proponent of building world-class analytical solutions. To be a part of the team means we will want your ideas, concerns, and opinions in our discussions. We are highly collaborative. To join us in our next industry-leading software project you will be expected to be part of our very impactful multi-functional team. Thanks to Apple's unique integration of hardware, software, and services, engineers here partner to get behind a single unified vision. That vision always includes a deep commitment to strengthening Apple's privacy policy, one of Apple's core values. Although services are a bigger part of Apple's business than ever before, these teams remain small, forward-thinking, and multi-functional, offering greater exposure to the array of opportunities here.
* Bachelor’s Degree or equivalent experience in Computer Science or related field

  

**Preferred Qualifications**  

* 5+ years of hands-on experience building distributed data processing applications using Apache Spark or Apache Flink.
* 5+ years of programming experience in Scala (preferred) or Java.
* Experience with Big data: Hadoop, HDFS, Spark, SQL, Kafka.
* Proven skills in designing scalable, highly available distributed systems using technologies like Kafka, Iceberg, Kubernetes, Airflow and Cassandra.
* Good understanding of software engineering principles and fundamentals including algorithms and data structures.
* Self-directed, self-motivated and ability to create architecture and design documents.
* Ability to capture multi-functional requirements and translate them into practical engineering tasks.
* Excellent communication skills and proven ability to work in a multi-functional environment.
* Understanding of functional programming ideas and principles.

  

**Pay & Benefits**  


At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $175,800 and $312,200, and your base pay will depend on your skills, qualifications, experience, and location.  

  

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses - including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.  

  

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.
  

More  

* Apple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics. Learn more about your EEO rights as an applicant.","https://www.indeed.com/cmp/Apple","http://www.apple.com","Cupertino, CA","10,000+","more than $10B (USD)","This is where you can do the best work of your life.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/60c39b87a9a4eaa4df878c716840f84d","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/8c915d66415088a4c67d85ca195547dd","Tim Cook","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/263b9814b50ba62127754ec8a3710160"
"dc63db908fa7acef","indeed","https://www.indeed.com/viewjob?jk=dc63db908fa7acef","https://glownetworks.hrmdirect.com/employment/view.php?req=3139929&jbsrc=1014&location=e6debf9b-4383-237c-4415-4ba2f784f03f","Senior Data Engineer","Glow Networks","Mountain View, CA, US","","2024-09-21","direct_data","yearly",124583.0,157750.0,"USD",True,"","","","","","**Primary Skills**: Terraform, Python Spark, SQL, Databricks, Privacera


**Secondary skills**: Java/J2EE, VB.Net, C#, Python


**Scope of Work**


* The team will be working in one of the following areas:
	+ Multi-cloud data exploration
		- Terraform infrastructure-as-code for managing AWS infrastructure and deep integration between enterprise tools (Starburst, Privacera, and Databricks) and client's services (LDAP, data decryption)
		- Testing user flows for data analysis, processing, and visualization with Python Spark notebooks and SQL running on distributed compute to join data between AWS S3 and GCP BigQuery
		- Developing data pipelines in Python Spark or SQL to push structured enterprise tool telemetry to our data lake
	+ Fine-grained access control for data exploration
		- Terraform infrastructure-as-code for managing AWS infrastructure and deep integration between enterprise tools (Databricks and Privacera)
		- Evaluating Databricks capabilities to sync Hive, Glue, and Unity Catalogs
		- Evaluating Privacera capabilities or building new capabilities (AWS Lambda with Python) to sync client's access policies with Unity Catalog
		- Testing user flows for data analysis, processing, and visualization with Python Spark notebooks on distributed compute or Databricks’ serverless SQL runtime

**Responsibilities**


* Develop and implement operational capabilities, tools, and processes that enable highly available, scalable, and reliable customer experiences
* Resolve defects/bugs during QA testing, pre-production, production, and post-release patches
* Work cross-functionally with various Intuit teams including: product management, analysts, data scientists, and data infrastructure
* Work with external enterprise support engineers from Databricks, Starburst, and Privacera to resolve integration questions and issues
* Experience with Agile Development, SCRUM, or Extreme Programming methodologies


**Qualifications**


* 8+ years experience designing and developing web, software, or mobile applications.
* 3+ years experience building and operating cloud infrastructure solutions.
* BS/MS in computer science or equivalent work experience.
* Expertise with any of the following Object Oriented Languages (OOD): Java/J2EE, C#, VB.NET, Python, or sometimes C++. Java and Python preferred.
* Expertise with AWS (IAM, VPC), Spark, and Terraform are preferred. Expertise with Databricks is a strong bonus.
* Expertise with the entire Software Development Life Cycle (SDLC), including: system design, code review, unit/integration/performance testing, build and deploy automation
* Operational excellence: minimizes costs and maximizes uptime
* Excellent communication skills: demonstrated ability to explain complex technical topics in an engaging way to both technical and non-technical audiences, both written and verbally","https://www.indeed.com/cmp/Glow-Networks","","","","","","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/c9c4b530878cbdbb5117eda41749610e","","",""
"cc05669dfd347232","indeed","https://www.indeed.com/viewjob?jk=cc05669dfd347232","https://jsv3.recruitics.com/redirect?rx_cid=3427&rx_jobId=200564808-1&rx_url=https%3A%2F%2Fjobs.apple.com%2Fen-us%2Fdetails%2F200564808%2Fsr-data-engineer-icloud%3Fboard_id%3DJB001%26rx_campaign%3Dindeed0%26rx_ch%3Djobp4p%26rx_group%3D130780%26rx_job%3D200564808-1%26rx_medium%3Dcpc%26rx_r%3Dnone%26rx_source%3Dindeed%26rx_ts%3D20241010T043802Z%26rx_vp%3Dcpc%26team%3DSFTWR","Sr. Data Engineer, iCloud","Apple","Cupertino, CA, US","fulltime","2024-09-21","direct_data","yearly",175800.0,312200.0,"USD",False,"","","","","","**Summary**  

  

Posted: Aug 22, 2024  

  

Weekly Hours: **40**  

  

Role Number:**200564808**  

  

Would you like to drive the future of Apple’s products, applications, and platform while having the unique opportunity to impact some of the most far-reaching software applications in the world? iCloud Data organization enables Apple to ship better products for iCloud users to access all their content across apps (Photos, Mail, Messages, FaceTime, Calendar etc) from all of their devices all the time by providing consistent, scalable, timely, accurate, complete and fully integrated data infrastructure and capabilities to accurately surface relevant information If this excites you and you are energized by solving hard, high-leverage problems at scale, we'd love to hear from you! We’re looking for exceptional data engineers who have a strong background in distributed data processing, have great and demonstrable data intuition, and share our passion for continuously improving the ways we use data to make the Apple’s products, applications, and platform better.  

  

**Description**  

  

What you will do: \\* Engineer efficient, adaptable and scalable data pipelines to process structured and unstructured data \\* Own and evolve extremely rich datasets on iCloud products and platform interactions to power a wide variety of use cases \\* Build forward-looking data solutions that interface well with existing systems and use judgement to bring cutting edge technologies in the industry to suit iCloud needs. \\* Understand how key technical decisions will drive business outcomes and deliver/aid data frameworks and platforms that improve delivery with high-quality to those outcomes by partnering with cross functional teams. \\* Join a stunning team of data experts with diverse skill set, and deliver excellent solutions that better enable our decision-making process
* 8+ years of experience working with Spark and other distributed data technologies (e.g. Hadoop, Presto, Flink, Druid) for building efficient & large scale data pipelines.
* Highly proficient in at least one of Java, Python or Scala.
* Deep expertise in Data Principles, Data Architecture & Data Modeling, Strong SQL skills.
* Strong problem solver with meticulous attention to detail, capable of taking on loosely defined problems.
* Experience working in a complex, matrixed organization involving cross-functional, and/or cross-business projects
* Strong communication and collaboration skills & ability to lead high-level discussions on technology strategy and approach
* Conceptually familiar with AWS cloud resources (S3, EC2, RDS etc)

  

**Preferred Qualifications**  

* Experience with Cloud Computing platforms like Amazon AWS, Google Cloud.
* Experience with building stream-processing applications using Apache Flink, Spark-Streaming, Apache Storm, Kafka Streams or others.
* Experience with Search systems (such as ElasticSearch, Solr), NoSQL datastores (such as HBase, Cassandra, MongoDB).
* Experience building distributed, high-volume data services is a plus.
* MS or BS or equivalent experience in Computer Science, Engineering, Mathematics, Statistics or a related field OR equivalent practical experience in Software or Data Engineering.

  

**Pay & Benefits**  


At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $175,800 and $312,200, and your base pay will depend on your skills, qualifications, experience, and location.  

  

Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses - including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits.  

  

Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.
  

More  

* Apple is an equal opportunity employer that is committed to inclusion and diversity. We take affirmative action to ensure equal opportunity for all applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or other legally protected characteristics. Learn more about your EEO rights as an applicant.","https://www.indeed.com/cmp/Apple","http://www.apple.com","Cupertino, CA","10,000+","more than $10B (USD)","This is where you can do the best work of your life.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/60c39b87a9a4eaa4df878c716840f84d","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/8c915d66415088a4c67d85ca195547dd","Tim Cook","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/263b9814b50ba62127754ec8a3710160"
"b7a12d7347661433","indeed","https://www.indeed.com/viewjob?jk=b7a12d7347661433","https://careers.tiktok.com/position/7413849895691946278/detail","Data Engineer-Data Solution, Data Cycling Center","TikTok","San Jose, CA, US","","2024-09-20","direct_data","yearly",135000.0,270000.0,"USD",False,"","","","","","Responsibilities
  
TikTok is the leading destination for short-form mobile video. At TikTok, our mission is to inspire creativity and bring joy. TikTok's global headquarters are in Los Angeles and Singapore, and its offices include New York, London, Dublin, Paris, Berlin, Dubai, Jakarta, Seoul, and Tokyo.
  
  

Why Join Us
  
Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible.
  
Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day.
  
To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.
  
At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve.
  
Join us.
  
  

About the team
  
The success of TikTok's data business model hinges on the supply of a large volume of high quality labeled data that will grow exponentially as our business scales up. However, the current cost of data labeling is excessively high. The Data Solutions team is built to understand data strategically at scale for all Global Business Solution (GBS) business needs. Data Solutions Team uses quantitative and qualitative data to guide and uncover insights, turning our findings into real products to power exponential growth. Data Solutions Team responsibility includes infrastructure construction, recognition capabilities management, global labeling delivery management.
  
  

About the role
  
As Data Engineer, you will be working on cutting-edge challenges in the big data and AI industry which requires strong passion and capability of innovation. You will collaborate closely with cross-functional teams to understand business requirements and translate them into technical solutions.
  
  

Responsibility
  
1. Architect efficient, scalable and reliable data pipelines and infrastructure for ingesting, processing, and transforming large volumes of data;
  
2. Define the technical strategy and roadmap for data engineering projects in alignment with business objectives, actively evaluate and bring in industry best practices and state-of-the-art technical approaches, and timely update the strategy according to the rapid change of the industry;
  
3. Own and drive data engineering projects by leveraging both internal and cross-functional resources, setting meaningful and challenging targets, and achieving them with innovative approaches;
  
Qualifications
  
  

**Minimum Qualifications:**  

1. Bachelor's or Master's degree in Computer Science, Engineering, or related field;
  
2. Experience in data engineering, with demonstrated expertise in building scalable data pipelines and infrastructure;
  
3. Proficiency in programming languages such as Python, SQL, and Java;
  
4. Experience with big data technologies such as Apache Spark, Hadoop, and Kafka.
  
  

**Preferred Qualifications:**  

1. Strong understanding of database systems, data warehousing, and distributed computing concepts;
  
2. Excellent communication, and interpersonal skills.
  
  

TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at https://shorturl.at/cdpT2
  
Job Information
  
The base salary range for this position in the selected city is $135000 - $270000 annually.
  
  

​
  
  

Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.
  
  

​
  
  

Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees:
  
  

​
  
  

We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.
  
  

​
  
  

**Our time off and leave plans are:** 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.
  
  

​
  
  

We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.
  
  

​
  
  

**For Los Angeles County (unincorporated) Candidates:**  

​
  
  

Qualified applicants with arrest or conviction records will be considered for employment in accordance with all federal, state, and local laws including the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act. Our company believes that criminal history may have a direct, adverse and negative relationship on the following job duties, potentially resulting in the withdrawal of the conditional offer of employment:
  
  

​
  
  

1. Interacting and occasionally having unsupervised contact with internal/external clients and/or colleagues;
  
  

​
  
  

2. Appropriately handling and managing confidential information including proprietary and trade secret information and access to information technology systems; and
  
  

​
  
  

3. Exercising sound judgment.","https://www.indeed.com/cmp/Tiktok","https://www.tiktok.com/","Los Angeles, CA","10,000+","Decline to state","TikTok is a destination for short-form mobile videos.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/83b6323a8116bb3e0e44be12781095c5","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/c6b31072b68e5e09f3ffa00b4fafbdf3","Shou Zi Chew","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/97e665a8d665548274a13c52e20bb5f4"
"f6b43b2a86e83a4d","indeed","https://www.indeed.com/viewjob?jk=f6b43b2a86e83a4d","https://grnh.se/c3e10f732us","Staff Data Analyst","Aurora Innovation","Mountain View, CA, US","","2024-09-20","direct_data","yearly",135000.0,216000.0,"USD",False,"","","","","careersiteaccommodations@aurora.tech, careersiteaccommodations@aurora.tech","**Who We Are**



Aurora (Nasdaq: AUR) is delivering the benefits of self-driving technology safely, quickly, and broadly to make transportation safer, increasingly accessible, and more reliable and efficient than ever before. The Aurora Driver is a self-driving system designed to operate multiple vehicle types, from freight-hauling semi-trucks to ride-hailing passenger vehicles, and underpins Aurora Horizon and Aurora Connect, its driver-as-a-service products for trucking and ride-hailing. Aurora is working with industry leaders across the transportation ecosystem, including Toyota, FedEx, Volvo Trucks, PACCAR, Uber, Uber Freight, U.S. Xpress, Werner, Covenant, Schneider, and Ryder. For Aurora's latest news, visit aurora.tech and @aurora\\_inno on Twitter.


On the Aurora Data Science team, you will join a world-class group whose mission is generating insights and intelligence to improve the Aurora Driver and help accelerate our path towards safe and broad commercialization of Autonomous Vehicle technology. We are looking for an exceptional Data Analyst that can play a key role in accelerating the development of the Aurora Driver by contributing towards the automation, monitoring, and analysis of our development and operational processes. This is an opportunity to leverage vast amounts of data from both online (on-road) and offline (simulation) test modalities to help Aurora achieve its product and commercialization goals.



The ideal candidate will be someone who thrives working cross-functionally, getting things done, and has an ability to navigate complex and exciting projects with our partner Software, Hardware, and Operations teams. If your passions align with working on cutting edge Data Science projects to deliver impactful analysis, tools, and workflows that will transform the Transportation space, then joining Aurora Data Science is the perfect opportunity for you.


**In this role, you will**


* Work with our Engineering teams to inform the development of the Aurora Driver and streamline critical validation activities
* Partner closely with those stakeholders to design and implement metrics and dashboards to accelerate their development processes and help them measure, understand, and improve their performance
* Influence Aurora's tooling ecosystem to support data analytics work streams.
* Collaborate with a team of world-class Data Scientist and Analysts on Data Science & Analytics problems spanning multiple subsystems (eg. Motion Planning, Perception, Controls, etc.)
* Work closely with engineering leads to support their decisions with data-driven input
* Collaborate with our Data Science and Engineering communities to ensure the adoption of best practices and suggest improvements


**Required Qualifications**


* 6+ years of experience as a Data Analyst, Data Scientist, Data Engineer or similar technical role
* Experience technically leading and mentoring in the data and analytics space
* Experience taking Data Analytics projects end-to-end: synthesizing business needs, building required data pipelines, analyzing data, and clearly presenting insights.
* Expert knowledge and experience using relational databases (SQL, PostgreSQL, etc.) and familiarity with best practices for Data Engineering
* Advanced knowledge of data analytics infrastructure, including data transformation tools such as DBT and visualization frameworks and tools
* Competent in Python, able to write readable code that others can easily interpret
* Able to work effectively in a highly cross-functional, fast-moving and high-stakes environment.
* Proven ability to communicate technical, data-driven analysis to both technical and non-technical audiences across stakeholders, including translating and cascading Executive input into their work


**Desirable Qualifications**


* Advanced degree (MS or PhD) in Statistics, Computer Science, Operations Research, Economics, or a related quantitative field
* Experience using Amazon Web Services (AWS) tools
* Experience in the Autonomous Vehicle, Robotics, or Advanced Transportation spaces


The base salary range for this position is $135K - $216K per year. Aurora's pay ranges are determined by role, level, and location. Within the range, the successful candidate's starting base pay will be determined based on factors including job-related skills, experience, qualifications, relevant education or training, and market conditions. These ranges may be modified in the future. The successful candidate will also be eligible for an annual bonus, equity compensation, and benefits.



#LI-SP1



#Mid-Senior

**Working at Aurora**



At Aurora, we bring together extraordinarily talented and experienced people united by the strength of our values. We operate with integrity, set outrageous goals, and build a culture where we win together — all without any jerks.



We have offices in several locations across the United States, where we encourage team and cross-functional collaboration. Aurora offers competitive medical, dental, and vision benefits, and additional healthcare support including medical transportation reimbursement, fertility, adoption, and surrogacy benefits. We empower our employees and their families with options to further their unique physical, mental, and financial well-being.



Our Learning and Development offerings include Aurora Academy, where our people learn, develop, and practice the essential skills that drive Aurora's mission, continually up-leveling our team along the way. Our Careers page provides insight into career opportunities at Aurora, and you can find all the latest news on our Blog.



Safety is central to everything we do. Every employee at Aurora has a role in contributing to safety, every step of the way. We seek candidates who take active responsibility, can contribute to building an atmosphere of trust, and invest in the organization's long-term success by working safely — no matter what.



We believe that self-driving technology has broad benefits – including increased access to transportation. To realize those benefits, we need a workforce with diverse experiences, insights, and perspectives — a workforce that reflects the communities our technology will serve.



Aurora is committed to providing access to anyone who seeks information from our website. We invite anyone using assistive technologies, such as a screen reader or Braille reader, to email us at careersiteaccommodations@aurora.tech if they experience difficulty using our website. Please describe the accessibility problem and include a URL (if available).


*Aurora considers candidates without regard to their race, color, religion, national origin, age, sex, gender, gender identity, gender expression, sexual orientation, marital status, pregnancy status, parent or caregiver status, ancestry, political affiliation, veteran and/or military status, physical or mental disability, or any other status protected by federal or state law. Aurora considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. We are also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at* *careersiteaccommodations@aurora.tech**.*


*For California applicants, information collected and processed as part of your application and any job applications you choose to submit is subject to**Aurora's California Employment Privacy Policy**.*


**Diversity, Equity and Inclusion**



At Aurora, every employee is empowered to take an active role in building an inclusive, collaborative, and unified culture that leverages our diverse strengths, perspectives, and backgrounds.



Transforming how the world moves people and goods involves seeking to understand backgrounds, insights, and lived experiences that differ from our own. One way we accomplish that is with our 15 employee-led Aurora Unified Groups, which support diverse voices and drive inclusive collaboration. We believe that teamwork, belonging, and trust motivate and support our employees to do their best work. As our team grows, we strive to attract and retain exceptional talent that adds new perspectives and experiences and continues to drive innovation. Learn more on our Culture Page.



We are committed to helping qualified military community members leverage their talents in service of our mission. To understand how your military experience aligns with career opportunities at Aurora, review your military job classification at MyNextMove.org and consider applying for open positions corresponding to your identified skills and experiences!","https://www.indeed.com/cmp/Aurora-Innovation-1","http://www.aurora.tech","Mountain View, CA","1,001 to 5,000","Decline to state","Aurora is building self-driving technology that will revolutionize the future of transportation - a Driver for every vehicle - built to move people and goods.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/afa4469a81504928c90b4c8f083add5b","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/cd7a9400110555faf8c058e5cd884cf0","Chris Urmson","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/40bb454fc3f820ba8b083e397090d0cf"
"3af599ac35c0e8f1","indeed","https://www.indeed.com/viewjob?jk=3af599ac35c0e8f1","https://www.tesla.com/careers/search/job/sr-data-engineer-bi-accounting-finance-227947","Sr. Data Engineer, BI Accounting & Finance","Tesla","Fremont, CA, US","fulltime","2024-09-19","direct_data","yearly",80000.0,258000.0,"USD",False,"","","Industrial Manufacturing","","","**Job Category** Engineering & Information Technology  

**Location** Fremont, California  

**Req. ID** 227947  

**Job Type** Full-time  




Tesla participates in the E-Verify Program
What to Expect
We are looking for a Sr. Data Engineer (5+ yrs. of experience) that will be focusing on providing automations and data solutions to Finance and Accounting teams. They will be crucial to support various initiatives such as Accounting Reporting, Analytics, Financial Forecasting and many more. They will make sure to support business teams using various technologies and tools based on needs of the projects. They will be able to handle projects end to end while effectively assuming multiple roles throughout the process. They would be comfortable collaborating with both business and technical teams to deliver automated data driven projects. This position involves designing and creating ETL pipelines, Data Models, developing Analytics and Reporting solutions.
What You’ll Do* Design and implement automated data solutions to support various business teams such as Manufacturing, Accounting and Finance
* Own and manage projects from design to production, maintain relationship with stakeholders and collaborate with both business and technical teams to satisfy business needs
* Write, maintain and optimize scripts, processes and jobs that will be used by analytics and reporting solutions
* Build, manage and optimize scalable ETL pipelines using multiple sources apply transformation as per business needs and load data into data warehouse
* Design and refine data models by following best practices and techniques using most effective approaches for reporting and analytics such as star schema
* Identify slow-running processes and bottlenecks, troubleshoot problems, research and resolve issues
* Stay up to date with latest trends in data engineering, experiment with new tools, services, technologies and real-time processing frameworks
* Reverse engineer existing projects or products in use and always look for improvements in processes preferably with open-source technologies
* Collaborate with auditor and compliance teams to ensure that data solutions are in compliance with sox requirements especially on accounting and finance related projects
* Set high technical bar not just for yourself but for entire team, leading by example in coding standards, documentation and best practices

What You’ll Bring* Very strong SQL skills and very good understanding of relational databases (SQL Server, MySQL, Oracle, Vertica, etc.)
* Data warehousing experience, good understanding of data modeling, dimensional modeling, working experience with large scale data
* Programming skills with Python, Java or similar
* Good understanding of open-source distributed systems technologies such as Kafka, Spark
* Expertise in scalable ETL and data pipelines and tools such as (SSIS, Informatica, Airflow, Luigi or similar)
* Knowledge of OLAP databases and tools (SSAS, Hyperion, Cognos etc.)
* Experience with Reporting and data visualization tools (SSRS, PowerBI, Tableau, Looker or similar)
* Excellent communication skills and able to effectively communicate and collaborate with both technical and business teams (such as manufacturing, compliance, finance and accounting)
* Having background in Accounting, Finance, Banking or similar industry is nice to have but not a necessity

Compensation and Benefits
Benefits  

Along with competitive pay, as a full-time Tesla employee, you are eligible for the following benefits at day 1 of hire:
* Aetna PPO and HSA plans > 2 medical plan options with $0 payroll deduction
* Family-building, fertility, adoption and surrogacy benefits
* Dental (including orthodontic coverage) and vision plans, both have options with a $0 paycheck contribution
* Company Paid (Health Savings Account) HSA Contribution when enrolled in the High Deductible Aetna medical plan with HSA
* Healthcare and Dependent Care Flexible Spending Accounts (FSA)
* LGBTQ+ care concierge services
* 401(k) with employer match, Employee Stock Purchase Plans, and other financial benefits
* Company paid Basic Life, AD&D, short-term and long-term disability insurance
* Employee Assistance Program
* Sick and Vacation time (Flex time for salary positions), and Paid Holidays
* Back-up childcare and parenting support resources
* Voluntary benefits to include: critical illness, hospital indemnity, accident insurance, theft & legal services, and pet insurance
* Weight Loss and Tobacco Cessation Programs
* Tesla Babies program
* Commuter benefits
* Employee discounts and perks program
  
  

Expected Compensation  

$80,000 - $258,000/annual salary + cash and stock awards + benefits  

  

Pay offered may vary depending on multiple individualized factors, including market location, job-related knowledge, skills, and experience. The total compensation package for this position may also include other elements dependent on the position offered. Details of participation in these benefit plans will be provided if an employee receives an offer of employment.  

Tesla is an Equal Opportunity / Affirmative Action employer committed to diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, age, national origin, disability, protected veteran status, gender identity or any other factor protected by applicable federal, state or local laws.
Tesla is also committed to working with and providing reasonable accommodations to individuals with disabilities. Please let your recruiter know if you need an accommodation at any point during the interview process.","https://www.indeed.com/cmp/Tesla","https://www.tesla.com","1 Tesla Road Austin, TX 78725","10,000+","$5B to $10B (USD)","Tesla is accelerating the world’s transition to sustainable energy.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/5e42be6c7dd264b60310b59afb8a3c48","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/0dd52e4838b7fbaad47cb480680a00d3","Elon Musk","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/0fc450600a0b471e811e0d08de5cbe98"
"6820b2f3bb4526e1","indeed","https://www.indeed.com/viewjob?jk=6820b2f3bb4526e1","https://click.appcast.io/track/kn01y6v-org?cs=5c","Data Engineer III","Sam's Club","Sunnyvale, CA, US","","2024-09-19","direct_data","yearly",117000.0,234000.0,"USD",False,"","","Retail","","","Position Summary...  

  

What you'll do...
  

  

You have a deep interest and passion for technology. You have a passion to drive critical business initiatives with Data. You love writing and owning codes and enjoy working with people who will keep challenging you at every stage. You have strong problem solving, analytic, decision- making and excellent communication with interpersonal skills. You are self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities.  

  

**About Team:**  

Sam's Club is our membership warehouse club, a business model that provides our members with high-quality products at prices that are unrivaled by traditional retail. Sam's Club provides a carefully curated assortment of items, as well as developing and leading technologies and services such as Scan & Go, Club Pickup, and home delivery service in select markets. Sam's Club also provides travel, auto purchasing, pharmacy, optical, hearing aid centers, tire and battery centers, and a portfolio of business operations support services.  

  

**What you'll do:**  

* Design, build, test and deploy cutting edge solutions at scale, impacting millions of customers worldwide drive value from data
* Interact with Sams Club engineering teams across geographies to leverage expertise and contribute to the tech community.
* Engage with Product Management and Business to drive the agenda, set your priorities and deliver awesome product features to keep platform ahead of market scenarios.
* Identify right open source tools to deliver product features by performing research, POC/Pilot and/or interacting with various open source forums
* Develop and/or Contribute to add features that enable adoption of data across Sams Club
* Deploy and monitor products on Cloud platforms
* Develop and implement best-in-class monitoring processes to enable data applications meet SLAs
* Guide the team technically for end to end solution Lifecycle.

  

**What you'll bring:**  

* **2 - 3 years of Big data development experience**
* **1 - 2 Years of Experience in GCP/Azure cloud platforms**
* Demonstrates up-to-date expertise in Data Engineering, complex data pipeline development
* **Architect, Design, develop, implement and tune distributed data processing pipelines that process large volume of data; focusing on scalability, low -latency, and fault-tolerance in every system built.**
* Exposure to Data Governance ( Data Quality, Metadata Management, Security, etc.)
* **Experience with Java, Scala and/or Python to write data pipelines and data processing layers**
* Demonstrates expertise in writing complex, highly-optimized queries across large data sets
* **Proven working expertise with Big Data Technologies Spark Scala/PySpark, and SQL**
* Knowledge and experience in Kafka, Spark Streaming, Druid and Presto.

  

""Immigration sponsorship is not available in this role.""  

  

**About Sam's Club**  

  

Sam Walton opened the first Sam's Club in 1983 to meet a growing need among customers who wanted to buy merchandise in bulk. Since then, Sam's Club has grown rapidly, opening more than 600 clubs in the U.S. and 100 clubs internationally. By offering affordable, wholesale merchandise to members, Sam's Club helps make saving simple for families and small business owners. Sam's Club employs about 110,000 associates in the U.S. The average club is 134,000 square feet and offers bulk groceries and general merchandise. Most clubs also have specialty services, such as a pharmacy, an optical department, a photo center, or a tire and battery center.  

  

**Flexible, hybrid work:**  

We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.  

  

**Benefits:**  

Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.  

  

**Equal Opportunity Employer:**  

Walmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.  

  

The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.  

  

At Sam's Club, we offer competitive pay as well as performance-based bonus awards and other great benefits for a happier mind, body, and wallet!  

‎
  

* Health benefits include medical, vision and dental coverage


‎
  

* Financial benefits include 401(k), stock purchase and company-paid life insurance


‎
  

* Paid time off benefits include PTO, parental leave, family care leave, bereavement, jury duty, and voting. You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable.


‎
  

  

For information about PTO, see https://one.walmart.com/notices .
  

  

‎
  

* Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.


‎
  

Live Better U is a company paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.  

‎
  

Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms.  

‎
  

  

For information about benefits and eligibility, see One.Walmart .
  

  

‎
  

The annual salary range for this position is $117,000.00-$234,000.00  

‎
  

Additional compensation includes annual or quarterly performance bonuses.  

‎
  

  

‎
  

  

‎
  

  

‎
  

  

‎  

  

**Minimum Qualifications...**  

  

Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.  

  

Option 1: Bachelor's degree in Computer Science and 2 years' experience in software engineering or related field. Option 2: 4 years' experience in  

software engineering or related field. Option 3: Master's degree in Computer Science.  

  

**Preferred Qualifications...**  

  

Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.  

  

Data engineering, database engineering, business intelligence, or business analytics, Master's degree in Computer Science or related field and 2 years' experience in software engineering or related field, We value candidates with a background in creating inclusive digital experiences, demonstrating knowledge in implementing Web Content Accessibility Guidelines (WCAG) 2.2 AA standards, assistive technologies, and integrating digital accessibility seamlessly. The ideal candidate would have knowledge of accessibility best practices and join us as we continue to create accessible products and services following Walmart's accessibility standards and guidelines for supporting an inclusive culture.  

  

**Primary Location...**  

  

640 W California Avenue, Sunnyvale, CA 94086-4828, United States of America","https://www.indeed.com/cmp/Sam's-Club","http://corporate.samsclub.com","Sam’s Club Home Office
2101 SE Simple Savings Dr. 
Bentonville, AR 72716-8048","201 to 500","more than $10B (USD)","","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/1c99fbcab972f5c780486df06135ed4b","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/ee07ecb9aeba67e7374d1cf7795f0b6f","Chris Nicholas",""
"63d1890f819762a2","indeed","https://www.indeed.com/viewjob?jk=63d1890f819762a2","https://www.amazon.jobs/jobs/2799821/data-engineer-network-product-development--optics?cmpid=DA_INAD200785B","Data Engineer, Network Product Development - Optics","Amazon.com","Cupertino, CA, US","fulltime","2024-09-02","direct_data","yearly",118900.0,205600.0,"USD",False,"","","Internet And Software","","","* Bachelor’s degree in Computer Science, Electrical/Electronic Engineering, Physics, Mechanical/Computer Engineering, or equivalent
* 4+ years of hands-on experience with onboarding to and collecting data
* 3+ years of experience with developing metrics from data
* 2+ years of experience creating software to ingest, and load data through pipelines
* 2+ years of experience validating and cleaning data
* Experience with big data technologies such as: Hadoop, Hive, Spark, EMR


Amazon seeks an experienced Data Engineer to join the NPD (Network product devleopment) interconnects metrics team. Our mission is to provide the data, metrics, alarming, and monitoring needed to improve the health of the network and increase availability to our customers as part of a A Continuous Improvement Model for Interconnects within AWS Data Centers. As a member of The Amazon Network Infrastructure team, you’ll have a unique opportunity to shape the development of one of the world’s largest and most complex optical networks. With Amazon Web Services our goal is to become “The Infrastructure Platform” to the world. Our customers demand the highest quality and reliability for their services.
  
  

As a Data Engineer, you will design, implement and support scalable data infrastructure solutions to integrate with multi heterogeneous data sources, aggregate and retrieve data in a fast and safe mode, curate data that can be used in reporting, analysis, machine learning models and ad-hoc data requests. You will be exposed to cutting edge AWS big data technologies. You should have excellent business and communication skills to be able to work with business owners and Tech leaders to gather infrastructure requirements, design data infrastructure, build up data pipelines and datasets to meet business needs. You stay abreast of emerging technologies, investigating and implementing where appropriate.
  
  

Key job responsibilities
  
* Develop and collect metrics to track and monitor the performance of the Amazon network
* Design, implement, and support data warehouse/ data lake infrastructure using AWS bigdata stack, Python, Redshift, QuickSight, Glue/lake formation, EMR/Spark, Athena etc.
* Creation and support of real-time data pipelines built on AWS technologies including EMR, Glue, Redshift/Spectrum and Athena.
* Use business intelligence and visualization software (e.g., QuickSight) to develop dashboards those are used by senior leadership.
* Collaborate with other Engineering teams, Product/Finance Managers/Analysts to implement advanced analytics algorithms that exploit our rich datasets for financial model development, statistical analysis, prediction, etc.
* Explore new datasets and establish mechanisms to provide access to them for the entire organization
* Empower technical and non-technical, internal customers to drive their own analytics and reporting (self-serve reporting) and support ad-hoc reporting when needed.
* Work with network operations team in identifying operational issues to improve overall quality of the fleet.
* Manage numerous requests concurrently and strategically, prioritizing when necessary
* Mentor other engineers, influence positively team culture, and help grow the team


A day in the life
  
On an everyday basis as part of our team, you have the unique opportunity to understand the growing AWS network and our internal customers’ requirement on interconnect solutions. You'll work backwards to devise hardware solutions by influencing the broad industry and/or to develop software tools with sister teams to maintain a highly available network that delights AWS customers. You design and implement processes and mechanisms that both help the team to deliver business impact to the organization in a systemic way, while also helping to raise the bar on our operational excellence.
  
Operating at the scale we do, there is no blueprint for how to do what we do, which encourages our engineers to identify and develop simple solutions to complex problems. We encourage durable solutions that look around corners while taking into consideration our customer needs from a cost, performance, and reliability perspective. We work closely with our internal partners that design, build and operate the network to ensure that our solutions meet their needs and exceed their expectations.
  
  

About the team
  
Within AWS Networking the NPD (Network Product Development) organization is responsible for, designing the hardware, building the software, and owning the interconnects for the routers that power the global AWS network. Beyond product delivery we actively manage the fleet or routers in a network that grows by 70% annually. This means tracking key business and operational metrics to ensure that we operate smoothly and minimize or eliminate customer impact due to device related issues for a transparent AWS customer experience.
  
Working at AWS in the Core Networking Team - Meet Matt, Director, Core Networking -- Link
  
Meet Kensie, Network Development Engineer -- Link
  
About AWS
  
Diverse Experiences
  
AWS values diverse experiences. Even if you do not meet all of the qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasn’t followed a traditional path, or includes alternative experiences, don’t let it stop you from applying.
  
  

Why AWS?
  
Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses.
  
  

Inclusive Team Culture
  
Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness.
  
  

Mentorship & Career Growth
  
We’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing resources here to help you develop into a better-rounded professional.
  
  

Work/Life Balance
  
We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the cloud.
  
  

* Masters or PhD preferred
* Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
* Experience with distributed systems as it pertains to data storage and computing
* Experience in databases and SQL.
* Experience in debugging and troubleshooting data ingestion related issues.
* Experience in the software development lifecycle.
* Experience in innovating or inventing metrics to solve business problems.
* Meets/exceeds Amazon’s leadership principles requirements for this roles.
* Meets/exceeds Amazon’s functional/technical depth and complexity for this role.


Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.
  
  

**Los Angeles County applicants:** Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
  
  

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.","https://www.indeed.com/cmp/Amazon.com","https://www.amazon.jobs","440 Terry Ave N, Seattle, WA, United States, Washington","10,000+","more than $10B (USD)","Our mission is to be Earth's most customer-centric company.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/3e9d43f5c277de169808abdcaf49ba2c","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/ff3e6de48f7941c7ea8babbf948a4998","Andrew Jassy","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/59f4d630d9c6b99af50a3381e6406486"
"acb1b0699d76e182","indeed","https://www.indeed.com/viewjob?jk=acb1b0699d76e182","https://www.amazon.jobs/jobs/2749373/data-engineer-ii-amazon-health-science--analytics?cmpid=DA_INAD200785B","Data Engineer II, Amazon Health Science & Analytics","Amazon.com","San Francisco, CA, US","fulltime","2024-08-19","direct_data","yearly",118900.0,205600.0,"USD",False,"","","Internet And Software","","","* 3+ years of data engineering experience
* Experience with data modeling, warehousing and building ETL pipelines
* - Knowledge of modern data warehouse (Snowflake, Big Query)
* - Proficiency in SQL
* - Ability to communicate technical concepts to diverse audiences


Want to channel the power of data to be a part of something big, having an impact our customers' and members' health and well being? Come join a dynamic, data-centric organization as we chart a course to greater self-service and empowerment of business, clinical, and technology leaders at One Medical!
  
  

You will be responsible for designing and building reliable & performant data
  
models and pipelines to provide actionable insights and accommodate needs from our
  
cross-functional partners and distributed analysts across the organization.
  
  

You are someone that enjoys exploring data to identify large areas of opportunity to drive
  
business impact, are able to ask the right questions to accurately analyze situations and can
  
acquire data from multiple and diverse sources when solving problems. Not only that, you are
  
also able to make sense of complex, high-quantity, and sometimes contradictory information to
  
solve these problems through structured thinking and have shown the ability to drive results in
  
accomplishing objectives despite obstacles and setbacks. You thrive at effective communication
  
in a variety of settings, whether it’s one-on-one, small and large groups, or among diverse styles
  
and position levels.
  
  

#everydaybetter
  
  

Key job responsibilities
  
* Partner with folks across the company on developing flexible and scalable analytics to


drive insights and decision making by internal customers
  
* Design and build reliable, performant and high quality data models and pipelines to


provide actionable insights and accommodate needs for our cross-functional teams
  
* Build out suites of standard KPIs/metrics
* Work with the team to define how we model and warehouse data that is accessed by


most teams and analysts across the company
  
* Engage in code reviews to ensure code committed is collectively maintainable by the


team
  
* Build proper data quality detection tools to identify data issues in the data transformation


stages and fix the problems to meet pipelines / table health SLAs
  
* Ensure all critical systems within team’s domain have appropriate and up to date


documentation
  
* Participate in our scheduled support rotation, where you’ll be responsible for maintaining


and troubleshooting pipelines and providing assistance to data analysts
  
* Champion the practice of making data-informed decisions by ensuring internal


stakeholders such as the product management, operations, marketing, clinical
  
effectiveness, finance and executive teams are making data driven decisions quickly and
  
with confidence.
  
* Build and improve data tooling in partnership with data engineering and platform teams
* Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions
* Experience with non-relational databases / data stores (object storage, document or key-value stores, graph databases, column-family databases)
* - Healthcare industry experience
* - Knowledge of Apache Airflow
* - Proficiency in Python


Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.
  
  

**Los Angeles County applicants:** Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
  
  

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
  
  

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.","https://www.indeed.com/cmp/Amazon.com","https://www.amazon.jobs","440 Terry Ave N, Seattle, WA, United States, Washington","10,000+","more than $10B (USD)","Our mission is to be Earth's most customer-centric company.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/3e9d43f5c277de169808abdcaf49ba2c","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/ff3e6de48f7941c7ea8babbf948a4998","Andrew Jassy","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/59f4d630d9c6b99af50a3381e6406486"
"e01d8d248b1f3812","indeed","https://www.indeed.com/viewjob?jk=e01d8d248b1f3812","https://www.amazon.jobs/jobs/2736828/senior-data-engineer-amazon-health-science--analytics?cmpid=DA_INAD200785B","Senior Data Engineer, Amazon Health Science & Analytics","Amazon.com","San Francisco, CA, US","fulltime","2024-08-14","direct_data","yearly",139100.0,240500.0,"USD",False,"","","Internet And Software","","","* 5+ years of data engineering experience
* Experience with data modeling, warehousing and building ETL pipelines
* Experience with SQL
* Experience in at least one modern scripting or programming language, such as Python, Java, Scala, or NodeJS
* Experience mentoring team members on best practices
* Experience working with DBT.
* Experience in dimensional data modelling and schema design.


Want to channel the power of data to be a part of something big, having an impact our customers' and members' health and well being? Come join a dynamic, data-centric organization as we chart a course to greater self-service and empowerment of business, clinical, and technology leaders at One Medical!
  
  

Key job responsibilities
  
* Partner with folks across the company on developing flexible and scalable analytics to drive insights and decision making by internal customers
* Design and build reliable, performant and high quality scalable data architecture, data models, and pipelines to provide actionable insights and accommodate needs for our cross-functional teams
* You will have the opportunity to design the most critical business level aggregated tables at One Medical
* Build out suites of standard KPIs and metrics
* Define the strategy for how we model and warehouse data that is accessed by most teams and analysts across the company
* Build proper data quality detection to identify data issues in the data transformation stages and fix the problems to meet pipelines / table health SLAs
* Champion the practice of making data-informed decisions by ensuring internal stakeholders such as product management, operations, marketing, clinical effectiveness, finance and the executive team are making data driven decisions quickly and with confidence.
* Build and improve data tooling in partnership with data engineering and platform teams
* Mentor junior team members and team members throughout the broader Amazon Health Services organization


#everydaybetter
  
  

* Experience with big data technologies such as: Hadoop, Hive, Spark, EMR
* Experience operating large data warehouses


Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.
  
  

**Los Angeles County applicants:** Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
  
  

Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
  
  

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $139,100/year in our lowest geographic market up to $240,500/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.","https://www.indeed.com/cmp/Amazon.com","https://www.amazon.jobs","440 Terry Ave N, Seattle, WA, United States, Washington","10,000+","more than $10B (USD)","Our mission is to be Earth's most customer-centric company.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/3e9d43f5c277de169808abdcaf49ba2c","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/ff3e6de48f7941c7ea8babbf948a4998","Andrew Jassy","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/59f4d630d9c6b99af50a3381e6406486"
"d1a4b6ed95071b4f","indeed","https://www.indeed.com/viewjob?jk=d1a4b6ed95071b4f","https://www.amazon.jobs/jobs/2707107/data-engineer-ii-hweng-data-science--analytics-team?cmpid=DA_INAD200785B","Data Engineer II, HWEng Data Science & Analytics team","Amazon.com","Cupertino, CA, US","fulltime","2024-07-19","direct_data","yearly",118900.0,205600.0,"USD",False,"","","Internet And Software","","","* A Bachelor's degree in a quantitative/technical field (e.g. Computer Science, Statistics, Engineering) or equivalent industry experience
* 3+ years of experience with demonstrated strength in ETL/ELT, data modeling, data warehouse technical architecture, infrastructure components and reporting/analytic tools
* 3+ years of hands-on experience in writing complex, highly-optimized SQL queries across large data sets.
* 3+ years of experience in scripting languages like Python etc.


AWS Hardware Engineering is looking for an experienced, innovative Data Engineer to join their Data Science and Analytics team. You will be part of a group of talented engineers and scientists that builds data products and services to turn hardware monitoring data into insights using advanced analytics and machine learning.
  
  

As a Data Engineer, you will provide technical leadership, lead data engineering initiatives, and build end-to-end analytical solutions that are highly available, scalable, stable, secure, and cost-effective. You strive for simplicity, demonstrate creativity and sound judgement. You deliver data solutions that are customer focused, easy to consume and create business impact.
  
  

You are passionate about working with huge datasets and have experience with the organization and curation of data for analytics. You have a strategic and long-term view on architecting advanced data ecosystem. You are experienced in building efficient and scalable data services and can integrate data systems with AWS tools and services to support a variety of customer use cases/applications.
  
  

**In this role, you can:**  

Design, implement and operate large-scale, high-volume, high-performance data structures for analytics and data science.
  
Implement data ingestion routines both real time and batch using best practices in data modeling, ETL/ELT processes by leveraging AWS technologies and big data tools.
  
Gather business and functional requirements and translate these requirements into robust, scalable, operable solutions with a flexible and adaptable data architecture.
  
Collaborate with engineers to help adopt best practices in data system creation, data integrity, test design, analysis, validation, and documentation.
  
Collaborate with scientists to create fast and efficient algorithms that exploit our rich data sets for optimization, statistical analysis, prediction, clustering, and machine learning.
  
Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service modeling and production support for customers.
  
  

This role falls within the broader AWS Infrastructure Services (AIS) organization, which owns the design, planning, delivery, and operation of all AWS global infrastructure. In other words, we’re the people who keep the cloud running. We support all AWS data centers and all the servers, storage, networking, power, and cooling equipment that ensure our customers have continual access to the innovation they rely on. We work on the most challenging problems, with thousands of variables impacting the supply chain — and we’re looking for talented people who want to help.
  
You’ll join a diverse team of software, hardware, and network engineers, supply chain specialists, security experts, operations managers, and other vital roles. You’ll collaborate with people across AWS to help us deliver the highest standards for safety and security while providing seemingly infinite capacity at the lowest possible cost for our customers. And you’ll experience an inclusive culture that welcomes bold ideas and empowers you to own them to completion.
  
  

About the team
  
Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud platform. We pioneered cloud computing and never stopped innovating — that’s why customers from the most successful startups to Global 500 companies trust our robust suite of products and services to power their businesses.
  
  

AWS values diverse experiences. Even if you do not meet all the preferred qualifications and skills listed in the job description, we encourage candidates to apply. If your career is just starting, hasn’t followed a traditional path, or includes alternative experiences, don’t let it stop you from applying.
  
  

We value work-life harmony. Achieving success at work should never come at the expense of sacrifices at home, which is why we strive for flexibility as part of our working culture. When we feel supported in the workplace and at home, there’s nothing we can’t achieve in the cloud.
  
  

Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster a culture of inclusion that empower us to be proud of our differences. Ongoing events and learning experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender diversity) conferences, inspire us to never stop embracing our uniqueness.
  
  

We’re continuously raising our performance bar as we strive to become Earth’s Best Employer. That’s why you’ll find endless knowledge-sharing, mentorship, and other career-advancing resources here to help you develop into a better-rounded professional.
  
  

* Experience with AWS services such as Redshift, Glue, S3, EMR, Kinesis and SNS/SQS.
* Experience architecting data lake and cloud data warehouses.
* Experience with big data technologies (Hadoop, Hive, Kafka, Spark, etc.)
* Experience in leading and delivering end-to-end projects.
* AWS certifications or other related professional technical certifications
* Meets/exceeds Amazon’s leadership principles requirements for this role
* Meets/exceeds Amazon’s functional/technical depth and complexity for this role


Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.
  
  

**Los Angeles County applicants:** Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.
  
  

Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $118,900/year in our lowest geographic market up to $205,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.","https://www.indeed.com/cmp/Amazon.com","https://www.amazon.jobs","440 Terry Ave N, Seattle, WA, United States, Washington","10,000+","more than $10B (USD)","Our mission is to be Earth's most customer-centric company.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/3e9d43f5c277de169808abdcaf49ba2c","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/ff3e6de48f7941c7ea8babbf948a4998","Andrew Jassy","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/59f4d630d9c6b99af50a3381e6406486"
"880a22054261bcc9","indeed","https://www.indeed.com/viewjob?jk=880a22054261bcc9","https://d.hodes.com/r/tp2?e=se&tv=pixel_tracker&aid=pacificlife&p=web&se_ca=indeed&se_ac=click&se_la=21132402&u=https%3A%2F%2Fpacificlife.wd1.myworkdayjobs.com%2FPacificLifeCareers%2Fjob%2FNewport-Beach-CA-700%2FSr-Data-Architect-II_R13340%3Futm_medium%3Dsymphonytalent-jobads%26utm_campaign%3DInformation%2520Technology%26utm_content%3DSr%2520Data%2520Architect%2520II%26utm_term%3DR13340%26utm_source%3DIndeed%26source%3DAPPLICANT_SOURCE-3-19&se_pr=e8b9312d2ba0edda&se_va=4855&tr_af=organic&ti_id=2094_R13340","Sr Data Architect II","Pacific Life","Newport Beach, CA, US","fulltime","2024-10-09","direct_data","yearly",144630.0,176770.0,"USD",True,"","","Insurance, Insurance","","","**Job Description:**  

We believe in giving you ongoing opportunities to advance your career. Whether you want to take on broader responsibilities or grow in new directions, you are in the right place. Here at Pacific Life, we want to help you embrace your potential so you can achieve your personal best doing purposeful work - every day.
  
  

Pacific Life is investing in bright, agile, and diverse talent to contribute to our mission of innovating our business and creating superior customer experience. We are actively seeking a talented Senior Data Architect to join our Enterprise data team in Newport Beach, CA. This role can be on-site, hybrid or 100% remote.
  
  

**How will you make an impact:**  

**Architect and Design Data Platforms:** Design and implement scalable, cloud-based data architectures, enabling real-time and batch data processing to support analytics, AI/ML, and business intelligence use cases.
  
**Data Integration:** Lead efforts to integrate diverse data sources (structured, semi-structured, and unstructured), ensuring data consistency, quality, and availability across hybrid environments (cloud and on-premises).
  
**Data Modernization:** Collaborate with cross-functional teams to assess and migrate legacy data systems to modern cloud platforms (e.g., AWS, Snowflake), optimizing for performance, cost, and scalability.
  
**Innovation:** Stay ahead of emerging data technologies like Data Mesh, Data Fabric, and API-driven services, and lead their implementation within the organization.
  
**Collaboration:** Partner with data engineers, data governance, and business stakeholders to understand their data needs and provide feasible data solutions.
  
  

**The experience you will bring:**  

**Educational Background:** Bachelor's degree in Information Technology, Computer Science, Data Science, or a related field. A Master’s degree in a relevant discipline is preferred.
  
**Data Architecture:** 7+ years of experience designing and building enterprise data platforms, with a strong focus on cloud-native architectures using platforms such as AWS, Azure, or Google Cloud.
  
**Data Solutions:** Extensive experience in end-to-end data solutions, data modeling, including relational, NoSQL, and dimensional models. Ability to design flexible, scalable architectures supporting both batch and streaming data pipelines.
  
**Data Integration and ETL/ELT Mastery:** Strong expertise in data integration, working with modern ETL/ELT tools (e.g., DBT, Matillion, Apache Airflow) and building efficient, scalable data pipelines across hybrid environments.
  
**Advanced SQL and Scripting Skills:** Expertise in SQL and other programming languages (e.g., Python, Scala) for data transformation, querying, and automating workflows. Experience in building and optimizing complex database structures like stored procedures, views, and materialized views.
  
**DevOps and CI/CD:** Experience in implementing DevOps practices and CI/CD pipelines in the context of data architecture, automating data deployments, testing, and monitoring.
  
**Collaboration and Leadership:** Strong communication and collaboration skills, with a proven ability to work closely with cross-functional teams, business stakeholders, and technical leadership to align data architecture with organizational goals.
  
  

**Preferred Qualifications:**  

**Third Party Data:** Experience working with third-party data management solutions and integrating external data sources (e.g., APIs, data feeds, SaaS platforms) into the enterprise data platform.
  
**Industry Expertise:** Prior experience in the financial services sector or a deep understanding of data management needs within highly regulated industries (e.g., finance, healthcare).
  
**Certifications:** Professional certifications in cloud platforms and specialized data technologies (e.g., Snowflake SnowPro, AWS Certified Solutions Architect, Google Professional Data Engineer)
  
  

You can be who you are.
  
People come first here. We’re committed to a diverse, equitable and inclusive workforce. Learn more about how we create a welcoming work environment through Diversity, Equity, and Inclusion at www.pacificlife.com. What’s life like at Pacific Life? Visit Instagram.com/lifeatpacificlife.
  
Benefits start Day 1.
  
Your wellbeing is important. We’re committed to providing flexible benefits that you can tailor to meet your needs. Whether you are focusing on your physical, financial, emotional, or social wellbeing, we’ve got you covered.
  
Prioritization of your health and well-being including Medical, Dental, Vision, and a Wellbeing Reimbursement Account that can be used on yourself or your eligible dependents
  
Generous paid time off options including Paid Time Off, Holiday Schedules, and Financial Planning Time Off
  
Paid Parental Leave as well as an Adoption Assistance Program
  
Competitive 401k savings plan with company match and an additional contribution regardless of participation.
  
  

**Base Pay Range:**  

The base pay range noted represents the company’s good faith minimum and maximum range for this role at the time of posting. The actual compensation offered to a candidate will be dependent upon several factors, including but not limited to experience, qualifications and geographic location. Also, most employees are eligible for additional incentive pay.
  
$144,630.00 - $176,770.00
  
  

Your Benefits Start Day 1
  
  

Your wellbeing is important to Pacific Life, and we’re committed to providing you with flexible benefits that you can tailor to meet your needs. Whether you are focusing on your physical, financial, emotional, or social wellbeing, we’ve got you covered.
  
  

Prioritization of your health and well-being including Medical, Dental, Vision, and Wellbeing Reimbursement Account that can be used on yourself or your eligible dependents
  
  

**Generous paid time off options including:** Paid Time Off, Holiday Schedules, and Financial Planning Time Off
  
  

Paid Parental Leave as well as an Adoption Assistance Program
  
  

Competitive 401k savings plan with company match and an additional contribution regardless of participation
  
  

**EEO Statement:**  

Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.","https://www.indeed.com/cmp/Pacific-Life","http://www.pacificlife.com","700 Newport Center Dr.
Newport Beach CA, United States 92660","1,001 to 5,000","$5B to $10B (USD)","Pacific Life provides a variety of products and services designed to create financial security for individuals and businesses in the retail, institutional, workforce benefits, and reinsurance markets.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/586965fc249d4be519ce9b686dc91775","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/1dcada2c8aa006d88490076b10ce700b","Darryl Button","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/c33e18fe813a5ab8c72a1c554ec778a4"
"be38976238c28550","indeed","https://www.indeed.com/viewjob?jk=be38976238c28550","https://careers.google.com/jobs/results/78534069649842886-data-engineer/","Data Engineer, Global Sales Activation, Go-To-Market","Google","Los Angeles, CA, US","fulltime","2024-10-09","description","yearly",118000.0,174000.0,"USD",False,"","","","","","This role may also be located in our Playa Vista, CA campus.
  
**Note:** By applying to this position you will have an opportunity to share your preferred working location from the following: Mountain View, CA, USA; Atlanta, GA, USA; Chicago, IL, USA; New York, NY, USA; Los Angeles, CA, USA; San Francisco, CA, USA; Washington D.C., DC, USA.
  
  

**Minimum qualifications:**  

* Bachelor’s degree in Engineering, Computer Science, a related field, or equivalent practical experience.
* 3 years of experience coding with one or more programming languages (e.g., Python, Java, C/C++).
* 3 years of experience designing and building data pipelines (ETL) and model data, for synch and asynch system integration and implementation.
* 3 years of experience analyzing data, database query (e.g. SQL), and creating dashboards/reports.


**Preferred qualifications:**  

* Master's degree in Engineering, Computer Science, or a related field.
* 3 years of experience partnering with stakeholders (e.g., users, partners, customers).
* 3 years of experience developing project plans and delivering projects on time within budget and scope.
* 3 years of experience designing data models and data warehouses, including data processing automation, data quality, data governance, business intelligence, and data privacy.
* Experience writing and maintaining ETLs which operate on a variety of structured and unstructured sources.
* Structured thinking with the ability to break down complex, ambiguous problems and propose solutions through impactful data modeling designs.


About the job
  
  

The Governance, Infrastructure, and Operations (GIO) team sits within Product Operations in the Global Sales Activation (GSA) organization, and is responsible for leading sales workflow activation strategy across business operations, governance, legal compliance, sales enablement, and measurement and analytics. GSA resides within the Go-To-Market Operations (GTM) team and enables Google’s Business Organization (GBO) to drive customer success. Experts in driving process improvements and consistency, team members are analytical and strategic with a pragmatic sense of getting things done.
  
Data is the fundamental building block for every tool and every insight. We build the data sets that help run the business, piping the relevant data into and out of our tools, and making it useful for analysts across the organization to drive reporting and insights. We are responsible for democratizing GBO and Ads data, helping business leaders make sense of business operations through timely, accurate, and robust business intelligence. We use SQL and ETL systems to produce useful datasets, establish best practices for data sets and reporting, and develop a breadth of expertise in various data domains. Ultimately, Data Engineers scale centralized reporting and automate data processes to ensure the business is operating more effectively and efficiently.
  
The US base salary range for this full-time position is $118,000-$174,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more aboutbenefits at Google.
  
Responsibilities
  
  

* Centralize ads and customer data to enable discovery and analysis for users.
* Recommend and adopt best practices in developing and modifying existing data models and ETL pipelines. Be responsible for data governance, data integrity, test design, validation.
* Create Extract, Transform, and Load (ETLs) and reporting systems for new data using a variety of traditional as well as large-scale distributed data systems.
* Work closely with analysts to productionize various statistical and machine learning models using data processing pipelines.
* Write and review technical documents including design, development, and revision documents.


Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See alsoGoogle's EEO Policy andEEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing ourAccommodations for Applicants form.","https://www.indeed.com/cmp/Google","http://goo.gle/3ygdkgv","Mountain View, CA","10,000+","more than $10B (USD)","Our mission is to organize the world’s information and make it universally accessible and useful. ","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/fff4be3829cee39e477a518f55475f44","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/56b1f27b69e0e2c02b8e9ad6e5fce05f","Sundar Pichai","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/417a5815642490eb9a47ed7970a26c97"
"4cf10eabfefa2dcb","indeed","https://www.indeed.com/viewjob?jk=4cf10eabfefa2dcb","https://careers.wipro.com/jobs/3112123/job?utm_source=indeed_integration&iis=Job%20Board&iisn=Indeed&indeed-apply-token=73a2d2b2a8d6d5c0a62696875eaebd669103652d3f0c2cd5445d3e66b1592b0f","Data Engineer","Wipro","Torrance, CA, US","fulltime","2024-10-08","direct_data","yearly",130000.0,150000.0,"USD",False,"","","","","","Overview:
**About Wipro:**
Wipro Limited (NYSE: WIT, BSE: 507685, NSE: WIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. We leverage our holistic portfolio of capabilities in consulting, design, engineering, operations, and emerging technologies to help clients realize their boldest ambitions and build future-ready, sustainable businesses. A company recognized globally for its comprehensive portfolio of services, strong commitment to sustainability and good corporate citizenship, we have over 250,000 dedicated employees serving clients across 66 countries. We deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world.* **A PROUD HISTORY OF OVER 75 YEARS**
* **FY22 REVENUE 10.4 BN USD**
* **WE’RE PRESENT IN 66 COUNTRIES**
* **OVER 1,400 ACTIVE GLOBAL CLIENTS**

 **Role – Data Engineer****Location: Torrance, CA (3 Days onsite in a week)****Yrs. of experience: 10+ Yrs.****Mode of employment: Full-Time** **Job Description:**

Skills: Datawarehouse using AWS, Glue, Redshift, Pricemart, and python.

* Overall experience of 10 + years with extensive hands on experience in AWS cloud, database and data warehouse architecture and delivery
* As Data Engineer will be responsible for providing the required data engineering capabilities that will enable ingestion and sustaining of these new data sets
* Provide Deep expertise on data sources, required transformations, quality, consistency, velocity, access
* Extensive hands-on experience implementing data migration and data processing using AWS services: VPC/SG, EC2, S3, AutoScaling, CloudFormation, LakeFormation, DMS, Kinesis, Kafka, Nifi, CDC processing Redshift, Snowflake, RDS, Aurora, Neptune, DynamoDB, Cloudtrail, CloudWatch, Docker, Lambda, Spark,Glue, Sage Maker, AI/ML, API GW, etc.
* Familiarity with the Technology stack available in the industry for data management, data ingestion, capture, processing and curation: Kafka, StreamSets, Attunity, GoldenGate, Map Reduce, Hadoop, Hive, Hbase, Cassandra, Spark, Flume, Hive, Impala, etc.

 *“Expected annual pay for this role ranges from [$X130,000] to [$150,000]. Based on the position, the role is also eligible for Wipro’s standard benefits including a full range of medical and dental benefits options, disability insurance, paid time off (inclusive of sick leave), other paid and unpaid leave options.”* **Wipro is an Equal Employment Opportunity employer and makes all employment and employment-related decisions without regard to a person's race, sex, national origin, ancestry, disability, sexual orientation, or any other status protected by applicable law.**

  

#LI-AK2","https://www.indeed.com/cmp/Wipro","http://www.wipro.com","Bengaluru","10,000+","$5B to $10B (USD)","","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/8b2cd63e1e41ba18596880aca0e609bc","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/015ae0ccaaae4f7122a8c630c71a8dd4","Srini Pallia","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/fbab115759103a89dce40628d5b28372"
"f3678ba37ea3098e","indeed","https://www.indeed.com/viewjob?jk=f3678ba37ea3098e","https://globalus242.dayforcehcm.com/CandidatePortal/en-US/lightbox/Site/LIGHTBOXCAREERS/Posting/View/391?source=Indeed","Digital Solutions - Data Engineer","LightBox","Irvine, CA, US","fulltime","2024-10-08","direct_data","yearly",91940.0,116417.0,"USD",True,"","","","","","At LightBox, we strive to not only equip confident, data-driven decisions across sectors, but to also enrich lives by bringing people, information, and technology together. As a company with a wide range of clients, we believe a diverse workforce is crucial to success. Our commitment to inclusion across race, gender, age, religion, identity, and experience is the foundation upon which we operate and connect with our customers and the communities in which we work.
  
  

With our expertise, we are producing the best available data, workflow tools, technology, and analytics to support everyone making a real estate decision. There has never been a better time to make an impact and we invite you to join us on this journey.
  
  

LightBox is a leading provider of data and workflow solutions across commercial real estate and location intelligence. Our solutions deliver the depth, speed and accuracy that enable insights to over 50,000 brokers, 1,000 banks and lenders, 1,000 law firms and 5,000 environmental consulting and engineering firms.
  
  

About LightBox
  
LightBox is the world’s leading platform for commercial real estate information and technology. We empower decision-makers with authoritative data, integrated workflows, and unparalleled industry connections. Our clientele includes commercial and government agencies, brokers, developers, investors, lenders, insurers, technology providers, environmental consultants, and valuation professionals—all requiring definitive real estate data and robust workflow solutions.
  
Our expertise enables us to deliver the highest quality data, workflow tools, technology, and analytics to support location-based decision-making. There has never been a better time to make an impact. Join us on this journey and help shape the future of real estate.
  
  

About Digital Solutions
  
  

The Digital Solutions (""Professional Services"") team at LightBox plays a crucial role in delivering tailored solutions and support to our clients. We ensure seamless integration and optimal use of LightBox's data and technology platforms, providing expert guidance and ongoing support to maximize the value of our tools. Leveraging industry knowledge and technical expertise, the Digital Solutions team helps clients streamline workflows, enhance data accuracy, and achieve superior decision-making outcomes.
  
  

Position Overview
  
As a Digital Solutions Data Engineer at LightBox, you will be responsible for designing, building, validating, and delivering data solutions to our customers.
  
You will collaborate with a highly motivated team of experienced data and software engineers, focusing on data creation, quality assurance, modeling, and architecting to address diverse use case scenarios. Your role involves developing scalable data ingestion pipelines, maintaining processes for ingesting, building, and validating spatial datasets, and leveraging your expertise in database management and Python to enhance client data solutions and ensure high-quality outputs. Data is typically delivered as standalone deliverables or within defined LightBox or client software environments.
  
LightBox data solutions are created using client data inputs, the LightBox data platform, and industry-standard GIS and data transformation/enrichment toolsets. These solutions provide property insights to the lending, insurance, real estate, environmental, and government sectors.
  
  

What you will do and achieve
  
Reporting to the Director of Digital Solutions, the Data Engineer will:
  
* Fulfill LightBox’s custom data deliveries to clients.
* Develop an in-depth understanding of LightBox data assets, infrastructure, and software, such as LandVision and SpatialStream.
* Analyze use cases and propose solutions to meet business objectives.
* Assess client requirements and develop data/software solutions accordingly.
* Model and architect data to address business problems.
* Analyze and resolve technical data and application issues.
* Create and maintain data pipelines to prepare and manage data for specific use cases.
* Develop, test, and document automated ETL (extract, transform, load) processes to meet business needs.
* Adhere to high-quality development principles while delivering solutions on time and within budget.
* Migrate existing workflows to newer infrastructures.
* Utilize SQL, ESRI ArcGIS, and other open-source GIS software to transform, enrich, and extend LightBox data assets for client delivery.
* Document data processing methodologies, best practices, and workflows concisely.
* Aggregate data from various sources and apply analytical techniques to uncover valuable insights and solve complex issues.
* Provide support, troubleshooting, modifications, enhancements, and maintenance for existing geospatial data processing scripts and tools.
* Develop data acceptance criteria, quality assurance plans, and automated testing routines.
* Investigate data-related issues and develop resolutions.
* Create tools and workflows to automate existing processes.


Education
  
  

* Bachelor’s degree or certificate in GIS, Geography, Computer Science, or a related discipline.
* Strong academic record with a solid foundation in GIS and Data Engineering.
* Familiarity with GIS standards, principles, best practices, open-source tools, and public domain data.


Experience
  
  

* 2-5 years of experience as a GIS Analyst, Data Engineer, or Data Analyst (qualified recent graduates will also be considered).


Key Knowledge & Skills
  
  

* Outstanding organizational, communication, analytical, and interpersonal skills.
* Ability to quickly understand technical products and explain concepts to non-technical audiences.
* Experience with project management techniques like Agile and Scrum
* Proven track record of meeting deadlines and managing multiple varied tasks.
* Fundamental knowledge in SQL (spatial), Python, ETL, and data management to aggregate, gather, manipulate, or validate data.
* Proficiency with GIS software packages and open-source tools (e.g., QGIS, ESRI, GRASS, GDAL, OGR).
* Experience utilizing Python modules, packages, and libraries.
* Experience with pipeline orchestration technology (e.g., Prefect, AirFlow).
* Proficiency with pipeline transformation tools, using Python and the Pandas library.
* Scripting experience.
* Ability to document workflows concisely.
* Commitment to exceeding assigned tasks and project expectations.
* Experience with cloud infrastructure (AWS), Git, Docker, Apigee, and Kubernetes
* Has knowledge of data security best practices (when handling sensitive data)


Core Competencies
  
  

* Keen interest in data engineering with a “tinkering” mindset.
* Excellent interpersonal, written, and oral communication skills.
* Driven to continually learn about and incorporate new technologies.
* Experience with implementing new technologies and continuous improvement of processes and workflows
* Thrive in a self-driven environment.
* Understanding and integrating human and machine workflows.
* Team player with the ability to work collaboratively and take on new tasks.
* Reliable problem solver with the ability to work efficiently and independently.
* Embraces challenges with a positive attitude.
* Passion for learning new concepts and skills.


Other Desirable Attributes
  
* 3+ years of experience in database design, data manipulation, and/or software engineering roles using SQL Server or similar RDBMS environments, including proficiency in stored procedures, views, optimizing queries and processes and ETL processes (Extract, Transform, Load).
* Proven experience in developing complex SQL queries to generate datasets for customers.
* Experience maintaining data quality across all stages of acquisition and processing, from data sourcing/collection to normalization and transformation.


LightBox's Diversity Commitment
  
  

At LightBox, we are dedicated to fostering a diverse workforce and creating an inclusive work environment that values everyone’s unique contributions, experiences, and perspectives. We believe in unity through diversity, cultivating a collaborative atmosphere that encourages creativity, initiative, and professional development. Our commitment includes offering a competitive salary and benefits package.
  
LightBox and its subsidiaries are equal opportunity employers, committed to prohibiting discrimination of any kind and providing equal employment opportunities to all employees and applicants, regardless of race, color, religion, sex, national origin, age, disability, or veteran status.
  
We believe that we are stronger together when we support, recognize, and embrace our differences.
  
  

Additional Information
  
This job description outlines the primary tasks and expectations of the position and does not encompass all responsibilities that may be assigned. Employees are expected to undertake additional tasks, responsibilities, and training as directed by their supervisors. Duties and responsibilities may evolve with business needs, with or without prior notice.
  
This role may require occasional overtime, including evenings, weekends, and holidays, to meet deadlines or accommodate customer requirements.
  
The position involves regular activities such as talking, hearing, walking, using hands, kneeling, crouching, and lifting up to 25 pounds. Reasonable accommodations will be considered for individuals with disabilities to facilitate the essential job functions.
  
We appreciate all applicants for their interest; however, only candidates selected for an interview will be contacted.
  
NO TELEPHONE CALLS OR AGENCY SOLICITATION PLEASE.
  
  

We thank all applicants in advance for their interest in this position, however, only those selected for an interview will be contacted.
  
  

This job description is a general listing of the required tasks and expectations of the position and in no way implies that the duties listed above are the employee’s only responsibilities. The employee is expected to perform other tasks, responsibilities and training as instructed by their supervisors. Duties and responsibilities may change at any time with or without notice.
  
  

This position may require additional hours outside of the standard work schedule including occasional holiday, evening and/or weekend hours in order to meet deadlines or to accommodate customers.
  
  

LightBox and all its holding companies are an equal opportunity/affirmative action employer. It is the policy of the LightBox and its holding companies to prohibit discrimination of any type and to afford equal employment opportunities to employees and applicants, without regard to race, color, religion, sex, national origin, age, disability, or veteran status.
  
  

NO TELEPHONE CALLS OR AGENCY SOLICITATION PLEASE.","https://www.indeed.com/cmp/Lightbox-4","","","","","","","","",""
"41d8dacb656efff9","indeed","https://www.indeed.com/viewjob?jk=41d8dacb656efff9","https://recruiting.adp.com/srccsh/public/RTI.home?r=5001075841500&c=2168707&d=SempraSoCalGas&rb=INDEED","Senior Data Engineer (Hybrid Schedule)","SoCalGas","Anaheim, CA, US","","2024-10-07","direct_data","yearly",109500.0,164300.0,"USD",False,"","","","","","About Us
  
  

At SoCalGas, we believe that every Californian deserves a resilient energy future. We are working to achieve that future by empowering California to reach its sustainability goals through innovation, collaboration, and decarbonization. As our state’s energy needs change, we will be there providing reliable energy that is clean, safe, and affordable to our 22 million customers.
  
  

In addition to helping shape the future of hydrogen technology and clean energy, as an employee of SoCalGas you’ll also enjoy an aggressive total compensation plan, multiple upward mobility opportunities and the ability to find a true work life balance. We also strive to reflect the communities we serve by attracting top talent and maintaining a diverse workforce. To discover more about how rewarding it is to work here, we invite you to visit these pages on our website: Our Mission; Diversity, Equity and Inclusion, Sustainability, In the Community, and Employee Benefits. Join SoCalGas today to share in our mission to build the cleanest, safest, and most innovative energy company in America!
  
  

Primary Purpose
  
Acts in a lead role in the design, development, implementation, maintenance, and enhancement of full cycle of data services – integration/transport, processing and/or visualization – and associated systems to support the analytics needs of data/business analysts or data scientists. Consults with and provides technical guidance to business partners, IT peer teams, regarding data requirements, design, processes and technical solutions. Leads analytics project workstreams and/or smaller integration or visualization projects. Works with multiple business subject areas/data domains, and applies expertise in multiple technology stacks and data services capabilities (integration, storage/processing, visualization).
  
  

Duties and Responsibilities
  
  

* Lead efforts to design, build, maintain, and troubleshoot data pipelines and processing systems to analytics applications. Lead small data analytics projects or initiatives. Manage the data catalog, metadata repository and any associated data management efforts. Work with vendor partners and/or coach junior IT staff to ensure data analytics solutions are designed and developed in a way that complies with architectural standards and established methodologies and practices.
* Solution development and support; Compile data requirements, perform data analysis and logical data modeling, define data and object elements. Build and scale data ingestion and transformation processes, to include batch (ETL, ELT), streaming, and/or virtualization. Build datasets, tools and documentation to enable analysts in all parts of the company to build their own analytics and reports. Design, build and implement applications to visualize performance data to enable actionable operational improvements. Provide after-hours support on a rotation basis.
* Collaboration/Continuous Improvement: Expand and continuously improve knowledge of business subject areas/data domain. Monitor and report to management on the status of project efforts, anticipating and identifying issues that inhibit the attainment of project goals and implementing corrective actions. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Lead and/or participate with IT staff, business/vendor partners, and other stakeholders in new product reviews, tests, and pilots. Foster and maintain good relationships with business partners, IT colleagues and vendor partners. Develop business knowledge and relationships to integrate activities with other IT departments to ensure successful implementation and support project efforts.
* Performs other duties as assigned (no more than 5% of duties).


$109500 - $164300 / year
  
  

Education
  
  

* Requires a Bachelor's Degree in Computer Science, Information Systems, Statistics or another quantitative field, or equivalent experience.


Experience
  
  

* Requires 6+ years of professional experience as a data engineer or equivalent.
* Experience building and optimizing ‘big data’ pipelines, architectures and data sets.
* Experience with Object-oriented programming or scripting languages desired (e.g., Python, SQL)
* Experience working in an agile/scrum environment
* Proven experience acting as a technical lead with ability to mentor and lead data engineers.
* Experience dealing with competing priorities in a fast-paced environment
* Proven track record of translating technical objectives into engineering reality


Knowledge, Skills and Abilities
  
  

* Expertise in several toolsets required such as big data tools: AWS Services, Athena, Quick sight, Hadoop, Spark, and Kafka.
* Proficient knowledge of data modeling, data architecture, data security and data governance practices
* Working knowledge of Python, SQL and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases tools.
* Fundamental technical knowledge of infrastructure concepts, including configuration setup on servers, routers, switches, firewalls etc
* Knowledge of Data Virtualization tools such as PowerBI, Business Objects, SAP Analytics Cloud, Cloud Services and Metadata Management tools.
* Strong analytic skills related to working with structured and unstructured datasets.
* Solid teamwork and interpersonal skills; ability to work well on cross-functional project teams and with vendor partners.
* Self-directed and comfortable supporting the data needs of multiple teams, systems and products
* Strong verbal and written communications skills, with an ability to express complex technical concepts in business terms
* Strong attention to detail with excellent analytical, problem-solving, and communication skills.
* Strong project management and organizational skills desired, operating as part of a team scoping, organizing, planning, and executing projects from the envisioning stage through implementation.
* Strong organizational and mentoring skills with experience in leading projects.


Benefits
  
  

SoCalGas offers a comprehensive benefits program to help support employees both personally and professionally. These benefits include, but are not limited to:
  
  

* Competitive pay & Annual Bonus program
* Medical, dental, and vision packages (plus free Mental Health resources/sessions)
* 401K company match & Company provided Pension Plan
* Work/Life Balance including generous PTO
* Wellness Programs/Classes
* Tuition/Education Reimbursement
* Career Development Tools & Resources through SoCalGas University


Follow us on social media to stay current with what we’ve been up to on X, Facebook, YouTube, and Instagram.
  
  

Equal Opportunity Employer Minorities/Women/Protected Veterans/Disabled","https://www.indeed.com/cmp/Socalgas","https://www.socalgas.com/careers","Los Angeles, CA","5,001 to 10,000","$1B to $5B (USD)","Headquartered in Los Angeles, SoCalGas® is the largest natural gas distribution utility in the United States.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/08bf69aefb81de22d40504d3a101512e","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/2e61b403898072f1ed2fa013c1346800","Scott Drury","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/14d4b7274bc3a83f80664af03936c4dc"
"3639903f97824b13","indeed","https://www.indeed.com/viewjob?jk=3639903f97824b13","https://jobs.cisco.com/jobs/ProjectDetail/Account-Executive-GES-WEST/1429738","Account Executive - GES WEST","Cisco","Irvine, CA, US","fulltime","2024-10-07","direct_data","yearly",137157.0,173672.0,"USD",True,"","","","","","**What You’ll Do**
------------------


We are seeking a dynamic Account Executive - Artificial Intelligence (AI) to join our strong and strategic sales team. As an AE (AI), you will drive the adoption of our AI solutions across various industries. You will identify potential clients, understand their specific needs, and provide tailored AI solutions that align to their business operations. This role requires a deep understanding of AI technologies and a strong ability to translate technical concepts to a diverse audience.**Who You’ll Work With**
------------------------


The Cloud + AI Infrastructure team delivers one scalable strategy with local execution for data center customer transformation and growth. We are the worldwide go-to-market compute and data center networking engine assembling market transitions and engaging with sellers to fuel growth for customers and Cisco. Alongside our colleagues, Cloud & AI Infrastructure builds the sales strategy, activates sellers and technical communities, and accelerates selling every single day.

**Who You Are**
---------------


You will develop and execute a sales strategy to achieve sales targets for AI products and services and identify and prioritize target accounts and develop relationships with key decision-makers and partners. Engaging with clients to understand their business challenges and conducting detailed analysis to find opportunities for AI solutions are two dynamic skills you will bring to this role. You understand AI technical concepts and translate them into business value for clients.

**Minimum Qualifications**

* 8+ years of technology-related sales or account management experience
* Expertise in two or more data estate workloads like Microsoft’s Data & AI Platform (Azure Synapse Analytics, Azure Databricks, CosmosDB, Azure SQL, HDInsight, etc.), AWS (Redshift, Aurora, Glue), Google (BigQuery), MongoDB, Cassandra, Snowflake, Teradata, Oracle Exadata, IBM Netezza, SAP (HANA, BW), Apache Hadoop & Spark, MapR, Cloudera/Hortonworks, etc.
* A validated understanding of the business issues of large CSP, accelerated Computing/ Data Center technology/ Deep learning & machine learning.
* Experience using CRM software to run sales pipelines and customer relationships.

**Preferred Qualifications**

* Bachelor’s degree or equivalent experience in Business, Computer Science, Engineering, or a related field; advanced degree is a plus.
* Excellent verbal and written communication skills.
* Experience engaging with large hyperscalers.
* Experience with deep learning, data science, and NVIDIA GPUs.
* Track record of growing revenue for new innovative technology-based solutions.
* Certifications with Azure Data Engineer, Azure AI Engineer or equivalent industry certifications.


We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.

**Why Cisco?**

#WeAreCisco. We are all unique, but collectively we bring our talents to work as a team, to develop innovative technology and power a more inclusive, digital future for everyone. How do we do it? Well, for starters – with people like you!


Nearly every internet connection around the world touches Cisco. We’re the Internet’s optimists. Our technology makes sure the data traveling at light speed across connections does so securely, yet it’s not what we make but what we make happen which marks us out. We’re helping those who work in the health service to connect with patients and each other; schools, colleges, and universities to teach in even the most challenging of times. We’re helping businesses of all shapes and sizes to connect with their employees and customers in new ways, providing people with access to the digital skills they need and connecting the most remote parts of the world – whether through 5G, or otherwise.


We tackle whatever challenges come our way. We have each other’s backs, we recognize our accomplishments, and we grow together. We celebrate and support one another – from big and small things in life to big career moments. And giving back is in our DNA (we get 10 days off each year to do just that).


We know that powering an inclusive future starts with us. Because without diversity and a dedication to equality, there is no moving forward. Our 30 Inclusive Communities, that bring people together around commonalities or passions, are leading the way. Together we’re committed to learning, listening, caring for our communities, whilst supporting the most vulnerable with a collective effort to make this world a better place either with technology, or through our actions.


So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture geek? Many of us are. Passion for technology and world changing? Be you, with us! #WeAreCisco


  
**Message to applicants applying to work in the U.S. and/or Canada:**  

  

When available, the salary range posted for this position reflects the projected hiring range for new hire, full-time salaries in U.S. and/or Canada locations, not including equity or benefits. For non-sales roles the hiring ranges reflect base salary only; employees are also eligible to receive annual bonuses. Hiring ranges for sales positions include base and incentive compensation target. Individual pay is determined by the candidate's hiring location and additional factors, including but not limited to skillset, experience, and relevant education, certifications, or training. Applicants may not be eligible for the full salary range based on their U.S. or Canada hiring location. The recruiter can share more details about compensation for the role in your location during the hiring process.
U.S. employees have **access** to quality medical, dental and vision insurance, a 401(k) plan with a Cisco matching contribution, short and long-term disability coverage, basic life insurance and numerous wellbeing offerings. Employees receive up to twelve paid holidays per calendar year, which includes one floating holiday, plus a day off for their birthday. Employees accrue up to 20 days of Paid Time Off (PTO) each year and have access to paid time away to deal with critical or emergency issues without tapping into their PTO. We offer additional paid time to volunteer and give back to the community. Employees are also able to purchase company stock through our Employee Stock Purchase Program.


Employees on sales plans earn performance-based incentive pay on top of their base salary, which is split between quota and non-quota components. For quota-based incentive pay, Cisco typically pays as follows:


.75% of incentive target for each 1% of revenue attainment up to 50% of quota;


1.5% of incentive target for each 1% of attainment between 50% and 75%;


1% of incentive target for each 1% of attainment between 75% and 100%; and once performance exceeds 100% attainment, incentive rates are at or above 1% for each 1% of attainment with no cap on incentive compensation.


For non-quota-based sales performance elements such as strategic sales objectives, Cisco may pay up to 125% of target. Cisco sales plans do not have a minimum threshold of performance for sales incentive compensation to be paid.","https://www.indeed.com/cmp/Cisco","http://www.cisco.com","San Jose, CA","10,000+","more than $10B (USD)","Cisco wants you to bring your uniqueness, join teams to solve challenges, and work together to build an inclusive future for all with our technology. Be you, with us! #WeAreCisco!","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/b799172fd63cfb12d47f7d0f8f79a90b","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/38be96056d761c3c6ef6aa2306838f5a","Chuck Robbins","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/ceed9092560f39a61bb37cb1c2d9aacf"
"1aec9a54fe69ff9c","indeed","https://www.indeed.com/viewjob?jk=1aec9a54fe69ff9c","https://grnh.se/9aa82ca37us","Data Analytics Engineer","LUGANO","Newport Beach, CA, US","","2024-10-04","","yearly","","","USD",False,"","","","","","**About Us**



Guided by our core values – The Lugano Way – our team embodies a proactive mindset that fuels our drive for success. We work with a people-first mentality and foster an environment of continuous learning and mutual growth. Our ultimate goal? To consistently find a path to YES and deliver remarkable in all we do. Through innovation, teamwork, and collaboration, we bring this to life. Join us in shaping a future of brilliance and endless possibilities.

**Who You Are**



You have deep professional experience and are a technically proficient Data Analytics Engineer looking for an opportunity to become the cornerstone of Lugano's data infrastructure. You are excited to leverage your expertise in data analysis, software engineering, and statistical modeling to play a pivotal role in transforming raw data into strategic insights that propel the business forward.



In this newly created role due to growth, you will be reporting directly to the Vice President of technology and collaborating with diverse teams across multiple departments to innovate and implement solutions that streamline operations and boost performance. In addition, your precision, strong business acumen, and effective communication skills will be key to your success in this growth-fueled opportunity where you will have a direct impact in shaping the future of data at Lugano.



Does this sound like you? If so, apply today, and let's be remarkable together!


**What You Will Do**


* Design, develop, and maintain scalable data pipelines and workflows for processing and analyzing large-scale datasets.
* Perform complex data analysis to identify trends, patterns, and actionable insights.
* Build and optimize data models, algorithms, and machine learning models to support business objectives and uncover valuable business insights.
* Implement data-driven solutions for data extraction, transformation, and loading (ETL) processes.
* Develop and deploy data visualizations and reports to communicate and report findings to a wide variety of stakeholders and systems.
* Collaborate with departments across the organization to understand data requirements and deliver data solutions that support business goals and objectives.
* Ensure impeccable data quality and integrity through rigorous testing and validation.
* Stay current with industry trends and best practices in all things data engineering and analytics.


**What You Will Bring**


* Professional experience and proven success as a Data Engineer, or similar role, within a dynamic, fast-paced, high-growth organization.
* Expert-level proficiency in SQL and relational databases.
* Deep skills and experience with data warehousing, ETL frameworks, and Azure Data Analytics technology (Synapse, Data Lake, Azure Pipeline, Databricks, etc.)
* Experience with data visualization tools (e.g., Power BI) and statistical analysis tools.
* Solid understanding of machine learning techniques and algorithms is an advantage.
* Ability to translate complex analytical findings into clear and actionable insights.
* Possession of an analytical mindset and adept problem-solving skills, enabling effective identification and resolution of complex issues.
* Excellent organizational skills, enabling efficient management of tasks, priorities, and deadlines within a dynamic testing environment.
* Bachelor's degree in computer science, Engineering, Mathematics, Statistics, or a related field.


**Pay Transparency**



Targeted base compensation is $140,000 per year, plus annual bonus. The total compensation package is determined by work location and additional factors, including job-related skills, experience, and relevant education or training.


**Our Work Environment**

Our workplace is clean, orderly, appropriately lighted and ventilated with the proper safety compliance. Noise levels are considered low and daily physical activities are considered light: office work, seldom lifting up to 25 pounds, bending, stooping, kneeling, or walking. Employees must have the stamina to work long hours if assigned. Hours and days of work may vary by position. Reasonable accommodation may be made to allow people with disabilities to perform the essential functions of their job within the environment.

**Our Benefits**



Lugano Diamonds is a fast-growing company with many opportunities for you to master your craft and grow your career. We are proud to offer employees a generous compensation package that includes commission and bonus plans for all employees, multi-option healthcare plans, 401k with match, and paid time off. Join the team and carve your own path to the future.


**Being You at Lugano**



Lugano is committed to creating a diverse work environment that recruits and rewards employees based on capabilities and performance. We are inclusive, celebrate our differences, and welcome a broad range of perspectives and ideas without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.


**Join Our Team –** Where People, Leadership, Innovation, and Passion come first.



CCPA disclosure notice here.","https://www.indeed.com/cmp/Lugano","","","","","","","","",""
"6e395c261a610ef0","indeed","https://www.indeed.com/viewjob?jk=6e395c261a610ef0","https://skechers.wd5.myworkdayjobs.com/One-career-site/job/Manhattan-Beach-CA/Customer-Data-Platform-Manager_JR102158","Consumer Data Platform Engineer","Skechers","Manhattan Beach, CA, US","fulltime","2024-10-01","direct_data","yearly",110000.0,140000.0,"USD",False,"","","Retail","","benefits@skechers.com","Skechers is seeking a Consumer Data Platform Engineer to join the Digital Team. The ideal candidate will collaborate with business operations to design and implement ecosystem changes that drive revenue growth and enhance operational efficiency. They will work with the data and analytics team to design, develop, and maintain our Customer Data Platform (CDP) infrastructure, ensuring seamless data integration and high quality. Additionally, the candidate will liaise with our vendor to manage system maintenance and provide expert guidance.**Essential Job Responsibilities**

* Collaborate with marketing operations, analytics, and IT teams to journey requirements and deliver solutions that enhance customer insights and personalization.
* Help maintaining robust and scalable data pipelines and ETL processes specifically for Customer Data Platforms.
* Implement and optimize data integration processes to ensure seamless data flow from multiple sources into the CDP.
* Ensure data quality and consistency within the CDP by implementing robust data validation and cleansing procedures.
* Develop and maintain comprehensive documentation related to CDP data pipelines, data models, and ETL processes.
* Monitor and troubleshoot data pipeline issues, ensuring minimal downtime and data loss.
* Ensure compliance with data privacy regulations and best practices in data security.
* Utilize serverless AWS services (e.g., AWS Lambda, Amazon S3, Amazon DynamoDB, AWS Glue) to build scalable and efficient data solutions.
* Stay updated with the latest trends and technologies in CDP, data engineering, and serverless computing, recommending improvements to existing systems.

**Supervisory Responsibilities**

* No
**Qualifications**
------------------

* Bachelor’s degree in Computer Science, Data Science, or a related field.
* 3-5 years of experience as a Data Engineer, with specific experience in Customer Data Platforms (e.g., ActionIQ, Segment, Tealium, mParticle, Adobe Experience Platform).
* Strong proficiency in SQL and experience with relational databases (e.g., PostgreSQL, MySQL, Oracle).
* Experience with non-relational document databases (e.g., MongoDB, DynamoDB).
* Experience with big data technologies (e.g., Hadoop, Spark, Kafka, Flink).
* Proficiency in programming languages such as Python, Java, or Scala.
* Familiarity with cloud platforms (e.g., AWS, Google Cloud, Azure) and their data services.
* Hands-on experience with serverless AWS services (e.g., AWS Lambda, Amazon S3, Amazon DynamoDB, AWS Glue).
* Strong analytical skills and experience with data analysis tools and techniques.
* Strong problem-solving skills and the ability to troubleshoot complex data issues.
* Excellent communication and collaboration skills.
* Able to work a hybrid schedule (2-3 days) out of the Manhattan Beach, Ca office.

**Preferred Qualifications**

* Understanding of data modeling and database design principles.
* Experience with real-time data processing and streaming technologies.
* Knowledge of data warehousing solutions (e.g., Databricks, Amazon Redshift, Google BigQuery).
* Knowledge of data privacy regulations and best practices in data security.
* Familiarity with AI and machine learning frameworks (e.g., TensorFlow, PyTorch, Scikit-Learn).
* Technical understanding of Marketing Automation tools (Marketo/Salesforce Marketing Cloud etc.), Salesforce CRM, Analytics platforms.

The salary range for this position is $110,000-$140,000 USD per year.

**About Skechers**  

Skechers (NYSE: SKX), a global, Fortune 500® brand develops and markets a diverse range of lifestyle and performance footwear, apparel, and accessories. Developing comfort technologies is the foundation of all we do – delivering stylish, innovative, and quality products. Serving over 180 countries and territories, Skechers connects customers to products through department and specialty stores, e-commerce and digital stores, and through our more than 5,200 company-and third-party-owned retail locations. Headquartered in Southern California, with offices and distribution centers around the globe, Skechers has spent 30 years helping people of all ages look and feel good.

 **Equal Employment Opportunity**  

Skechers is committed to providing a safe, inclusive, and respectful work environment. Skechers provides equal employment opportunities for all employees and applicants for employment without regard race, color, religion, gender, gender identification and expression, national origin, marital status, age, disability, genetic information, military status, sexual orientation, or any other protected characteristic established by local, state or federal law.

 **Reasonable Accommodation**  

Applicants for employment who require a reasonable accommodation to apply for a job should request appropriate accommodation by emailing benefits@skechers.com.  

To perform this job successfully, an individual must be able to perform each job responsibility satisfactorily. The skills, abilities and physical demands described are representative of those duties that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodation may be made to enable individuals with disabilities, who are otherwise qualified for the job position, to perform the essential functions.","https://www.indeed.com/cmp/Skechers","https://www.skechers.com","228 S Sepulveda Blvd
Manhattan Beach, California 90266

","10,000+","$5B to $10B (USD)","Skechers is focused on designing products that deliver style, comfort, innovation, and quality at a reasonable price.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/a0daef7c976e56f87f4c942a8c7ee7d9","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/cb3255f55a2f1160548c568d038cf3f5","Robert Greenberg – CEO, Founder","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/ad29aac2746990ea8c1c5946d1539554"
"0b0fc1420e07a770","indeed","https://www.indeed.com/viewjob?jk=0b0fc1420e07a770","https://workforcenow.adp.com/mascsr/default/mdf/recruitment/recruitment.html?cid=a6473ed1-cdd4-45f8-bc74-747398481523&ccId=19000101_000001&jobId=517396&source=IN&lang=en_US","Data Analytics Architect","Fastener Distribution Holdings","Commerce, CA, US","fulltime","2024-09-30","direct_data","yearly",130000.0,150000.0,"USD",False,"","","","","","**FDH Aero** is a trusted global supply chain partner for aerospace and defense companies. With more than 55 years of experience, it specializes in c-class components that include hardware, electrical, chemical, and consumable products and services for global OEM and aftermarket customers. At FDH Aero, we understand that the strength of our brand comes from our people, and our culture empowers every team member to contribute and grow. As a global team, our culture is rooted in five (5) core values that begin with the words “We are” and include: service-first, respectful, amplifiers, open-minded and accountable.**FDH Aero** is headquartered in Commerce, California, and has operations across the Americas, EMEA and APAC. FDH Aero has locations in 14 countries across the globe, with more than 1,200 best-in-industry employees and over 650,000 square feet of inventory space.


For more information, please visit the FDH Aero website.

  

The Data Analytics Architect will be responsible for designing, implementing, and maintaining data pipelines and infrastructure to support our organization's data-driven decision-making processes. You will work closely with analysts and other stakeholders to ensure data availability, quality, and reliability. **Responsibilities:*** Design, build, and maintain robust data pipelines that extract, transform, and load (ETL) data from various sources into data warehouses or data lakes. These pipelines should be scalable and efficient
* Manage and optimize data warehouses to ensure high performance, availability, and scalability
* Implement best practices for data modeling and schema design
* Integrate data from different systems and sources, ensuring data consistency and accuracy
* Collaborate with cross-functional teams to understand data requirements
* Implement data quality checks and validation processes to identify and rectify data inconsistencies or anomalies
* Ensure data is accurate, complete, and up-to-date
* Optimize data processing and query performance to meet business requirements
* Identify and resolve bottlenecks in data pipelines and database systems
* Implement and maintain data security measures to protect sensitive information
* Follow best practices for data encryption, access control, and compliance with data privacy regulations
* Create and maintain documentation for data pipelines, processes, and data schemas and ensure knowledge sharing within the team
* Set up monitoring and alerting systems to proactively detect and address issues with data pipelines and infrastructure
* Perform troubleshooting and root cause analysis
* Design systems that can scale with growing data volumes
* Automate routine tasks to improve operational efficiency
* Collaborate with analysts, software engineers, and other stakeholders to understand data requirements and deliver solutions that meet their needs
* Stay updated on emerging technologies and tools in the data engineering field
* Evaluate and recommend new technologies that can enhance data processing capabilities
 **Basic Qualifications:**

* Bachelor’s degree in computer science, or related field
* Proven 2-4 years of experience as a Data Engineer, preferably in a senior or lead role
* Strong programming skills in languages such as Python, Java, or Scala
* Proficiency in SQL and experience with relational and NoSQL databases
* Expertise in data warehousing and ETL processes
* Familiarity with data integration and data modeling concepts
* Knowledge of big data technologies such as Hadoop, Spark, or Kafka is a plus
* Experience with cloud platforms like AWS, Azure, or Google Cloud
* Strong problem-solving and troubleshooting skills
* Excellent communication and collaboration skills

  

Job Type: Full Time


Pay: $130,000-$150,000 annually

 **FDH** is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability status, protected veteran status, or any other characteristic protected by law.","https://www.indeed.com/cmp/Fastener-Distribution-Holdings","https://fdhaero.com/","","","","","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/5f110e72d18d1af860027a73a62116a6","","",""
"3f4d725111d903bc","indeed","https://www.indeed.com/viewjob?jk=3f4d725111d903bc","https://careers.hireology.com/nationsinfocorp/2031557/description?ref=indeed.com&source=indeed","Business Intelligence Data Engineer","Nations Info Corp.","Thousand Oaks, CA, US","fulltime","2024-09-30","direct_data","yearly",70000.0,80000.0,"USD",False,"","","","","","Nations Info Corp is looking for a talented Business Intelligence Data Engineer. If you love working with metrics, dashboards, databases, and know exactly what “left join” and “p-value” mean, this is the job for you. We are looking for someone that is passionate about our subscription model online business. You will gather, organize and interpret large amounts of business intelligence to continuously optimize our business.  



You will work cross-functionally with smart and dedicated professionals, and will be a valuable member of our Business Intelligence team.  


**Responsibilities**
* Provide ETL design and development for our Business Intelligence data warehouse


* Understand the underlying database schema and create MySQL queries


* Use DBT Data Build Tool to clean and transform the business data


* Stay on top of best practices to ensure data quality, data governance and data security standards


* Assist in reporting, A/B testing, and analytical projects


* Use the Sisense business intelligence tool to create and maintain dashboards for the multiple business units


* Analyze data, present the results and make recommendations to the business units


* Support data needs for existing and new predictive models

  


**Requirements**
* Minimum 2 years of experience in data engineering and analytics


* Expert knowledge using SQL for data querying and manipulation


* Experience with data visualization tools


* Experience supporting predictive data modeling; Data model development experience using R and Python preferred


* Strong analytical and communication skills


* Willingness to learn about business operations and new technologies, including digital subscription billing, machine learning, etc

  


**Employment Details**
* Location: Westlake Village, CA
* Status: Full time
* Benefits include company sponsored 401K, with company match
* Additional benefits include: Health, Vision and Dental Insurance, Life Insurance, Long Term Disability
* Vacation Benefits
* Salary: $70,000 - $80,000/yr, based on experience
  


**About Nations Info Corp**



Founded in 2005, Nations Info Corp is a leading online provider of real estate and financial information and services to home buyers, investors and real estate professionals. Our powerful technology aggregates and synthesizes massive amounts of real estate data including distressed properties, which is otherwise difficult to find and interpret, into formats which are easy to access, use and ultimately empowering for home buyers. Our goal is to present information that will help consumers make informed home buying or financial decisions. Through our industry-leading platforms such as RealtyStore.com and RealtyTrac.com, we provide customers with exclusive access to millions of properties that are otherwise hard to find, while helping investors unlock real estate investment opportunities easily and quickly.



We are continually looking to the future by innovating and bringing new data driven, consumer products to the marketplace in different verticals. To accomplish these goals, we've grown an extraordinarily talented team and have established office locations in Westlake Village, CA and Santa Barbara, CA. Our efforts are grounded in a culture of collaboration, ownership and decisiveness, where every team member is empowered with tools, resources and support to produce high quality and high impact work, to take the initiative and strive for continuous improvement, and to drive projects into success. If you value the opportunity to collaborate with creative problem solvers in an inclusive, transparent and intellectually stimulating environment, this could be the place for you to do your best work yet.



Learn more about us here - https://nationsinfocorp.com/","https://www.indeed.com/cmp/Nations-Info-Corp.","","","","","","","","",""
"0258244f34e5e691","indeed","https://www.indeed.com/viewjob?jk=0258244f34e5e691","https://rr.jobsyn.org/C1777DEC2E244BC1A69FF9E5C42468111554","Principal Data Engineer Architect IS","Providence","Irvine, CA, US","fulltime","2024-09-30","direct_data","hourly",65.0,106.0,"USD",True,"","","","","","**Description**


**Principal Data Engineer Architect**


Renton, WA


Providence is seeking a full-time Principal Data Engineer Architect responsible to design and build modern data-centric software applications to support clinical and operational processes across all parts of the healthcare system. These applications leverage cloud computing, big data, data science, and modern software development methodologies and frameworks. Build data pipelines and transformations, data enrichment processes, provisioning layers, and user interfaces to meet the requirements of key initiatives. Design, build and deliver quantitative applications that improve operations and generate value. Participate in DevOps, Agile, and continuous integration frameworks. Stay abreast of emerging technologies, open source projects, and best practices in the field. Data warehousing, big data, enterprise search, business intelligence, analytics, modern and mobile applications. Build processes that are fault-tolerant, self-healing, reliable, resilient and secure. Work effectively and in real-time with other developers, product managers, and customers to deliver on collective goals. Actively participate in code reviews, support the overall code base, and support the establishment of standard processes and frameworks. Take an open and transparent approach to the work by sharing code and expertise, by consulting peers for problem-solving, and by being a mentor to peers. Be a recognized subject matter expert in the data engineering and app dev disciplines and build expert-to-expert relationships with similar SMEs across the enterprise. Display maturity in working with code, systems and designs. Ability to design and architect robust data models and workflows. Employee has option to telecommute full-time from any state in which Providence has an office (currently: AK, WA, OR, CA, NM, MT, TX).


Applicants must have:


* Bachelor’s degree in Computer Engineering, Electronics Engineering, Computer Science, or related field.
* 10 years of experience as a Data Engineer, Data Architect, Software Developer, or related occupation.
* 10 years experience in cloud computing and data warehousing, Linux, Hadoop, Spark, and other NoSQL platforms in the healthcare industry.
* 10 years experience with relational database platforms, database design, OLAP/data warehousing.
* Past professional experience working with unstructured and semi-structured data file formats and APIs

**Why Join Providence?**


Our best-in-class benefits are uniquely designed to support you and your family in staying well, growing professionally, and achieving financial security. We take care of you, so you can focus on delivering our Mission of caring for everyone, especially the most vulnerable in our communities.


**About Providence**


At Providence, our strength lies in Our Promise of “Know me, care for me, ease my way.” Working at our family of organizations means that regardless of your role, we’ll walk alongside you in your career, supporting you so you can support others. We provide best-in-class benefits and we foster an inclusive workplace where diversity is valued, and everyone is essential, heard and respected. Together, our 120,000 caregivers (all employees) serve in over 50 hospitals, over 1,000 clinics and a full range of health and social services across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. As a comprehensive health care organization, we are serving more people, advancing best practices and continuing our more than 100-year tradition of serving the poor and vulnerable.


**About the Team**


Providence Shared Services is a service line within Providence that provides a variety of functional and system support services for our family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise.


Providence is proud to be an Equal Opportunity Employer. We are committed to the principle that every workforce member has the right to work in surroundings that are free from all forms of unlawful discrimination and harassment on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law. We believe diversity makes us stronger, so we are dedicated to shaping an inclusive workforce, learning from each other, and creating equal opportunities for advancement.


**About Providence**


At Providence, our strength lies in Our Promise of “Know me, care for me, ease my way.” Working at our family of organizations means that regardless of your role, we’ll walk alongside you in your career, supporting you so you can support others. We provide best-in-class benefits and we foster an inclusive workplace where diversity is valued, and everyone is essential, heard and respected. Together, our 120,000 caregivers (all employees) serve in over 50 hospitals, over 1,000 clinics and a full range of health and social services across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. As a comprehensive health care organization, we are serving more people, advancing best practices and continuing our more than 100-year tradition of serving the poor and vulnerable.


The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.


Providence offers a comprehensive benefits package including a retirement 401(k) Savings Plan with employer matching, health care benefits (medical, dental, vision), life insurance, disability insurance, time off benefits (paid parental leave, vacations, holidays, health issues), voluntary benefits, well-being resources and much more. Learn more at providence.jobs/benefits.


**About the Team**


Providence Shared Services is a service line within Providence that provides a variety of functional and system support services for our family of organizations across Alaska, California, Montana, New Mexico, Oregon, Texas and Washington. We are focused on supporting our Mission by delivering a robust foundation of services and sharing of specialized expertise.


Providence is proud to be an Equal Opportunity Employer. We are committed to the principle that every workforce member has the right to work in surroundings that are free from all forms of unlawful discrimination and harassment on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law. We believe diversity makes us stronger, so we are dedicated to shaping an inclusive workforce, learning from each other, and creating equal opportunities for advancement.


**Requsition ID:** 318475


**Company:** Providence Jobs


**Job Category:** IT Administration


**Job Function:** Information Technology


**Job Schedule:** Full time


**Job Shift:** Day


**Career Track:** Business Professional


**Department:** 4011 SS IS HI DP 3


**Address:** CA Irvine 3345 Michelson Dr


**Work Location:** Providence Health System Office-Irvine


**Workplace Type:** On-site


**Pay Range:** $65.03 - $106.68


The amounts listed are the base pay range; additional compensation may be available for this role, such as shift differentials, standby/on-call, overtime, premiums, extra shift incentives, or bonus opportunities.","https://www.indeed.com/cmp/Providence-959155fe","http://www.providence.jobs","Renton, WA","10,000+","$100M to $500M (USD)","Providence is a not-for-profit network of hospitals, care centers, health plans, clinics, home health care and services continuing a more than 100-year tradition of serving the poor and vulnerable.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/3fb09f5772b2f0fa41003ed27a771303","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/cd0fe67e2a25093d167cd6a7681fa3a9","Rod Hochman, MD",""
"285e63d06a1fb721","indeed","https://www.indeed.com/viewjob?jk=285e63d06a1fb721","http://www.indeed.com/job/data-engineer-databricks-285e63d06a1fb721","Data Engineer-Databricks","WeVision LLC","Irvine, CA, US","fulltime","2024-09-30","direct_data","yearly",105000.0,140000.0,"USD",True,"","","","","","**What You’ll Do**

* Design, develop, optimize, and maintain data architecture and pipelines that adhere to ETL principles and business goals
* Collaborate with data engineers, data consumers, and other team members to come up with simple, functional, and elegant solutions that balance the data needs across the organization
* Solve complex data problems to deliver insights that helps the organization achieve its goals
* Create data products that will be used throughout the organization
* Advise, consult, mentor and coach other data and analytic professionals on data standards and practices
* Foster a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytic solutions
* Develop and deliver documentation on data engineering capabilities, standards, and processes; participate in coaching, mentoring, design reviews and code reviews
* Partner with business analysts and solutions architects to develop technical architectures for strategic enterprise projects and initiatives.
* Deliver awesome code

**What You’ll Bring**

* 7+ years relevant and progressive data engineering experience
* Deep Technical knowledge and experience in Databricks, Python, Scala, Microsoft Azure architecture and platform including Azure Event Hub and ADF (Azure Data Factory) pipelines
* Hands-on experience working with data pipelines using a variety of source and target locations (e.g., Databricks, SQL Server, Data Lake, file-based, SQL and No-SQL database)
* Experience in engineering practices such as development, code refactoring, and leveraging design patterns, CI/CD, and building highly scalable data applications and processes
* Experience developing batch ETL pipelines; real-time pipelines are a plus
* Knowledge of advanced data engineering concepts such as dimensional modeling, ETL, data governance, data warehousing involving structured and unstructured data
* Thorough knowledge of SQL Server including T-SQL and stored procedures
* A successful history of manipulating, processing and extracting value from large disconnected datasets.
* Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
* Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.

Job Type: Full-time

Pay: $105,000.00 - $140,000.00 per year

Work Location: Hybrid remote in Irvine, CA 92618","https://www.indeed.com/cmp/Wevision-LLC","","","","","","","","",""
"9311a66f0de79418","indeed","https://www.indeed.com/viewjob?jk=9311a66f0de79418","http://www.indeed.com/job/data-engineer-9311a66f0de79418","Data Engineer","WeVision LLC","Irvine, CA, US","fulltime","2024-09-30","direct_data","yearly",105000.0,140000.0,"USD",True,"","","","","","The Ad Intelligence team is under Ad Platforms and its mission is to transform advertising and Ad platform with data and AI across TV and streaming video. We build solutions to measure and optimize every aspect of the advertising life cycle. Our tenant is a strong cross-domain team to deliver E2E solutions covering tech areas ranging from machine learning, big data, microservices to data visualization. Our team is seeking a data engineer who will be a core team member for our advertising data platform engineering group. This engineering group focuses on big data infrastructure, operational data, audience solution, inventory forecasting and full funnel measurements as a foundation layer for Ad Platforms.

**WHAT YOU’LL DO**

· Build components of large-scale data platform for real-time and batch processing, and own features of big data applications to fit evolving business needs

· Build next-gen cloud based big data infrastructure for batch and streaming data applications, and continuously improve performance, scalability and availability

· Contribute to the best engineering practices, including the use of design patterns, CI/CD, code review and automated test  
Chip in ground-breaking innovation and apply the state-of-the-art technologies

· As a key member of the team, contribute to all aspects of the software lifecycle: design, experimentation, implementation and testing.

· Collaborate with program managers, product managers, SDET, and researchers in an open and innovative environment

**WHAT TO BRING**

· Bachelor or above in computer science or EE

· 4+ years of professional programming in Java, Scala, Python, and etc.

· 3+ years of big data development experience with technical stacks like Spark, Flink, Singlestore, Kafka, Nifi and AWS big data technologies  
Knowledge of system, application design and architecture

· Experience of build industry level high available and scalable service  
Passion about technologies, and openness to interdisciplinary work

**Preferred Qualifications**

· Experience with processing large amount of data at petabyte level

· Demonstrated ability with cloud infrastructure technologies, including Terraform, K8S, Spinnaker, IAM, ALB, and etc.

· Experience with ClickHouse, Druid, Snowflake, Impala, Presto, Kinesis, etc.

· Experience in widely used Web framework (React.js, Vue.js, Angular, etc.) and good knowledge of Web stack HTML, CSS, Webpack

Job Type: Full-time

Pay: $105,000.00 - $140,000.00 per year

Work Location: Hybrid remote in Irvine, CA 92618","https://www.indeed.com/cmp/Wevision-LLC","","","","","","","","",""
"3e38769f79433fc2","indeed","https://www.indeed.com/viewjob?jk=3e38769f79433fc2","https://jobs.uci.edu/jobs/93113/job?utm_source=indeed_integration&iis=Job%20Board&iisn=Indeed&indeed-apply-token=73a2d2b2a8d6d5c0a62696875eaebd669103652d3f0c2cd5445d3e66b1592b0f","Senior Data Engineer - Enterprise Data and Analytics - FT - Day - Remote","UC Irvine Health","Irvine, CA, US","fulltime","2024-09-27","direct_data","yearly",104900.0,198900.0,"USD",True,"","","Health Care","","eec@uci.edu","Overview:
**UCI Health** is the clinical enterprise of the University of California, Irvine, and the only academic health system based in Orange County. UCI Health is comprised of its main campus, UCI Medical Center, a 459-bed, acute care hospital in in Orange, Calif., four hospitals and affiliated physicians of the UCI Health Community Network in Orange and Los Angeles counties and ambulatory care centers across the region. Listed among America’s Best Hospitals by U.S. News & World Report for 23 consecutive years, UCI Medical Center provides tertiary and quaternary care and is home to Orange County’s only National Cancer Institute-designated comprehensive cancer center, high-risk perinatal/neonatal program and American College of Surgeons-verified Level I adult and Level II pediatric trauma center, gold level 1 geriatric emergency department and regional burn center. UCI Health serves a region of nearly 4 million people in Orange County, western Riverside County and southeast Los Angeles County.
To learn more about UCI Health, visit www.ucihealth.org.
Responsibilities:
**Position Summary:**The incumbent will be responsible for implementing and maintaining the infrastructure, tools, and analytical application environments necessary to support the UCI Health enterprise strategic vision. The incumbent will work on a team of data specialists within the Enterprise Data and Analytics Department to ensure the proper configuration, movement, transformation, and quality of data as it flows from multiple source systems towards ultimate analytical consumption. Initial projects will include the implementation of an infrastructure migration to the cloud along with future expansion of the data platform for dynamic reporting and advanced analytics capabilities.
Qualifications:
**Total Compensation**
We offer a wealth of benefits to make working at UCI even more rewarding. These benefits may include medical insurance, sick and vacation time, retirement savings plans, and access to a number of discounts and perks. Please utilize the links listed here to learn more about our compensation practices and benefits. **Required Qualifications:*** Strong written and verbal communication skills
* Must possess the skill, knowledge and ability essential to the successful performance of assigned duties
* Must demonstrate customer service skills appropriate to the job
* Experience maintaining technical documentation and reviewing code within a centralized code repository
* Excellent written and verbal communication skills in English
* Bachelor’s degree in Computer Science (or related field) or equivalent work experience
* Ability to maintain a work pace appropriate to the workload
* Ability to establish and maintain effective working relationships across the Health System
* 3+ years with SQL or NoSQL databases and data warehousing technologies
* 3+ years hands-on experience with ETL Tools or Business Intelligence
* 2+ years of hands-on experience creating data pipelines using Python
* 2+ years hands-on experience as a Data Engineer

 **Preferred Qualifications:*** Knowledge of University and Medical Center organizations, policies, procedures and forms
* Experience working with data governance and a data catalog platform (e.g., Collibra)
* Experience performing unit tests and troubleshooting complex issues/efforts with other team members or cross divisional teams
* Experience creating and optimizing data pipelines capable of ingesting and integrating data from multiple heterogenous sources with advanced analytics capabilities (e.g., NLP, ML)
* Ability to work in agile team structure
* 2+ years of hands-on experience in pipeline orchestration tools, logging, monitoring & alerting, troubleshooting, and automated testing & deployments (CI/CD), preferably using cloud-based technologies (e.g., Azure, Databricks, AWS)

 **Conditions of Employment:**
The University of California, Irvine (UCI) seeks to provide a safe and healthy environment for the entire UCI community. As part of this commitment, all applicants who accept an offer of employment must comply with the following conditions of employment:* Background Check and Live Scan
* Legal Right to Work in the United States
* Vaccination Policies
* Smoking and Tobacco Policy
* Drug Free Environment


The following additional conditions may apply, some of which are dependent upon business unit or job specific requirements.* California Child Abuse and Neglect Reporting Act
* E-Verify
* Pre-Placement Health Evaluation


Details of each policy may be reviewed by visiting the following page: https://hr.uci.edu/new-hire/conditions-of-employment.php **Closing Statement:**
The University of California, Irvine is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, age, protected veteran status, or other protected categories covered by the UC nondiscrimination policy.
  

  

We are committed to attracting and retaining a diverse workforce along with honoring unique experiences, perspectives, and identities. Together, our community strives to create and maintain working and learning environments that are inclusive, equitable, and welcoming.
  

  

UCI provides reasonable accommodations for applicants with disabilities upon request. For more information, please contact UCI's Employee Experience Center (EEC) at eec@uci.edu or at (949) 824-0500, Monday - Friday from 8:30 a.m. - 5:00 p.m.","https://www.indeed.com/cmp/Uc-Irvine-Health","http://careers.ucirvinehealth.org/","Orange, CA","1,001 to 5,000","","UC Irvine Health is committed to attracting talented employees to continue to build on the organization's strengths and achievements.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/f719f6d113695ec78bc684eac0982507","","",""
"92bb044c1739cde2","indeed","https://www.indeed.com/viewjob?jk=92bb044c1739cde2","https://careers.kiausa.com/job/Irvine-Emerging-Field-Data-EngineerSpecialist-Cali-92606/1217775200/?feedId=269400&utm_source=Indeed&utm_campaign=KIA_Indeed","Emerging Field Data Engineer/Specialist","Kia America, Inc.","Irvine, CA, US","","2024-09-27","direct_data","yearly",72328.0,96838.0,"USD",False,"","","","","","At Kia, we’re creating award-winning products and redefining what value means in the automotive industry. It takes a special group of individuals to do what we do, and we do it together. Our culture is fast-paced, collaborative, and innovative. Our people thrive on thinking differently and challenging the status quo. We are creating something special here, a culture of learning and opportunity, where you can help Kia achieve big things and most importantly, feel passionate and connected to your work every day.


Kia provides team members with competitive benefits including premium paid medical, dental and vision coverage for you and your dependents, 401(k) plan matching of 100% up to 6% of the salary deferral, and paid time off. Kia also offers company lease and purchase programs, company-wide holiday shutdown, paid volunteer hours, and premium lifestyle amenities at our corporate campus in Irvine, California.

**Status**
----------


Exempt**Summary**
-----------


The purpose of this position is to support the Emerging Field Data Manager and Data Evaluation Team (DET) by identifying at an early stage in a model’s life cycle, any emerging potential safety and noncompliance issues through Kia’s Safety Data Analytics Infrastructure (SDAI) system and other supporting applications. This includes review of Kia America (KUS) warranty, Techline, Customer Care, field reports, and quality information reports, as well as NHTSA Vehicle Owner Questionnaires (VOQs) and other data sources, as applicable.


This position will be responsible for performing detailed screening of potential safety issue alerts and escalating relevant alerts for further data analysis and/or investigation. This involves review of data across data sources to identify frequency, severity, and detectability of alerted issues. The position will also provide verbal reports to management, other DET members, and Forensic Engineering & Investigations team members, and support data analysis efforts in the investigation of potential safety and noncompliance issues.

**Major Responsibilities**
--------------------------

**1st Priority - 40%**


Perform detailed screening of potential safety issue alerts and escalate relevant alerts for further data analysis and/or investigation. Work from SDAI dashboards to identify frequency, severity, and detectability of alerted issues.

**2nd Priority -15%**


Develop sophisticated monitoring criteria to ensure that any developments on closed cases are tracked in a timely manner.

**3rd Priority - 30%**


Evaluate escalated alerts for any potential trends and communicate findings to Emerging Field Data Manager. Collaborate with the Data Evaluation Team or Forensic Engineering and Investigation Team to support further data analysis.

**4th Priority - 15%**


Assist in the continuous improvement and development of Safety Data Analytics Infrastructure (SDAI) by creating training data for improving machine learning model accuracy and communicating opportunities to improve efficiency to Emerging Field Data Manager.

**Education/Certification**
---------------------------

* Engineer: BS degree in Engineering or Automotive Technology or equivalent work experience required.
* Specialist: Bachelors degree in technical field or equivalent work experience
**Overall Experience**
----------------------

* 3-7 years of experience in technical positions such as safety analysis, product quality, technical customer assistance, or in a product engineering environment.
* Written and oral technical communications experience.
**Directly Related Experience**
-------------------------------

* Automotive, aerospace, commercial vehicle, or similar technical work experience required
* Working knowledge of statistical analysis concepts and software.

**Other Requirements:**

* Schedule(s) may vary due to needs of the business including but not limited to working outside of normal business hours, travel, weekends and/or holidays.
* Perform other duties as assigned.
**Skills**
----------


Basic knowledge of SAS programing language and Structured Query Language (SQL).
Excellent analytical skills and attention to detail.
Excellent teamwork skills.
Excellent written and oral communication skills.
Intermediate knowledge of automotive systems and components.
Knowledge of PC software such as Microsoft Excel and PowerPoint.
Knowledge of SAS Visual Analytics.
Knowledge of statistics.**Competencies**
----------------


Care for People
Chase Excellence, Every Day
Dare to Push Boundaries
Empower People to Act
Move Further, Together**Pay Range**


$72,328 - $96,838


Pay will be based on several variables that are unique to each candidate, including but not limited to, job-related skills, experience, relevant education or training, etc.

 ***Equal Employment Opportunities***

*KUS provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, ancestry, national origin, sex, including pregnancy and childbirth and related medical conditions, gender, gender identity, gender expression, age, legally protected physical disability or mental disability, legally protected medical condition, marital status, sexual orientation, family care or medical leave status, protected veteran or military status, genetic information or any other characteristic protected by applicable law. KUS complies with applicable law governing non-discrimination in employment in every location in which KUS has offices. The KUS EEO policy applies to all areas of employment, including recruitment, hiring, training, promotion, compensation, benefits, discipline, termination and all other privileges, terms and conditions of employment.*

  



*Disclaimer**: The above information on this job description has been designed to indicate the general nature and level of work performed by employees within this classification and for this position. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities, and qualifications required of employees assigned to this job.*","https://www.indeed.com/cmp/Kia-America,-Inc.","","","","","","","","",""
"445dc512c7a95a4f","indeed","https://www.indeed.com/viewjob?jk=445dc512c7a95a4f","https://d.hodes.com/r/tp2?e=se&tv=pixel_tracker&aid=pacificlife&p=web&se_ca=indeed&se_ac=click&se_la=21083781&u=https%3A%2F%2Fpacificlife.wd1.myworkdayjobs.com%2FPacificLifeCareers%2Fjob%2FNewport-Beach-CA-700%2FLead-Data-Engineer_R13177%3Futm_medium%3Dsymphonytalent-jobads%26utm_campaign%3DInformation%2520Technology%26utm_content%3DLead%2520Data%2520Engineer%26utm_term%3DR13177%26utm_source%3DIndeed%26source%3DAPPLICANT_SOURCE-3-19&se_pr=e8b9312d2ba0edda&se_va=4855&tr_af=organic&ti_id=2094_R13177","Lead Data Engineer","Pacific Life","Newport Beach, CA, US","fulltime","2024-09-27","direct_data","yearly",144630.0,176770.0,"USD",True,"","","Insurance, Insurance","","","**Job Description:**  

Pacific Life is investing in bright, agile, and diverse talent to contribute to our mission of innovating our business and creating superior customer experience. We are actively seeking a talented Lead Data Engineer to join our Enterprise data team in Newport Beach, CA. This role can be on-site, hybrid or 100% remote .
  
As a Lead Data Engineer , you will play a key role in Pacific Life’s growth and long-term success . This position will report to the Data & Technology Manager and will be responsible for delivering data engineering solutions within the newly formed 3 rd party data team . These solutions augment and enrich internal Pacific Life data with external 3 rd party data. This role brings value by deliver ing technology and processes that optimize the use of 3 rd party data through out Pacific Life.
  
  

**How you will make an impact:**  

Collaborate with architecture, data governance, and business stakeholders to deliver quality data
  
  

Technically lead and develop multiple data projects using agile methodology
  
  

Establish fault tolerant data pipelines to bring external data into internal data management platform
  
  

Enable data literacy and democratization of 3 rd party data within Pacific Life
  
  

**The experience you will bring:**  

8+ years of experience in analysis, design, development, and delivery of data
  
  

8+ years of experience and proficiency in SQL, ETL, data transformation, and data management tools (Snowflake, Redshift, Informatica, Matillion , DBT, Control-M )
  
  

Ability to technically lead data engineers and data analysts, review their work, and advise on patterns and best practices
  
  

4+ years of experience with DevOps and CI/CD
  
  

Ability to effectively communicate , facilitate and influence at a technical and functional level with project stakeholders and across the organization
  
  

Solid understanding of data modeling concepts & best practices
  
  

2+ years of experience leveraging 3 rd party datasets to enrich internal company data
  
  

**What makes you stand out:**  

2+ years of experience in Snowflake , Data build tool ( DBT ) , and cloud services
  
  

Experience with automation, scripting, and testing in a data delivery environment
  
  

Strong understanding of data catalogs, glossary, data quality, and effective data governance
  
  

Financial services domain knowledge
  
  

Data driven individual with ability to setup effective processes in your sphere of ownership
  
  

Strong communication with the ability to translate business requirements into technical specifications
  
  

Demonstrated e xperience designing robust, complex, and strategic data solutions
  
  

Deep understanding of database design principles, data modeling, and data warehousing system knowledge
  
  

Ability to set domain data strategies that align with organizational goals
  
  

You can be who you are.
  
  

People come first here. We’re committed to a diverse, equitable and inclusive workforce. Learn more about how we create a welcoming work environment through Diversity, Equity, and Inclusion at www.pacificlife.com. What’s life like at Pacific Life? Visit Instagram.com/lifeatpacificlife.
  
  

Benefits start Day 1.
  
  

Your wellbeing is important. We’re committed to providing flexible benefits that you can tailor to meet your needs. Whether you are focusing on your physical, financial, emotional, or social wellbeing, we’ve got you covered.
  
  

* Prioritization of your health and well-being including Medical, Dental, Vision, and a Wellbeing Reimbursement Account that can be used on yourself or your eligible dependents
* Generous paid time off options including Paid Time Off, Holiday Schedules, and Financial Planning Time Off
* Paid Parental Leave as well as an Adoption Assistance Program
* Competitive 401k savings plan with company match and an additional contribution regardless of participation.


**Base Pay Range:**  

The base pay range noted represents the company’s good faith minimum and maximum range for this role at the time of posting. The actual compensation offered to a candidate will be dependent upon several factors, including but not limited to experience, qualifications and geographic location. Also, most employees are eligible for additional incentive pay.
  
$144,630.00 - $176,770.00
  
  

Your Benefits Start Day 1
  
  

Your wellbeing is important to Pacific Life, and we’re committed to providing you with flexible benefits that you can tailor to meet your needs. Whether you are focusing on your physical, financial, emotional, or social wellbeing, we’ve got you covered.
  
  

Prioritization of your health and well-being including Medical, Dental, Vision, and Wellbeing Reimbursement Account that can be used on yourself or your eligible dependents
  
  

**Generous paid time off options including:** Paid Time Off, Holiday Schedules, and Financial Planning Time Off
  
  

Paid Parental Leave as well as an Adoption Assistance Program
  
  

Competitive 401k savings plan with company match and an additional contribution regardless of participation
  
  

**EEO Statement:**  

Pacific Life Insurance Company is an Equal Opportunity /Affirmative Action Employer, M/F/D/V. If you are a qualified individual with a disability or a disabled veteran, you have the right to request an accommodation if you are unable or limited in your ability to use or access our career center as a result of your disability. To request an accommodation, contact a Human Resources Representative at Pacific Life Insurance Company.","https://www.indeed.com/cmp/Pacific-Life","http://www.pacificlife.com","700 Newport Center Dr.
Newport Beach CA, United States 92660","1,001 to 5,000","$5B to $10B (USD)","Pacific Life provides a variety of products and services designed to create financial security for individuals and businesses in the retail, institutional, workforce benefits, and reinsurance markets.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/586965fc249d4be519ce9b686dc91775","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/1dcada2c8aa006d88490076b10ce700b","Darryl Button","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/c33e18fe813a5ab8c72a1c554ec778a4"
"eebaa286323682d2","indeed","https://www.indeed.com/viewjob?jk=eebaa286323682d2","https://www.capgemini.com/jobs/UbINNJIBT9NJdD-e1Daa/076859/","Senior Software Engineer","Capgemini","Ontario, CA, US","","2024-09-27","direct_data","yearly",116278.0,147234.0,"USD",False,"","","","","","#### **Job Location:**

**Toronto**

#### **Job Description:**

**Overall experience includes about 5+ years of experience in 1) data project development experience, Azure Data Engineer with hands-on experience in Azure Synapse, Databricks, SQL data warehouse and data visualization models 2) ETL experience in data warehousing concepts - data extraction, transformation, schemas, merge 3) Azure data pipeline orchestration and automation, spot key performance indicators and implement efficiencies, analyze previous and present data for better decision making and 4) Developing strong data documentation around pipelines, processes, and components being created.**

#### **Key Responsibilities:**

* **Data Ingestion and Extraction connecting to various data sources like databases, files, APIs**
* **Designing and implementing efficient ETL or ELT pipelines to move data between systems.**
* **Ensuring data quality and consistency through cleansing, validation, and standardization processes.**
* **Applying Data transformations to data using tools like Azure Data Factory, Azure Databricks, or Azure Synapse Analytics.**
* **Designing data models (e.g., dimensional or normalized) to support analytical queries.**

#### **Required Skills:**

* **Data Ingestion and Extraction connecting to various data sources like databases, files, APIs**
* **Designing and implementing efficient ETL or ELT pipelines to move data between systems.**
* **Ensuring data quality and consistency through cleansing, validation, and standardization processes.**
* **Applying Data transformations to data using tools like Azure Data Factory, Azure Databricks, or Azure Synapse Analytics.**
* **Designing data models (e.g., dimensional or normalized) to support analytical queries.**

#### **Life at Capgemini**

**Capgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:**

* **Collaborating with teams of creative, fun, and driven colleagues**
* **Flexible work options enabling time and location-based flexibility**
* **Company-provided home office equipment**
* **Virtual collaboration and productivity tools to enable hybrid teams**
* **Comprehensive benefits program (Health, Welfare, Retirement and Paid time off)**
* **Other perks and wellness benefits like discount programs, and gym/studio access.**
* **Paid Parental Leave and coaching, baby welcome gift, and family care/illness days**
* **Back-up childcare/elder care, childcare discounts, and subsidized virtual tutoring**
* **Tuition assistance and weekly hot skill development opportunities**
* **Experiential, high-impact learning series events**
* **Access to mental health resources and mindfulness programs**
* **Access to join Capgemini Employee Resource Groups around communities of interest**

#### **About Capgemini**

**Capgemini is a global business and technology transformation partner, helping organizations to accelerate their dual transition to a digital and sustainable world, while creating tangible impact for enterprises and society. It is a responsible and diverse group of 340,000 team members in more than 50 countries. With its strong over 55-year heritage, Capgemini is trusted by its clients to unlock the value of technology to address the entire breadth of their business needs. It delivers end-to-end services and solutions leveraging strengths from strategy and design to engineering, all fueled by its market leading capabilities in AI, cloud and data, combined with its deep industry expertise and partner ecosystem. The Group reported 2023 global revenues of €22.5 billion.**

**Get The Future You Want |** **www.capgemini.com**

#### **Disclaimer**

**Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.**

**This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.**

**Capgemini is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.**

**Click the following link for more information on your rights as an Applicant** **http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law**

**Please be aware that Capgemini may capture your image (video or screenshot) during the interview process and that image may be used for verification, including during the hiring and onboarding process.**

**Applicants for employment in Canada must have valid work authorization that does not now and/or will not in the future require sponsorship of a visa for employment authorization in Canada by Capgemini.**","https://www.indeed.com/cmp/Capgemini","https://www.capgemini.com","Paris","10,000+","more than $10B (USD)","With more than 325,000 people, Capgemini is present in over 50 countries and celebrated its 50th Anniversary year in 2017.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/705e8467dd710fe59b83f3f0d13d2b16","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/e219c883fd16c60154364d43b9c497c1","Aiman Ezzat","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/3ea22fd272586e04be0a256d26409e76"
"c066d061b4eb2d48","indeed","https://www.indeed.com/viewjob?jk=c066d061b4eb2d48","https://www.disneycareers.com/job/-/-/391/70396865248","Principal Data Engineer","Disney Entertainment & ESPN Technology","Santa Monica, CA, US","","2024-09-26","direct_data","yearly",164500.0,231100.0,"USD",False,"","","","","","On any given day at Disney Entertainment & ESPN Technology, we’re reimagining ways to create magical viewing experiences for the world’s most beloved stories while also transforming Disney’s media business for the future. Whether that’s evolving our streaming and digital products in new and immersive ways, powering worldwide advertising and distribution to maximize flexibility and efficiency, or delivering Disney’s unmatched entertainment and sports content, every day is a moment to make a difference to partners and to hundreds of millions of people around the world.

*A few reasons why we think you’d love working for Disney Entertainment & ESPN Technology*

* **Building the future of Disney’s media business:** DE&E Technologists are designing and building the infrastructure that will power Disney’s media, advertising, and distribution businesses for years to come.
* **Reach & Scale:** The products and platforms this group builds and operates delight millions of consumers every minute of every day – from Disney+ and Hulu, to ABC News and Entertainment, to ESPN and ESPN+, and much more.
* **Innovation:** We develop and execute groundbreaking products and techniques that shape industry norms and enhance how audiences experience sports, entertainment & news.


The Product & Data Engineering team is responsible for end to end development for Disney’s world-class consumer-facing products, including streaming platforms Disney+, Hulu, and ESPN+, and digital products & experiences across ESPN, Marvel, Disney Studios, NatGeo, and ABC News. The team drives innovation at scale for millions of consumers around the world across Apple, Android, Smart TVs, game consoles, and the web, with our platforms powering core experiences like personalization, search, messaging and data.


This role involves building and maintaining our Audience Manager Platform (AMP), a centralized Disney audience data platform that captures & processes all Disney consumers cross channel behavior and delivers varying summarizations in a timely manner to multiple endpoints to support all business needs. At its core, it is a product that provides a comprehensive source of truth for customer data. It is built around customer profiles and is able to provide insights from across the business so stakeholders can quickly act on the data through activation pipelines


We are looking for a Principal Software Engineer who is passionate about developing high performance data platforms. To be successful in this role, you need effective communication and collaboration skills, a passion for learning and trying new things, and a strong foundational understanding of programming and computer science.


As a member of our team, you will apply your knowledge and skills to help us deliver scalable, performant, maintainable, and testable software.

**Responsibilities:**

* Work with a distributed team of engineers across multiple products building software collaboratively.
* Work cross-team to build consensus on approach for delivering projects
* Collaborate with business partners to understand and refine requirements
* Eliminate ambiguity in projects and communicate direction to engineers to help team members work in parallel
* Ramp up quickly on existing software to deliver incremental, integrated solutions in a complex environment
* Build high-performance, stable, scalable systems to be deployed in an enterprise setting
* Lead high-level architecture discussions and planning sessions
* Participate in the code review process by assessing pull requests
* Support systems and services during production incidents as part of the on-call rotation
* Author and recommend technical proposals and root cause analyses
* Provide mentoring and advice for other specialists
* Establish engineering practices and standards within the team to drive quality and excellence
* Represent the DEET technical community at presentations, tech talks, and other knowledge-sharing efforts

**Basic Qualifications:**

* Bachelor's degree in computer science, Information Systems, Software, Electrical or Electronics Engineering, or comparable field of study, and/or equivalent work experience.
* Minimum of 10 years of related big data engineering experience modeling and developing large data pipelines and platforms
* Hands-on experience with distributed systems such as Spark, Hadoop (HDFS, Hive, Presto, PySpark) to query and process data
* Expert in Python and SQL skills processing big datasets
* A strong grasp of computer science fundamentals (data structures, algorithms, databases, etc.)
* Experience with at least one major MPP or cloud database technology (Snowflake, Redshift, Big Query, Databricks)
* Expert in Data Modeling techniques and Data Warehousing standard methodologies and practices
* You are a problem solver with strong attention to detail and excellent analytical and communication skills
* In-depth experience with Cloud technologies like AWS (S3, ECS, EMR, EC2, Lambda, etc.)
* Solid experience with data integration toolsets (i.e Airflow), CI/CD
* Experience using source control systems and CI/CD pipelines.

**Preferred Qualifications**

* Proficient with Scrum and Agile methodologies
* Experience directly managing and mentoring a team.


#DISNEYTECH

  


The hiring range for this position in Santa Monica, CA is $164,500 to $220,600 per year and in New York, NY and Seattle, WA is $172,300 to $231,100 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","https://www.indeed.com/cmp/Disney-Entertainment-&-Espn-Technology","","","","","","","","",""
"63939c3301d8ea89","indeed","https://www.indeed.com/viewjob?jk=63939c3301d8ea89","https://www.disneycareers.com/job/-/-/391/70401976320","Sr Data Engineer","Disney Entertainment & ESPN Technology","Santa Monica, CA, US","","2024-09-26","direct_data","yearly",136100.0,191100.0,"USD",False,"","","","","","On any given day at Disney Entertainment & ESPN Technology, we’re reimagining ways to create magical viewing experiences for the world’s most beloved stories while also transforming Disney’s media business for the future. Whether that’s evolving our streaming and digital products in new and immersive ways, powering worldwide advertising and distribution to maximize flexibility and efficiency, or delivering Disney’s unmatched entertainment and sports content, every day is a moment to make a difference to partners and to hundreds of millions of people around the world.

*A few reasons why we think you’d love working for Disney Entertainment & ESPN Technology*

* **Building the future of Disney’s media business:** DE&E Technologists are designing and building the infrastructure that will power Disney’s media, advertising, and distribution businesses for years to come.
* **Reach & Scale:** The products and platforms this group builds and operates delight millions of consumers every minute of every day – from Disney+ and Hulu, to ABC News and Entertainment, to ESPN and ESPN+, and much more.
* **Innovation:** We develop and execute groundbreaking products and techniques that shape industry norms and enhance how audiences experience sports, entertainment & news.


The Product & Data Engineering team is responsible for end to end development for Disney’s world-class consumer-facing products, including streaming platforms Disney+, Hulu, and ESPN+, and digital products & experiences across ESPN, Marvel, Disney Studios, NatGeo, and ABC News. The team drives innovation at scale for millions of consumers around the world across Apple, Android, Smart TVs, game consoles, and the web, with our platforms powering core experiences like personalization, search, messaging and data.


This role involves building and maintaining our Audience Manager Platform (AMP), a centralized Disney audience data platform that captures & processes all Disney consumers cross-channel behavior and delivers varying summarizations in a timely manner to multiple endpoints to support all business needs. At its core, it is a product that provides a comprehensive source of truth for customer data. It is built around customer profiles and is able to provide insights from across the business so stakeholders can quickly act on the data through activation pipelines


This role requires expert knowledge of building scalable, fault-tolerant data processing pipelines and backend to ensure the reliable delivery of audience data.

**Responsibilities:**

* Partner with development leads to build and maintain product-driven initiatives to improve and expand the Unified Messaging Platform, enhance/improve the underlying codebase to be extensible, reusable, and maintainable
* Promote and support Agile methodologies such as Scrum, Kanban, and Scrumban by actively participating in regular ceremonies such as stand-ups, retrospectives and sprint planning.
* Participate in on-call support
* Collaborate with your squad, Product Managers, Designers, QA, Operations, and other stakeholders to understand requirements and articulate technical decisions and outcomes.
* Run tests and generate reports

**Basic Qualifications:**

* Bachelor's degree in computer science, Information Systems, Software, Electrical or Electronics Engineering, or comparable field of study, and/or equivalent work experience
* Minimum 5 years of related big data engineering experience modeling and developing large data pipelines
* Hands-on experience with distributed systems such as Spark, Hadoop (HDFS, Hive, Presto, PySpark) to query and process data
* Strong Python and SQL skills processing big datasets
* Experience with at least one major MPP or cloud database technology (Snowflake, Redshift, Big Query, Databricks)
* Familiarity with Data Modeling techniques and Data Warehousing standard methodologies and practices
* You are a problem solver with strong attention to detail and excellent analytical and communication skills
**Preferred Qualifications:**

* Demonstrated experience with Cloud technologies like AWS (S3, ECS, EMR, EC2, Lambda, etc.)
* Solid experience with data integration toolsets (i.e Airflow), CI/CD
* Familiarity with Scrum and Agile methodologies


#DISNEYTECH

  


The hiring range for this position in Santa Monica, CA is $136,100 to $182,400 per year and in New York, NY and Seattle, WA is $142,600 to $191,100 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","https://www.indeed.com/cmp/Disney-Entertainment-&-Espn-Technology","","","","","","","","",""
"77f6202e7fbd3312","indeed","https://www.indeed.com/viewjob?jk=77f6202e7fbd3312","https://www.disneycareers.com/job/-/-/391/70396865504","Lead Data Engineer","Disney Entertainment & ESPN Technology","Santa Monica, CA, US","","2024-09-26","direct_data","yearly",149300.0,209600.0,"USD",False,"","","","","","On any given day at Disney Entertainment & ESPN Technology, we’re reimagining ways to create magical viewing experiences for the world’s most beloved stories while also transforming Disney’s media business for the future. Whether that’s evolving our streaming and digital products in new and immersive ways, powering worldwide advertising and distribution to maximize flexibility and efficiency, or delivering Disney’s unmatched entertainment and sports content, every day is a moment to make a difference to partners and to hundreds of millions of people around the world.

*A few reasons why we think you’d love working for Disney Entertainment & ESPN Technology*

* **Building the future of Disney’s media business:** DE&E Technologists are designing and building the infrastructure that will power Disney’s media, advertising, and distribution businesses for years to come.
* **Reach & Scale:** The products and platforms this group builds and operates delight millions of consumers every minute of every day – from Disney+ and Hulu, to ABC News and Entertainment, to ESPN and ESPN+, and much more.
* **Innovation:** We develop and execute groundbreaking products and techniques that shape industry norms and enhance how audiences experience sports, entertainment & news.


The Product & Data Engineering team is responsible for end to end development for Disney’s world-class consumer-facing products, including streaming platforms Disney+, Hulu, and ESPN+, and digital products & experiences across ESPN, Marvel, Disney Studios, NatGeo, and ABC News. The team drives innovation at scale for millions of consumers around the world across Apple, Android, Smart TVs, game consoles, and the web, with our platforms powering core experiences like personalization, search, messaging and data.


This role involves building and maintaining our Audience Manager Platform (AMP), a centralized Disney audience data platform that captures & processes all Disney consumers cross channel behavior and delivers varying summarizations in a timely manner to multiple endpoints to support all business needs. At its core, it is a product that provides a comprehensive source of truth for customer data. It is built around customer profiles and is able to provide insights from across the business so stakeholders can quickly act on the data through activation pipelines


The role requires expert knowledge of building scalable, fault-tolerant data processing pipelines and backend to ensure the reliable delivery of audience data

**Responsibilities:**

* Build and maintain product-driven initiatives to improve and expand the Unified Messaging Platform, enhance/improve the underlying codebase to be extensible, reusable, and maintainable
* Promote and support Agile methodologies such as Scrum, Kanban, and Scrumban by actively participating in regular ceremonies such as stand-up, retrospectives and sprint planning.
* Collaborate with your squad, Product Managers, Designers, QA, Operations, and other stakeholders to understand requirements and articulate technical decisions and outcomes.
* Participate in on-call support
* Serve as an advanced resource to other Data Engineers on the team, and mentor and coach more junior members of the team helping to improve their skills, knowledge, and productivity.

**Basic Qualifications:**

* Bachelor's degree in computer science, Information Systems, Software, Electrical or Electronics Engineering, or comparable field of study, and/or equivalent work experience.
* Minimum 7 years of related big data engineering experience modeling and developing large data pipelines
* Hands-on experience with distributed systems such as Spark, Hadoop (HDFS, Hive, Presto, PySpark) to query and process data
* Strong Python and SQL skills processing big datasets
* Experience with at least one major MPP or cloud database technology (Snowflake, Redshift, Big Query, Databricks)
* Familiarity with Data Modeling techniques and Data Warehousing standard methodologies and practices
* You are a problem solver with strong attention to detail and excellent analytical and communication skills

**Preferred Qualifications:**

* In-depth experience with Cloud technologies like AWS (S3, ECS, EMR, EC2, Lambda, etc.)
* Solid experience with data integration toolsets (i.e Airflow), CI/CD
* Familiar with Scrum and Agile methodologies


#DISNEYTECH

  


The hiring range for this position in Santa Monica, CA is $149,300 to $200,200 per year and in New York, NY and Seattle, WA is $156,300 to $209,600 per year. The base pay actually offered will take into account internal equity and also may vary depending on the candidate’s geographic region, job-related knowledge, skills, and experience among other factors. A bonus and/or long-term incentive units may be provided as part of the compensation package, in addition to the full range of medical, financial, and/or other benefits, dependent on the level and position offered.","https://www.indeed.com/cmp/Disney-Entertainment-&-Espn-Technology","","","","","","","","",""
"a13aba877a032c0f","indeed","https://www.indeed.com/viewjob?jk=a13aba877a032c0f","https://www.paycomonline.net/v4/ats/web.php/jobs/ViewJobDetails?job=102084&clientkey=865B815AF28EB43FB92C7C50F831635E&source=Indeed","SQL Developer","Markwins Beauty Brands","Industry, CA, US","fulltime","2024-09-25","direct_data","yearly",90000.0,105000.0,"USD",False,"","","","","","**Position Summary**


The SQL Developer will report directly to the AVP, Engineering & Service Management. You will assist with all development stages for the SQL databases, write SQL queries, and conduct SQL database troubleshooting. The SQL Developer will be responsible for the stability, reliability, and performance of the databases. The SQL Developer will also be responsible for the implementation, configuration, maintenance, and performance of SQL Server to ensure the availability and consistent performance of our corporate applications. This is a hands-on position requiring solid technical skills, as well as excellent interpersonal and communication skills.

**Essential Duties and Responsibilities**

* Write simple to advance queries and stored procedures used for applications
* Create and modify database tables, archived tables, and indexes to improve database performance and create or modify triggers for automation
* Monitor and optimize performance of databases
* Resolve and update IT tickets for SQL related tasks/issues in a timely and efficient manner
* Database administration including installation/upgrade of SQL database, tools, user and security management, backup, restores, and replication
* Develop SQL-based reports and ad-hoc queries
* Produce SQL developments for warehouse management system HighJump
* Work with application vendors on incidents and technical support as needed
* Create/modify standard operating procedure and documentation as needed
* Provide on-call and after-hours support and maintenance duties as required

**Minimum Qualifications**

* Bachelor's Degree in Computer Science, Information Analytics, or related technical degree desired
* SQL related certifications preferred
* Required minimum 3 years of professional experience as SQL Developer or data Engineer
* Required minimum 2 years of professional experience in troubleshooting SQL related task and resolving performance issue.
* 2+ years of SQL Server Reporting Services (SSRS) experience
* 2+ years of SQL Server Integration Services (SSIS) experience
* 2+ year of MS SQL server administration
* Preferred 1+ years of HighJump Development experience in SQL

*Note: The statements herein are intended to describe the general nature and level of work being performed by employees, but are not a complete list of responsibilities, duties, and skills required of personnel so classified. Furthermore, they do not establish a contract for employment and are subject to change at the discretion of the employer.*

***Working Conditions****:*

 *Good working conditions, with the absence of disagreeable conditions.*

 ***Salary:***

*Pay commensurate with experience.*

 ***Benefits:***

*Comprehensive benefits package includes employer paid health benefits and 401k match. Benefits typically offered only to full-time employees.*

  

**Markwins Beauty Brands is an Equal Opportunity Employer**


Markwins Beauty Brands does not discriminate in practices or employment opportunities on the basis of an individual's race, color, national or ethnic origin, religion, age, sex, gender, sexual orientation, marital status, veteran status, disability, or any other proscribed category set forth in federal or state regulations.","https://www.indeed.com/cmp/Markwins-Beauty-Brands","https://www.markwinsbeauty.com/","","","","As the world’s largest indie beauty company, Markwins brings beauty to the people by innovating, responding quickly, and nurturing its employees.","","","",""
"09a5e3f84e43851f","indeed","https://www.indeed.com/viewjob?jk=09a5e3f84e43851f","https://jobs.smartrecruiters.com/Expeditors/744000015936094-senior-data-engineer","Senior Data Engineer","Expeditors","Hawthorne, CA, US","fulltime","2024-09-24","direct_data","yearly",130000.0,160000.0,"USD",False,"","","Transport And Freight","","","**Company Description**  

“We’re not in the shipping business; we’re in the information business” -Peter Rose, Expeditors Founder


Global supply chain management is what we do, but at the heart of Expeditors you will find professionalism, leadership, and a friendly environment, all of which foster an innovative, customer service-based approach to logistics.

* 15,000 trained professionals
* 250+ locations worldwide
* Fortune 500
* Globally unified systems

  

**Job Description**  

As a Senior Data Engineer, you will play a pivotal role in our agile analytics team, leading the design, development, and optimization of complex data infrastructure and pipelines. Your expertise will be crucial in delivering high-impact reporting, analytics, and machine learning solutions that drive business success. You will leverage your extensive experience to not only build and maintain critical data systems but also to mentor and guide junior engineers, ensuring the seamless translation of intricate business requirements into robust and scalable data solutions.


This position is for a role within GEO-IS Data Platforms Product Development team. This team supports our entire GEO-IS Solutions data infrastructure.


Successful candidates must understand or be able to translate complex business requirements into scalable and trusted data pipelines and models. At the core, a successful Senior Data Engineer will excel at the following:

* Serve as the subject matter expert for data and systems.
* Design, develop, and maintain scalable data pipelines and models, driving architecture and best practices for high performance.
* Identify and lead data quality improvements, standardizing and enriching data to solve complex challenges and provide insights.
* Collaborate with cross-functional teams to enhance data models and support advanced BI and analytics.
* Mentor junior data engineers, lead code reviews, and promote best practices and skill development.
* Optimize data pipelines for performance and scalability while staying updated on industry trends and technologies.

 **Major Duties and Responsibilities**

* Translate complex business needs into aligned data models and architecture.
* Design and implement scalable, high-performance data pipelines and models.
* Optimize data infrastructure to meet evolving business and tech needs.
* Monitor and enhance data pipelines for performance and integrity.
* Lead testing and troubleshooting for complex data issues.
* Drive data quality initiatives and enforce standards.
* Manage version control, backups, and disaster recovery with rigorous documentation.
* Create and maintain up-to-date technical documentation.
* Document and communicate data lineage and governance.
* Establish and promote best practices for data pipeline and model development.
* Train and mentor end-users on data models and business logic.
* Refine data models in collaboration with stakeholders for optimal performance.
* Support agile practices and maintain current work management systems.

 **Qualifications** **Minimum Qualifications**

* Bachelor's degree in an IT-related field or equivalent experience, with at least 5-7 years of progressive experience in data engineering.
* Extensive expertise in schema design, dimensional data modeling, and data warehousing, including experience with cloud-based platforms (e.g., AWS, Azure, Google Cloud).
* Proven ability to lead and collaborate effectively with cross-functional development teams, including stakeholders and executive leadership.
* Demonstrated capability to independently manage and prioritize complex projects, driving team commitments and meeting strategic objectives.
* Expert-level proficiency in writing, optimizing, and troubleshooting complex SQL queries across multiple databases.
* Advanced skills in data processing and manipulation using programming languages such as Python, with a focus on developing scalable data solutions.
* Experience with on-prem data engineering tools such as dbt core.
* Proven track record in automating complex data tasks and workflows, with experience in designing and implementing automation frameworks.

 **Desired Qualifications**

* Master’s degree or higher in Computer Science, Data Engineering, or a related field.
* Relevant certifications in cloud platforms (e.g., AWS Certified Data Analytics, Google Cloud Professional Data Engineer, Microsoft Azure Data Engineer Associate).
* Proven experience in migrating data infrastructures from on-premises to cloud environments, including strategy development, execution, and post-migration optimization.
* Experience with big data technologies such as PySpark or Kafka for processing and analyzing large-scale datasets.
* Experience with modern data warehousing solutions (e.g., Azure Synapse, Databricks) and their integration with BI tools.
* Knowledge of data governance, data privacy regulations (e.g., GDPR, CCPA), and best practices for ensuring data security and compliance.
* Familiarity with DevOps practices and tools (e.g., Docker, Kubernetes) for deploying and managing data pipelines in a CI/CD environment.
* Proficiency with advanced ETL (Extract, Transform, Load) tools and frameworks (e.g., Apache NiFi, Talend).
* Experience with managing and optimizing MS SQL Server environments (e.g., advanced T-SQL, performance tuning, linked servers, proactive maintenance).

 **Additional Information**  

The annual salary for this position is between $130,000 to $160,000.


Position is full time (40 hours per week) Monday through Friday (in office). We are an office business attire company.


Applicants are required to be eligible to lawfully work in the U.S. immediately; employer will not transfer or sponsor applicants for U.S. work authorization (such as an H-1B visa) for this opportunity.


Expeditors offers excellent benefits

* Paid Vacation, Holiday, Sick Time
* Health Plan: Medical, Prescription Drug, Dental and Vision
* Life and Long Term Disability Insurance
* 401(k) Retirement Savings Plan (US only)
* Employee Stock Purchase Plan
* Training and Personnel Development Program


All your information will be kept confidential according to EEO guidelines.","https://www.indeed.com/cmp/Expeditors","http://www.expeditors.com","1015 3rd Avenue
12th Floor
Seattle, WA 98104","10,000+","$5B to $10B (USD)","Expeditors is a Fortune 500 global logistics company that satisfies the increasingly sophisticated needs of international trade.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/aad1681b0e5965424defc81614185bd3","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/b55fc4622972cec38f457ce81e54032d","Jeffrey S. Musser",""
"fdc1b62d8114bb88","indeed","https://www.indeed.com/viewjob?jk=fdc1b62d8114bb88","https://jobs.lever.co/StubHub/e925e417-85d3-403a-a9fe-ea33b6b78ab2?lever-source=Indeed","Senior Data Engineer","StubHub","Los Angeles, CA, US","fulltime","2024-09-23","direct_data","yearly",200000.0,300000.0,"USD",False,"","","Internet And Software","","","StubHub is on a mission to redefine the live event experience on a global scale. Whether someone is looking to attend their first event or their hundredth, we’re here to delight them all the way from the moment they start looking for a ticket until they step through the gate. The same goes for our sellers. From fans selling a single ticket to the promoters of a worldwide stadium tour, we want StubHub to be the safest, most convenient way to offer a ticket to the millions of fans who browse our platform around the world.  

We are seeking talented data engineers to join StubHub’s Data Engineering team and work closely with stakeholders on our Customer Acquisition team. In this role you will be responsible for designing and building the underlying systems and pipelines for centralizing StubHub’s internal plus third-party data. Our team's goal is to empower organizations across the company to transform data for analysis and reporting, new product development, experimentation, and machine learning. This includes developing the core infrastructure for the data lake and data warehouse, creating foundational data models and data pipelines, and building shared tooling to ease the process of creating high-quality, trustworthy data assets.

As a Senior Data Engineer, you will build core data models and pipelines that facilitate our organization’s growth. You will also play a key role in defining the culture and expectations of what great data engineering looks like. We are looking for the right person that is passionate about the power of data in informing business decisions that aid the hypergrowth happening at StubHub. **This role will be based out of our Los Angeles, CA, office and has a hybrid (3 in-person days per week) work schedule.**
### **What You've Done**

* 5+ years of relevant data engineering experience in fast paced environments
* Expertise with one or more programming languages (Python, Java, etc.)
* Very high SQL proficiency, with experience in both transactional RDBMS systems and OLAP databases
* Experience designing and developing large-scale, efficient batch and streaming data processing pipelines, with well modeled data for easy consumption
* Knowledgeof data pipeline management and orchestration tools, such as Airflow
* Ability to analyze and reason about large datasets to identify data quality issues and other contextual insights
* Passionate about working with non-technical stakeholders to understand, anticipate, and deliver on their data needs

  

* A **plus** if you have experience with:
* Data transformation frameworks, such as dbt
* Batch processing systems, such as Spark
* Data pipeline management and orchestration tools, such as Airflow
* Cloud-based data warehousing solutions, such as Snowflake, BigQuery, and Redshift
* Streaming or event-driven workflows, such as Kafka and Flink

### **What You'll Do**

* Partner deeply with the Customer Acquisition team to deeply understand their domain, data, and challenges
* Build and operate scalable data pipelines with robust QA, monitoring, and alerting
* Influence the direction for key infrastructure and framework choices for data pipelining and data management
* Build and deploy core cross-functional data models
* Manage individual initiatives—setting priorities, deadlines, and deliverables based on your technical expertise
* Foster a culture of inclusion, results-oriented execution, open innovation, and limitless creativity in your team

### **What We Offer**

* **Accelerated Growth Environment:** Immerse yourself in an environment designed for swift skill and knowledge enhancement, where you have the autonomy to lead experiments and tests on a massive scale.
* **Top Tier Compensation Package:** Enjoy a rewarding compensation package that includes enticing stock incentives, aligning with our commitment to recognizing and valuing your contributions.
* **Flexible Time Off:** Embrace a healthy work-life balance with unlimited Flex Time Off, providing you the flexibility to manage your schedule and recharge as needed.
* **Comprehensive Benefits Package:** Prioritize your well-being with a comprehensive benefits package, featuring 401k, and premium Health, Vision, and Dental Insurance options.
* **Perks for Your Palate**: Delight in the workplace perks, including free weekly lunches, a diverse selection of office snacks, and the convenience of cold-brew and kombucha kegs.
* **Team-Building Events:** Engage in vibrant team events that foster camaraderie and collaboration, creating an atmosphere where your professional and personal growth are celebrated.


The anticipated gross annual base salary range for this role is $200,000 – $300,000 per year. Actual compensation will vary depending on factors such as a candidate’s qualifications, skills, experience, and competencies. Base annual salary is one component of StubHub’s total compensation and competitive benefits package, which also includes equity, 401(k), paid time off, paid parental leave, and comprehensive health benefits.  

  

California Job Applicant Privacy Notice found here **About Us**
StubHub is the world’s leading marketplace to buy and sell tickets to any live event, anywhere. Through StubHub in North America and viagogo, our international platform, we service customers in 195 countries in 33 languages and 49 available currencies. With more than 300 million tickets available annually on our platform to events around the world - from sports to music, comedy to dance, festivals to theater - StubHub offers the safest, most convenient way to buy or sell tickets to the most memorable live experiences. Come join our team for a front-row seat to the action. **We are an equal opportunity employer and value diversity on our team. We do not discriminate on the basis of race, color, religion, sex, national origin, gender, sexual orientation, age, disability, veteran status, or any other legally protected status.**","https://www.indeed.com/cmp/Stubhub","http://www.stubhub.com","199 Fremont,
San Francisco, CA 94105","1,001 to 5,000","$1B to $5B (USD)","StubHub is the world’s largest ticket marketplace with tickets available for over 10 million live sports, music and theatre events in more than 40 countries.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/55e98a2e769bc7b8ed4122e9c28d07ee","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/b8680a2821d1fe5e95c020ca2837ead4","Eric H. Baker","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/bc3a091c7950d963968dfe48e3d491f2"
"1ff70c827f595724","indeed","https://www.indeed.com/viewjob?jk=1ff70c827f595724","https://grnh.se/fb09b6bb5us","Principal Data Engineer","SPOTTER","Culver City, CA, US","","2024-09-23","direct_data","yearly",175000.0,215000.0,"USD",False,"","","","","","**Overview:**



Spotter is a platform for Creators, providing services and software designed to accelerate growth for the world's best Creators and brands. Creators working with Spotter can access the capital, knowledge, community, and personalized AI software products they need to succeed. With unique knowledge of how Creators work, the resources they need to grow, and the challenges they face, Spotter is empowering top YouTube Creators to succeed.



Spotter has already deployed over **$940 million** to YouTube Creators to reinvest in themselves and accelerate their growth, with plans to reach $1 billion in investment by **2024**. With a premium catalog that spans over **725,000 videos**, Spotter generates more than 88 billion monthly watch-time minutes, delivering a unique scaled media solution to Advertisers and Ad Agencies that is transparent, efficient, and 100% brand safe. For more information about Spotter, please visit https://spotter.com.

**OVERVIEW**



The successful candidate will be responsible for processing huge data sets (billions of records) using distributed data processing frameworks (Apache Spark, etc...).


**Must have:**


* Extensive experience working with very large data sets, creating performant & scalable ETL pipelines using Spark
* In-depth understanding of performance bottlenecks in large-scale data processing


**What You'll Do:**



Are you ready to help lead the charge in shaping the data-driven future of Spotter? We're in search of an exceptional Principal Data Engineer who will play a pivotal role in designing, building, and optimizing scalable data infrastructure. You will help us with data pipelines for acquisition and transformation of large datasets, storage and querying optimizations of varying data to support a large range of use cases from Analytics to Creator Products to Operations using traditional and ML focused access patterns. You will be a key player in empowering us to make data-informed decisions that will fuel our innovation and growth.


* Develop and maintain scalable data pipelines, including:
+ ETL pipelines, both single and multi-node solutions
+ Build data quality assurance steps for new and existing pipelines
+ Create derived datasets with augmented properties
+ Work on analytics ready datasets to power internal and creator facing tools
+ Troubleshoot issues when they arise, working directly with internal data consumers
+ Automate pipeline runs with scheduling and orchestration tools

* Work with large scale datasets
* Work with/use various external APIs to enhance data
* Setup database tables for analytics users to consume the data collected by the Data Engineering team
* Work with big data technologies to improve data availability and data quality in the cloud (AWS)
* Lead development of projects involving other team members and act as a mentor
* Actively participate in team discussions about technology/architecture/solutions for new projects and to improve existing code and pipeline


**Who You Are:**


* 10+ years of Data Engineering experience. Ideally also have 2-4 years software engineering
* 5+ years experience with Apache Spark or Apache Flink
* 4+ years of experience running software and services in the cloud
* Proficiency in working with DataFrame APIs (Pandas and Spark) for parallel and single node processing
* Proficiency using advanced languages and techniques with Python, Scala, etc. with modern data optimized file formats such as Parquet and Avro
* Proficiency with SQL on RDBMS and data warehouse solutions like Redshift
* Hands on experience with Data Lake technologies like Delta Lake and Iceberg
* Experience with data acquisition from external APIs at large scale / in parallel processing
* Experience supporting ML/AI projects: deployed pipelines for computing features, using models for inference on large datasets
* Bachelor's degree (OR equivalent work experience), preferably in Computer Science related field


**Additional Valued Skills:**


* Experience with YouTube APIs
* Experience with AWS Glue metastore
* Experience with Data-Mesh approaches
* Experience with data cataloging, data lineage and data governance tools and approaches
* Experience with vector databases


**Why Spotter:**


* Medical and vision insurance covered up to 100%
* Dental insurance
* 401(k) matching
* Stock options
* Complimentary gym access
* Autonomy and upward mobility
* Diverse, equitable, and inclusive culture, where your voice matters.


In compliance with local law, we are disclosing the compensation, or a range thereof, for roles that will be performed in Culver City. Actual salaries will vary and may be above or below the range based on various factors including but not limited to skill sets; experience and training; licensure and certifications; and other business and organizational needs. The overall market range for roles in this area of Spotter are typically: $175K-$215K salary per year. The range listed is just one component of Spotter's total compensation package for employees. Other rewards may include annual discretionary bonus and equity.

*Spotter is an equal opportunity employer. Spotter does not discriminate in employment on the basis of race, religion, creed, color, national origin, ancestry, citizenship, physical or mental disability, medical condition, genetic characteristics or information, marital status, sex (including pregnancy, childbirth, breastfeeding, and related medical conditions), gender, gender identity, gender expression, age, sexual orientation, military status, veteran status, use of or request for family or medical leave, political affiliation, or any other status protected under applicable federal, state or local laws.*


*Equal access to programs, services and employment is available to all persons. Those applicants requiring reasonable accommodations as part of the application and/or interview process should notify a representative of the Human Resources Department.*","https://www.indeed.com/cmp/Spotter","","","","","","","","",""
"9b4a7c55d9458e14","indeed","https://www.indeed.com/viewjob?jk=9b4a7c55d9458e14","https://workforcenow.adp.com/mascsr/default/mdf/recruitment/recruitment.html?cid=c0e902c9-f0fc-44ab-b5e9-a1e3d0a92d77&ccId=19000101_000001&jobId=533679&source=IN&lang=en_US","DATA ENGINEER","CareConnectMD","Costa Mesa, CA, US","fulltime","2024-09-23","direct_data","yearly",135000.0,150000.0,"USD",False,"","","","","","**Position Overview:**


We are seeking a skilled Data Engineer with experience in the healthcare industry. The ideal candidate will have expertise with the Microsoft Azure Cloud platform, data processing, data pipelines, storage and interoperability. Experience with CMS (Center for Medicare and Medicaid) and Value Based Care programs is highly preferred with an emphasis on knowledge with claims data (CCLF) and electronic medical records (EMRs).**Responsibilities:*** Develop solutions for optimal extraction, transformation, and loading of data from a wide variety of data sources into targeted databases.
* Collaborate directly with internal teammates to take business ideas and develop technical requirements that meet the business request.
* Support internal IT teammates by helping to implement tools for tracking of data, users & performance of SQL queries that enable strategic planning of product enhancements & process improvements.
* Support ETL operations and the administration of data and systems securely and in accordance with data governance standards. As an Azure Data Engineer, you should be able to manage data storage and security.
* Monitoring and resolving data pipeline problems will guarantee consistency and availability of the data.
* Work with data analytics to incorporate data requirements and build the ETL processes.

 **Required Qualifications:*** Education: Bachelor’s degree in computer science, Information Technology, or a related field.
* 3+ years of experience using Enterprise Data Integration Tools such as SSIS, Azure Data Factory, and Python.
* Experience with reading health care claims and clinical data in XML, HL7, JASON source format and converting them into relational database objects.
* 3+ years of experience working directly in relational databases as well as working familiarity with SQL and MySQL, technologies, data structures, creating stored procedures, functions, views, and concept of version control.
* Familiarity with visualization tools such as Power BI and SSRS.

 **Preferred Qualifications:*** Familiarity with CMS and Value Based Care programs such as MSSP and ACO REACH.
* Knowledge of healthcare interoperability standards (e.g., HL7, FHIR).
* Experience with DevOps practices and tools (e.g., Docker, Kubernetes, Jenkins, Github).
* Familiarity with Agile development methodologies.

**Essential Skills and Abilities*** Advanced Excel, Dashboard and Power BI ability
* Some knowledge of medical terminology and operations
* Fundamental knowledge of Microsoft SQL and SQL Reporting Services
* Strong analytical and problem-solving skills
* Ability to comprehend, analyze, and systematically compile technical and statistical information into comprehensive reports or other formats.
* Proficiency in MS Office
* Ability to work effectively with both technical and non-technical staffs
* Thrives in an unstructured, start-up environment.
* Self-starter that can work independently and collaboratively, prioritize tasks and has initiative and excitement to take on unfamiliar tasks.
* Advanced knowledge of word processing, graphic presentation and computer software related to specific tasks
* Demonstrated excellent computer and word processing skills with special emphasis on calendaring, presentation, and spreadsheet capabilities
* Working knowledge of company policies, procedures, and operations
* Excellent composition, grammar, and business language skills
* Excellent communication and interpersonal skills with the ability to effectively communicate with all levels of management, patients, and family members.
* Creative, flexible, well organized, resourceful, and detail-oriented
* Excellent judgment in handling confidential and sensitive information
* Ability to work independently, set priorities and handle multiple tasks with a high level of efficiency
* Establishing and maintaining cooperative working relationships with others
* Ability to work across locations and time zones

**Core Competencies*** Instills trust
* Customer focus
* Manages ambiguity
* Collaborates
* Drives results

***To ensure the health and safety of our workforce while doing our part to protect those around us, CareConnectMD is requiring proof of full COVID vaccination for employees as a condition of employment, subject to legally recognized accommodations.***","https://www.indeed.com/cmp/Careconnectmd-1","http://careconnectmd.com/","","","","","","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/524b0f241a21ab184bb7d00a69313954","",""
"c5209d4fc0bc80c9","indeed","https://www.indeed.com/viewjob?jk=c5209d4fc0bc80c9","https://ww3.cakecareers.com/jobs/view/496719?referral=indeed","Integrations Analyst","The Cheesecake Factory","Calabasas Hills, CA, US","","2024-09-21","direct_data","yearly",95000.0,110000.0,"USD",False,"","","","","","**Overview**


You may know us for our huge menu of delicious food…and for being recognized by Fortune Magazine as one of the “100 Best Companies to Work For®” 11 years in a row! What you may *not* know is that our IT team skillfully supports a global $3.4 billion public company with over 300 full-service restaurants and more than 47,500 total staff members.  

  

As the Integrations Analyst you will be an integral part of the Integrations team within our Information Technology department. You'll have the responsibility to design, develop, support, and optimize data pipelines and architectures using modern iPaaS solutions, and other cloud-based data processing and storage solutions. You will collaborate with various stakeholders to identify data needs and utilize best practices to integrate with disparate systems for data sharing. ***You’ll thrive in this position if you are:**** **Builder of Bridges:** By joining forces with diverse experts, you craft dynamic data pipelines and integration solutions that fuel our business's rocket ship to success.
* **Data systems detective:** Whether it's diving deep into Azure SQL mysteries or untangling Data Factory knots, you thrive on optimizing and troubleshooting to keep the data highways flowing smoothly.
* **Precision architect of data realms:** With meticulous care, you craft sturdy data models and safeguard their integrity—keeping governance, security, and auditing standards top-notch.
* **Tech chameleon:** Flexing with the times, eagerly embrace new tools and technologies. Through POCs, drive innovations that revolutionize our data integration, keeping us ahead of the curve.
* **Master of the art of communication:** From brainstorming with Business Analysts and BI engineers to decoding stakeholder needs, you ensure the data solutions speak volumes—clear, concise, and always on point.

 **Responsibilities**

* Design, develop and maintain scalable data pipelines to support data integration and processing.
* Implement integration solutions with external systems to facilitate data exchange and synchronization.
* Collaborate with Business Analysts, BI engineers, and other stakeholders to gather requirements and deliver data solutions.
* Optimize and troubleshoot data systems (Azure SQL, Data Factory, SSIS) for performance and reliability.
* Provide production support for data pipelines to ensure continuous and reliable operation.
* Design and implement robust data models to ensure data quality and consistency.
* Implement best practices for data management, including data governance, security, and auditing.
* Maintain documentation of data workflows, architectures, and processes to ensure clarity and continuity.
* Assess new tools or technologies by conducting POCs and presenting recommendations.

 **Qualifications**

* 1+ years of hands-on experience with Azure Data Factory, Azure SQL offerings, and SSIS.
* Proficiency in SQL, stored procedures, triggers, and other data transformation techniques.
* Expertise in optimizing SQL queries using query optimization techniques and other performance tuning strategies.
* Scripting experience utilizing Python/C#/JavaScript.
* Strong problem-solving and data debugging skills.
* Demonstrated ability to learn and adapt to new technologies and methodologies.
* Excellent communication skills and teamwork abilities.
* Bachelor’s degree in Computer Science, Information Systems, Data Analytics, or a related field.

 ***What we prefer:**** 3+ years of hands-on experience with Azure Data Factory, Azure SQL offerings, and SSIS.
* Restaurant industry experience.
* Experience with iPaaS tools like TIBCO, Adeptia, SnapLogic, etc.
* Familiarity with other cloud-based technologies and services on Azure e.g. Logic Apps, Functions.
* System design and architecture experience.
* Familiarity with any of the modern data warehouses and data processing tools like Databricks, BigQuery, Synapse, Snowflake etc.
* Experience building frameworks and utilities that standardize implementation of data quality, logging, monitoring etc.
* Azure certifications e.g. Azure Fundamentals, Azure Data Fundamentals, Azure Data Engineer

 **About the Company**


Recognized as a *Fortune* 100 Best Companies to Work For® since 2014, The Cheesecake Factory Incorporated is a global $3.3 billion public company with 47,500 staff members across more than 300 casual dining restaurants, including The Cheesecake Factory, North Italia, Grand Lux Cafe, Social Monk, and Fox Restaurant Concepts. Internationally, 30 The Cheesecake Factory restaurants operate under licensing agreements. Our Bakery division creates over 35,000 delicious cheesecakes per day
  

and other baked products for our restaurants, international licensees, and third-party bakery customers.  

  

We offer a people-centered culture and are committed to creating an inclusive workplace for all. We welcome applicants from a wide variety of identities, ideas, perspectives, and experiences, and encourage individuals from underrepresented backgrounds to apply.
  

  

#SoCheesecake #LifeAtCheesecake  

  

*The Cheesecake Factory Incorporated is an Equal Opportunity Employer and offers reasonable accommodations to job applicants with disabilities.* **Compensation Range**


$95000 - $110000 / Year","https://www.indeed.com/cmp/The-Cheesecake-Factory","http://www.cakecareers.com","Calabasas Hills, CA","10,000+","$1B to $5B (USD)","We believe in making big things happen at The Cheesecake Factory. Come join us and let's do big things together.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/26aa32c7b3d2447d4042e34eb4d795e9","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/ef1e7bd660ace88650efbc16dedada3a","David Overton","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/8b2dd63bba4fde7e5a3e7601af6c298c"
"e694af895eae19d8","indeed","https://www.indeed.com/viewjob?jk=e694af895eae19d8","https://capgroup.wd1.myworkdayjobs.com/en-US/capitalgroupcareers/job/Los-Angeles/Data-Engineering-Manager_JR3657","Data Engineering Manager","Capital Group","Los Angeles, CA, US","fulltime","2024-09-19","direct_data","yearly",187370.0,299792.0,"USD",False,"","","","","","“I can succeed as a Data Engineering Manager at Capital Group.”
As a Data Engineering Manager, you will lead a team that builds and manages a complex set of data capabilities to support portfolio construction, research and monitoring capabilities for our multi-asset portfolio solutions business. Our investment professionals use the platform to construct portfolios, monitor and review their portfolios, and to make investment decisions. You will collaborate with the Product Management team, Solutions Engineering team, investment professionals, and technology associates to create and implement detailed quality technical designs for mission critical and complex applications using existing and emerging technology platforms. You have an agile mindset and will contribute to the design, implementation, and delivery of large-scale, critical, and complex data architecture, storage, and pipelines. You will build enterprise data processing and analytics systems, optimizing both computational and storage efficiencies on cloud platforms. In this role, you will lead a team of Data Engineers and be responsible for their coaching and professional development. You are a player-coach, passionate about our mission, and committed to driving superior long-term investment results through the application of modern engineering and data management methods.  

“I am the person Capital Group is looking for.”* You have a bachelor’s degree in Computer Science, Engineering or a related technical field
* You are a people leader, capable of leading a team of Data Engineers while developing and mentoring individuals on the team.
* You encourage your team to be effective and efficient through a metrics-driven analytical approach.
* You are a hands-on manager, architecting, designing, and guiding your team members, and have a strong technical ability to provide feedback in design reviews and code reviews.
* You have significant experience running business critical data capabilities effectively.
* You can seamlessly partner with Product, business users, Architecture, Enterprise Data Office, and other technology teams.
* You are a continuous learner who seeks out stretch opportunities to build new technical skills and expand business acumen.
* You have led a team of at least 3+ direct reports to deliver high-quality data and analytics solutions. Experience managing 5+ direct reports is a plus.


Qualifications:* You have strong experience in various data systems and structures (i.e., SQL, NoSQL, Key-Value, Streams); your expertise includes building ETL data pipelines using Python and Pyspark and orchestration tools like Apache Airflow, Luigi, etc.
* You are an experienced manager of data engineers (5+ years)
* You have extensive prior experience as a data engineer, with a solid understanding of engineering best practices (e.g. Agile software development, test-driven development, unit testing, code reviews, design documentation, etc.)
* You understand the importance of implementing end-to-end monitoring & alerting solutions, and utilization of data processing technologies (i.e., Hadoop, Apache Spark, AWS Glue, and Kafka)
* You are passionate about management, leadership, and developing others.
* You have a strong background in Cloud Data Platforms using any one of the leading cloud platforms -AWS/Azure/GCP. (AWS preferred)
* You possess the business acumen and the ability to communicate effectively with your team, distributed teams, and with the leadership team.
* You can implement cloud-based solutions using technologies such as modern distributed systems design patterns, microservices, streaming platforms, and container orchestration systems (Docker, Swarm, Kubernetes).
* You're thoughtful in your approach to ensuring engineering best practices are established, understood, and adopted by the teams you lead.
* Prior experience in building tools for multi-asset portfolio construction and investment preferred.

  

Southern California Base Salary Range: $187,370-$299,792  

*In addition to a highly competitive base salary, per plan guidelines, restrictions and vesting requirements, you also will be eligible for an individual annual performance bonus, plus Capital’s annual profitability bonus plus a retirement plan where Capital contributes 15% of your eligible earnings.**You can learn more about our compensation and benefits* *here**.** *Temporary positions in Canada and the United States* *are excluded from the above mentioned compensation and benefit plans.*

 *We are an equal opportunity employer, which means we comply with all federal, state and local laws that prohibit discrimination when making all decisions about employment. As equal opportunity employers, our policies prohibit unlawful discrimination on the basis of race, religion, color, national origin, ancestry, sex (including gender and gender identity), pregnancy, childbirth and related medical conditions, age, physical or mental disability, medical condition, genetic information, marital status, sexual orientation, citizenship status, AIDS/HIV status, political activities or affiliations, military or veteran status, status as a victim of domestic violence, assault or stalking or any other characteristic protected by federal, state or local law.*","https://www.indeed.com/cmp/Capital-Group-1","https://www.capitalgroup.com","Los Angeles, CA","5,001 to 10,000","$1B to $5B (USD)","One of the world's largest & most trusted investment management companies with a mission to improve lives through successful investing.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/d1a8f7875439b39924ee3f95ffdbf692","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/1d5aa4f34277ba76d7f060cdd2d9e784","Mike Gitlin","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/d6a76feb92849d4f4085dfdeac9ad0ec"
"e810dbab7e953bc7","indeed","https://www.indeed.com/viewjob?jk=e810dbab7e953bc7","https://prageru.breezy.hr/p/f47aaddab91e-data-analyst-engineer?source=indeed","Data Analyst/Engineer","PragerU","Los Angeles, CA, US","fulltime","2024-09-01","direct_data","yearly",135000.0,150000.0,"USD",False,"","","","","","**Location**: Los Angeles, California (on-site)


PragerU is the world's leading conservative nonprofit that is focused on changing minds through the creative use of digital media. Taking full advantage of today's technology and social media, we educate millions of Americans and young people about the values that make America great. We're proud to be voted among the “Best Place to Work in Los Angeles” by the LA Business Journal 2 years in a row.


We are looking for a Data Analyst/Engineer, reporting to the VP of Performance Marketing. As a digital-first company, we need a versatile data leader to help provide ownership for our data analytics and performance tracking. Working with our marketing team, this role will oversee all data projects and requests for the organization.


**Duties and Responsibilities:**


**Marketing/Product/Analytics**


* Develop and maintain dashboards for main KPI performance analysis across the company
* Evaluate ROI for advertising and media spends
* Integrate current data systems to analyze success of campaigns
* Maintain, update and clean contact lists to always remain current
* Analyze data from multiple departments to reach conclusions and help discover areas for improvement
* Create system for tracking metrics/success of digital content across multiple platforms
* Define and drive all levels of campaign performance management, reporting, and analytics - bring insights to the management team based on research
* Create recurring and ad-hoc reporting and data analysis to support execution and measurement of marketing activities


**Data Engineer**


* Design, develop and maintain scalable data pipelines and processes
* Build and optimize data warehouse architecture to support analytics and reporting
* Develop algorithms to convert raw data into actionable insights
* Collaborate with marketing team to understand data needs
* Automate manual data processes, increasing efficiency and reducing errors


**Successful Candidates Will Possess:**


* 4+ years of experience in a related field, with strong knowledge of data science and business intelligence with large, complex data sets
* Proficiency in SQL, Python, Excel, Google Analytics/Tag Manager, Social Media analytics and other key platform/statistical tools
* Experience in conducting database analytics / data-driven marketing with solid understanding of marketing automation concepts and practices
* Has understanding of social media APIs and integration with centralized system
* 3+ years experience in technical email marketing for large lists (1M+)
* Strong understanding of consumer segmentation and testing
* Extensive knowledge of MailChimp, Excel modeling
* Excellent written and verbal communication skills
* Commitment to PragerU's mission, and excellence in all endeavors


**How to Apply**: First review our website at www.prageru.com (http://www.prageru.com/). Read our biannual report here (https://downloads.ctfassets.net/qnesrjodfi80/21vzuHL2bPkPehO5YhyUXp/69c4f2dd1102c512a7d9551776d4bc3f/PragerU\\_2024\\_Biannual\\_Report\\_FINAL\\_Pages.pdf). Submit a resume and cover letter. In your cover letter, include a section explaining how your values align with ours, and why you would want to specifically work at PragerU.


**What We Do**: We promote American values through the creative use of educational videos that reach millions of people online. Serving all ages, our content offers a free alternative to the dominant left-wing ideology in culture, media, and education. Whether you're searching for a deeper understanding, a new perspective, or a way to get involved, PragerU helps people think and live better. To learn more about PragerU, visit http://prageru.com.


**Salary Range:** The salary target for this role is $135,000 - $150,000. Final offer amounts depend on multiple factors including candidate experience and expertise, and most recent market data. This position is eligible for an annual bonus based on personal and company performance, in addition to our robust benefits package. The final candidate hired may potentially have less or more experience than originally posted as per job description, and if this happens, an updated salary range may be used for final hiring package.


We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, gender identity, disability, protected veteran status, or any other characteristic protected by law.


*An error page could appear for several reasons. If a technical issue occurs while applying, we suggest double checking a few things.* *Click here for additional information* (https://drive.google.com/file/d/1fuTleiCec3LQ\\_DiEvKmrnFIsia69g2Fx/view?usp=sharing)*.*


*Please note that we constantly have ideas and concepts pitched to us which we appreciate. Most ideas and concepts are not protectable and are freely available for the public and PragerU to use or modify and use. From time to time where they are not, you agree that by presenting these ideas and concept, and in consideration of PragerU reviewing these ideas and concepts, you hereby grant to PragerU an irrevocable, worldwide, royalty-free and non-exclusive license to use, modify and exploit for any purpose any ideas and concepts and any expressions of those ideas and concepts. Nothing herein precludes you from using any ideas or concepts presented.*","https://www.indeed.com/cmp/Prageru","","","","","","","","",""
"d590df983117a734","indeed","https://www.indeed.com/viewjob?jk=d590df983117a734","https://recruitingbypaycor.com/career/JobIntroduction.action?id=8a78859e902d783601903bb04409013c&source=Indeed+Free","Automation Data Engineer","Ensign Services","San Juan Capistrano, CA, US","fulltime","2024-07-23","direct_data","yearly",100000.0,160000.0,"USD",False,"","","Health Care","","","**Data Engineer**
Ensign Services, Inc. seeks a talented and energetic **Automation Data Engineer.** This position will be based at ESI’s San Juan Capistrano Service Center.
**About the Company**
Ensign Services, Inc is one of the most progressive companies in the exploding healthcare services field today. Dedicated to restoring public confidence in the healthcare industry, ESI has assembled a team of highly competent, dedicated, and caring individuals who are creating a new standard of excellence for healthcare providers everywhere
We have a unique set of core values that shape our organization. They include- CUSTOMER SECEOND, ACCOUNTABILITY, PASSION FOR LEARNING, LOVE ONE ANOTHER, INTELLIGENT RISK TAKING, CELEBRATION, and OWNERSHIP. These core values allow us to successfully serve over 300 skilled nursing, assisted living, and mobile diagnostic operations with over 40,000 employees across the United States. These facilities have no corporate headquarters or traditional management hierarchy. Instead, they operate independently with support from the “Service Center,” a world-class service team that provides the centralized clinical, legal, risk management, HR, training, accounting, IT and other resources necessary to allow on-site leaders and caregivers to focus squarely on day-to-day care and business issues in their individual facilities.
**About the Opportunity**
We are currently seeking an experienced Automation Data Engineer to join our growing finance and IT automation team. This team member will work closely with key stakeholders and other system and application developers to design, architect, implement and maintain end-to-end data needs that will support our process automation team. These solutions will drive business efficiencies and eliminate current manual processes. This individual will lead major data and other complex business development projects through delivery while capturing the project’s full impact and value.
We are looking for a team member who has a genuine passion for data and passionate to support those who rely on it; is motivated to driven to be the best, whether that’s decreasing data load times or making an innovative change to “how it’s always been done” to continuously improve our processes to handle the growing footprint of the organization; collaborative and excited to work with fellow engineers and big thinkers within the department, but across the organization; and strives for frictionless IT environment to promote a seamless, smooth, user friendly, and reliable environment.
**Job Duties**
* Collaborate with stakeholders, business analysts, and subject matter experts to design, architect, and support the data needs of the automation team.
* Provide technical direction for the design, development, testing, deployment, and maintenance of standard and complex data needs using best practices and industry standards from definition phase through implementation with governance and audit mindset.
* Adept at interpreting data models and extracting meaningful insights from data within various source systems.
* Mentor team members and help foster professional opportunities for team members looking to expand their skillsets.
* Provide ongoing maintenance and support of deployed data projects.
* Develop, manage and track project deliverables in a timely manner
* Measure outcomes, gathering user feedback, and make program improvements
* Exercise Change Management leadership skills
* Apply significant knowledge of product and developments to improve service
* Easily recognize system deficiencies and implement effective solutions
* Continually be learning about the latest features, upgrades, and industry trends to ensure continuous improvement of the data utilized in automation solutions.
* Ensure internal controls systems are accurately documented and working effectively.

**Qualifications*** 5-7 years of relevant experience.
* Experience in architecting, designing, and maintaining data environments in a large enterprise.
* Proficiency in writing complex SQL queries, optimizing them for performance, and understanding the data context within source systems.
* Proven ability to design and build databases from scratch, including setting up database schemas, tables, relationships, and indexes.
* Experience with SQL database design, administration, and ETL processes.
* In-depth knowledge of relational database management systems (RDBMS) and the ability to implement data security and recovery protocols.
* Familiarity with data warehousing concepts and experience with data warehouse technologies
* Strong understanding of automation tools and frameworks for data pipelines
* Knowledge of scripting languages such as Python, Bash, or PowerShell for automation tasks.
* Preferred basic understanding of Javascript and some experience supporting data needs for work flow tools.
* Experience with cloud platforms (AWS, Azure) and their data services.
* Understanding of basic accounting principles
* Experience in project lifecycle, including requirements gathering, evaluation of available options and cost/benefit analysis, development of implementation strategies, testing and deployment.
* Experience with strict adherence to version control in an enterprise environment
* Ability to meet deadlines and manage expectations.
* Outstanding communication skills – verbal and written.
* Strong analytical and problem-solving skills.
* Ability to work independently as well as in a team environment.
* Attention to detail and a commitment to delivering high-quality work.
* Must be able to multitask and willing to work on multiple projects at a given time.
* Ability to be proactive in your day-to-day responsibilities and work with minimal supervision.
* Ability to manage diverse personalities with superior customer service skills.
* Ability to be flexible and adapt to changes in regards to expectations and the needs of the organization.

**Preferred Qualifications**
* Experience in platforms such as Workday Extend, Appian, Nintex, Chorus, Ultimus, or similar tools.
* Experience in coding JavaScript, R, or Python.

**Compensation**
ESI offers an attractive compensation package including a competitive base salary and benefits, plus eligibility for bonuses and stock options. Success will only be limited by performance.
If you are passionate about helping others and believe you can meet the expectations outlined above, please submit your resume along with a cover letter explaining why you are the right candidate for our organization!
**Additional Information**
Salary: $100,000-$160,000 DOE
Position Type: Regular, Full-Time Employee
Benefits: Medical, dental, vision, and life insurance, 401(k) with company match, vacation pay, holiday pay, fun and supportive work environment
Location: San Juan Capistrano, CA
**Contact Information**
All inquiries held in confidence. No phone calls or agencies/third party/recruiting please.
Ensign Services, Inc. is an Equal Opportunity Employer. Pre-employment drug screening required.","https://www.indeed.com/cmp/Ensign-Services","https://ensign.wd1.myworkdayjobs.com/Ensign","29222 Rancho Viejo Road, Suite 127 San Juan Capistrano, CA 92675","10,000+","$100M to $500M (USD)","Ensign provides a wealth of healthcare and rehab services through its subsidiary facilities across the nation.","https://d2q79iu7y748jz.cloudfront.net/s/_squarelogo/256x256/8ea3cc2541405f2c07ea1350dcb86c6a","https://d2q79iu7y748jz.cloudfront.net/s/_headerimage/1960x400/97b20c57465da191662c1883091e3c0b","Barry Port","https://d2q79iu7y748jz.cloudfront.net/s/_ceophoto/512x512/8e0b23df0ef939c3d1e257e482fe65c2"
